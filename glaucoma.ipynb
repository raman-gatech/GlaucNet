{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5862aa-be6c-4c48-9ece-991578845f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.4884 - Train Acc: 76.06% - Test Acc: 91.49%\n",
      "Epoch [2/50] - Loss: 0.3153 - Train Acc: 87.41% - Test Acc: 90.07%\n",
      "Epoch [3/50] - Loss: 0.2406 - Train Acc: 89.72% - Test Acc: 94.33%\n",
      "Epoch [4/50] - Loss: 0.1696 - Train Acc: 94.15% - Test Acc: 97.16%\n",
      "Epoch [5/50] - Loss: 0.1930 - Train Acc: 93.79% - Test Acc: 96.45%\n",
      "Epoch [6/50] - Loss: 0.1524 - Train Acc: 93.62% - Test Acc: 96.45%\n",
      "Epoch [7/50] - Loss: 0.1236 - Train Acc: 95.21% - Test Acc: 97.16%\n",
      "Epoch [8/50] - Loss: 0.1335 - Train Acc: 95.39% - Test Acc: 96.45%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m         scheduler.step()\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs)\u001b[39m\n\u001b[32m    106\u001b[39m outputs = model(inputs)\n\u001b[32m    107\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m optimizer.step()\n\u001b[32m    111\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#basic only acrima\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Training/\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Testing/\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Lower batch size for memory efficiency\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hybrid Model with Self-Gating Mechanism\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.gate = nn.Linear(feature_dim, feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Self-gating mechanism\n",
    "        gate_values = torch.sigmoid(self.gate(fused_features))\n",
    "        gated_features = fused_features * gate_values\n",
    "        \n",
    "        gated_features = self.batch_norm(gated_features)\n",
    "        gated_features = self.dropout(gated_features)\n",
    "        return self.fc(gated_features)\n",
    "\n",
    "# Model initialization\n",
    "model = HybridModel().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total * 100\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        test_accuracy = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8361a60-7fa3-42d9-8cfc-ef8ace10021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.3391 - Train Acc: 85.28% - Test Acc: 86.52%\n",
      "Epoch [2/50] - Loss: 0.1682 - Train Acc: 93.26% - Test Acc: 95.04%\n",
      "Epoch [3/50] - Loss: 0.1774 - Train Acc: 93.97% - Test Acc: 90.78%\n",
      "Epoch [4/50] - Loss: 0.1263 - Train Acc: 94.68% - Test Acc: 92.20%\n",
      "Epoch [5/50] - Loss: 0.1671 - Train Acc: 93.97% - Test Acc: 94.33%\n",
      "Epoch [6/50] - Loss: 0.1188 - Train Acc: 95.39% - Test Acc: 97.16%\n",
      "Epoch [7/50] - Loss: 0.1473 - Train Acc: 94.86% - Test Acc: 97.16%\n",
      "Epoch [8/50] - Loss: 0.0564 - Train Acc: 98.05% - Test Acc: 95.04%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 144\u001b[39m\n\u001b[32m    141\u001b[39m         scheduler.step()\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs)\u001b[39m\n\u001b[32m    136\u001b[39m train_accuracy = correct_train / total_train * \u001b[32m100\u001b[39m\n\u001b[32m    137\u001b[39m avg_loss = running_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m test_accuracy = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% - Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    141\u001b[39m scheduler.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_loader, device)\u001b[39m\n\u001b[32m    106\u001b[39m correct, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:245\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[33;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m path, target = \u001b[38;5;28mself\u001b[39m.samples[index]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.transform(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:284\u001b[39m, in \u001b[36mdefault_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:264\u001b[39m, in \u001b[36mpil_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    263\u001b[39m     img = Image.open(f)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/PIL/Image.py:984\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    982\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/PIL/ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#only acrima again\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Training/\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Testing/\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Lower batch size for memory efficiency\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Synthetic Data Generator (GAN-based)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_shape=(3, 224, 224)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, np.prod(img_shape)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "generator = Generator().to(device)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Feature Fusion using Attention-based Weighting\n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Model initialization\n",
    "model = HybridModel().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=50)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total * 100\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        test_accuracy = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9428a16b-0321-4b2f-8cff-b5c894b7c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.4288 - Train Acc: 81.60% - Test Acc: 85.94%\n",
      "Epoch [2/50] - Loss: 0.1740 - Train Acc: 92.83% - Test Acc: 83.85%\n",
      "Epoch [3/50] - Loss: 0.1764 - Train Acc: 92.83% - Test Acc: 89.58%\n",
      "Epoch [4/50] - Loss: 0.1398 - Train Acc: 95.11% - Test Acc: 91.67%\n",
      "Epoch [5/50] - Loss: 0.1522 - Train Acc: 93.97% - Test Acc: 93.23%\n",
      "Epoch [6/50] - Loss: 0.1369 - Train Acc: 93.97% - Test Acc: 89.06%\n",
      "Epoch [7/50] - Loss: 0.0921 - Train Acc: 96.42% - Test Acc: 90.62%\n",
      "Epoch [8/50] - Loss: 0.1159 - Train Acc: 95.28% - Test Acc: 86.46%\n",
      "Epoch [9/50] - Loss: 0.0933 - Train Acc: 96.58% - Test Acc: 86.98%\n",
      "Epoch [10/50] - Loss: 0.0582 - Train Acc: 97.88% - Test Acc: 93.75%\n",
      "Epoch [11/50] - Loss: 0.1184 - Train Acc: 96.58% - Test Acc: 91.15%\n",
      "Epoch [12/50] - Loss: 0.1259 - Train Acc: 95.77% - Test Acc: 89.58%\n",
      "Epoch [13/50] - Loss: 0.0728 - Train Acc: 97.56% - Test Acc: 91.67%\n",
      "Epoch [14/50] - Loss: 0.0659 - Train Acc: 97.56% - Test Acc: 88.02%\n",
      "Epoch [15/50] - Loss: 0.0853 - Train Acc: 97.23% - Test Acc: 86.98%\n",
      "Epoch [16/50] - Loss: 0.0531 - Train Acc: 98.53% - Test Acc: 92.71%\n",
      "Epoch [17/50] - Loss: 0.0786 - Train Acc: 97.39% - Test Acc: 88.54%\n",
      "Epoch [18/50] - Loss: 0.0853 - Train Acc: 97.39% - Test Acc: 87.50%\n",
      "Epoch [19/50] - Loss: 0.0775 - Train Acc: 97.72% - Test Acc: 93.75%\n",
      "Epoch [20/50] - Loss: 0.0583 - Train Acc: 98.05% - Test Acc: 90.10%\n",
      "Epoch [21/50] - Loss: 0.0367 - Train Acc: 98.53% - Test Acc: 91.67%\n",
      "Epoch [22/50] - Loss: 0.0835 - Train Acc: 97.23% - Test Acc: 93.75%\n",
      "Epoch [23/50] - Loss: 0.0512 - Train Acc: 98.05% - Test Acc: 91.67%\n",
      "Epoch [24/50] - Loss: 0.0736 - Train Acc: 97.56% - Test Acc: 92.71%\n",
      "Epoch [25/50] - Loss: 0.0487 - Train Acc: 98.53% - Test Acc: 89.58%\n",
      "Epoch [26/50] - Loss: 0.0348 - Train Acc: 98.37% - Test Acc: 93.75%\n",
      "Epoch [27/50] - Loss: 0.0503 - Train Acc: 98.05% - Test Acc: 92.19%\n",
      "Epoch [28/50] - Loss: 0.0374 - Train Acc: 98.53% - Test Acc: 89.58%\n",
      "Epoch [29/50] - Loss: 0.1101 - Train Acc: 97.56% - Test Acc: 92.71%\n",
      "Epoch [30/50] - Loss: 0.0916 - Train Acc: 98.37% - Test Acc: 90.62%\n",
      "Epoch [31/50] - Loss: 0.1068 - Train Acc: 96.25% - Test Acc: 89.06%\n",
      "Epoch [32/50] - Loss: 0.0798 - Train Acc: 97.56% - Test Acc: 91.15%\n",
      "Epoch [33/50] - Loss: 0.0552 - Train Acc: 98.53% - Test Acc: 88.02%\n",
      "Epoch [34/50] - Loss: 0.0331 - Train Acc: 98.86% - Test Acc: 91.15%\n",
      "Epoch [35/50] - Loss: 0.0749 - Train Acc: 97.72% - Test Acc: 92.71%\n",
      "Epoch [36/50] - Loss: 0.0387 - Train Acc: 98.53% - Test Acc: 93.75%\n",
      "Epoch [37/50] - Loss: 0.0431 - Train Acc: 98.70% - Test Acc: 92.19%\n",
      "Epoch [38/50] - Loss: 0.0750 - Train Acc: 96.91% - Test Acc: 92.19%\n",
      "Epoch [39/50] - Loss: 0.0402 - Train Acc: 98.70% - Test Acc: 86.98%\n",
      "Epoch [40/50] - Loss: 0.0804 - Train Acc: 97.07% - Test Acc: 91.67%\n",
      "Epoch [41/50] - Loss: 0.0459 - Train Acc: 98.70% - Test Acc: 88.02%\n",
      "Epoch [42/50] - Loss: 0.0639 - Train Acc: 98.21% - Test Acc: 92.19%\n",
      "Epoch [43/50] - Loss: 0.0238 - Train Acc: 99.19% - Test Acc: 92.19%\n",
      "Epoch [44/50] - Loss: 0.0160 - Train Acc: 99.35% - Test Acc: 83.85%\n",
      "Epoch [45/50] - Loss: 0.0569 - Train Acc: 97.72% - Test Acc: 92.19%\n",
      "Epoch [46/50] - Loss: 0.0274 - Train Acc: 99.19% - Test Acc: 84.90%\n",
      "Epoch [47/50] - Loss: 0.0202 - Train Acc: 99.19% - Test Acc: 93.75%\n",
      "Epoch [48/50] - Loss: 0.0535 - Train Acc: 98.70% - Test Acc: 91.15%\n",
      "Epoch [49/50] - Loss: 0.0385 - Train Acc: 98.53% - Test Acc: 93.75%\n",
      "Epoch [50/50] - Loss: 0.0262 - Train Acc: 99.02% - Test Acc: 89.58%\n"
     ]
    }
   ],
   "source": [
    "#BASIC GAN ACRIMA_DRISHTI BEST AS OF NOW\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Lower batch size for memory efficiency\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Synthetic Data Generator (GAN-based)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_shape=(3, 224, 224)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, np.prod(img_shape)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "generator = Generator().to(device)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Feature Fusion using Attention-based Weighting\n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Model initialization\n",
    "model = HybridModel().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=50)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total * 100\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        test_accuracy = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02dc515c-61b7-4a65-bf5c-4f4cd6330cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.3905 - Train Acc: 81.11% - Test Acc: 81.25%\n",
      "Epoch [2/50] - Loss: 0.2679 - Train Acc: 88.76% - Test Acc: 84.90%\n",
      "Epoch [3/50] - Loss: 0.2128 - Train Acc: 91.21% - Test Acc: 85.94%\n",
      "Epoch [4/50] - Loss: 0.1927 - Train Acc: 93.65% - Test Acc: 89.58%\n",
      "Epoch [5/50] - Loss: 0.1288 - Train Acc: 94.79% - Test Acc: 89.58%\n",
      "Epoch [6/50] - Loss: 0.1655 - Train Acc: 94.14% - Test Acc: 85.42%\n",
      "Epoch [7/50] - Loss: 0.1346 - Train Acc: 93.97% - Test Acc: 90.10%\n",
      "Epoch [8/50] - Loss: 0.1471 - Train Acc: 94.14% - Test Acc: 88.02%\n",
      "Epoch [9/50] - Loss: 0.1252 - Train Acc: 95.44% - Test Acc: 91.15%\n",
      "Epoch [10/50] - Loss: 0.1068 - Train Acc: 96.58% - Test Acc: 90.62%\n",
      "Epoch [11/50] - Loss: 0.1246 - Train Acc: 95.11% - Test Acc: 84.90%\n",
      "Epoch [12/50] - Loss: 0.1214 - Train Acc: 94.63% - Test Acc: 91.67%\n",
      "Epoch [13/50] - Loss: 0.0639 - Train Acc: 97.23% - Test Acc: 90.10%\n",
      "Epoch [14/50] - Loss: 0.0842 - Train Acc: 97.07% - Test Acc: 91.67%\n",
      "Epoch [15/50] - Loss: 0.1270 - Train Acc: 95.77% - Test Acc: 84.38%\n",
      "Epoch [16/50] - Loss: 0.1247 - Train Acc: 95.44% - Test Acc: 89.06%\n",
      "Epoch [17/50] - Loss: 0.1191 - Train Acc: 96.42% - Test Acc: 90.10%\n",
      "Epoch [18/50] - Loss: 0.0929 - Train Acc: 96.42% - Test Acc: 91.15%\n",
      "Epoch [19/50] - Loss: 0.0767 - Train Acc: 96.58% - Test Acc: 90.10%\n",
      "Epoch [20/50] - Loss: 0.0615 - Train Acc: 97.88% - Test Acc: 91.15%\n",
      "Epoch [21/50] - Loss: 0.0714 - Train Acc: 97.72% - Test Acc: 88.02%\n",
      "Epoch [22/50] - Loss: 0.0705 - Train Acc: 97.39% - Test Acc: 86.46%\n",
      "Epoch [23/50] - Loss: 0.0930 - Train Acc: 96.58% - Test Acc: 86.98%\n",
      "Epoch [24/50] - Loss: 0.0873 - Train Acc: 97.72% - Test Acc: 92.19%\n",
      "Epoch [25/50] - Loss: 0.0721 - Train Acc: 96.91% - Test Acc: 90.10%\n",
      "Epoch [26/50] - Loss: 0.0451 - Train Acc: 97.88% - Test Acc: 91.15%\n",
      "Epoch [27/50] - Loss: 0.0856 - Train Acc: 97.39% - Test Acc: 91.67%\n",
      "Epoch [28/50] - Loss: 0.0992 - Train Acc: 97.39% - Test Acc: 88.54%\n",
      "Epoch [29/50] - Loss: 0.0489 - Train Acc: 97.88% - Test Acc: 90.10%\n",
      "Epoch [30/50] - Loss: 0.0361 - Train Acc: 98.53% - Test Acc: 91.67%\n",
      "Epoch [31/50] - Loss: 0.0650 - Train Acc: 98.05% - Test Acc: 91.15%\n",
      "Epoch [32/50] - Loss: 0.0651 - Train Acc: 98.05% - Test Acc: 91.67%\n",
      "Epoch [33/50] - Loss: 0.0794 - Train Acc: 97.56% - Test Acc: 89.58%\n",
      "Epoch [34/50] - Loss: 0.0526 - Train Acc: 97.88% - Test Acc: 91.15%\n",
      "Epoch [35/50] - Loss: 0.0382 - Train Acc: 98.05% - Test Acc: 89.58%\n",
      "Epoch [36/50] - Loss: 0.0401 - Train Acc: 99.02% - Test Acc: 88.54%\n",
      "Epoch [37/50] - Loss: 0.0559 - Train Acc: 98.37% - Test Acc: 89.58%\n",
      "Epoch [38/50] - Loss: 0.0455 - Train Acc: 98.86% - Test Acc: 92.71%\n",
      "Epoch [39/50] - Loss: 0.0531 - Train Acc: 97.39% - Test Acc: 89.58%\n",
      "Epoch [40/50] - Loss: 0.0584 - Train Acc: 97.88% - Test Acc: 92.19%\n",
      "Epoch [41/50] - Loss: 0.0395 - Train Acc: 97.88% - Test Acc: 89.58%\n",
      "Epoch [42/50] - Loss: 0.0341 - Train Acc: 98.86% - Test Acc: 92.19%\n",
      "Epoch [43/50] - Loss: 0.0338 - Train Acc: 98.86% - Test Acc: 91.67%\n",
      "Epoch [44/50] - Loss: 0.0244 - Train Acc: 99.19% - Test Acc: 91.67%\n",
      "Epoch [45/50] - Loss: 0.0590 - Train Acc: 98.70% - Test Acc: 89.58%\n",
      "Epoch [46/50] - Loss: 0.0306 - Train Acc: 99.19% - Test Acc: 90.62%\n",
      "Epoch [47/50] - Loss: 0.0528 - Train Acc: 97.88% - Test Acc: 90.10%\n",
      "Epoch [48/50] - Loss: 0.0283 - Train Acc: 98.86% - Test Acc: 88.02%\n",
      "Epoch [49/50] - Loss: 0.0308 - Train Acc: 98.21% - Test Acc: 92.19%\n",
      "Epoch [50/50] - Loss: 0.0141 - Train Acc: 99.35% - Test Acc: 89.58%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Lower batch size for memory efficiency\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Synthetic Data Generator (GAN-based)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_shape=(3, 224, 224)):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, np.prod(img_shape)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "generator = Generator().to(device)\n",
    "\n",
    "# CycleGAN Placeholder for Domain Adaptation\n",
    "class CycleGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "cycle_gan = CycleGANGenerator().to(device)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Feature Fusion using Attention-based Weighting\n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Model initialization\n",
    "model = HybridModel().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=50)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce7c223-01fd-4583-86b0-d97f7135816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.4052 - Train Acc: 83.22% - Test Acc: 70.31%\n",
      "Epoch [2/50] - Loss: 0.2688 - Train Acc: 89.41% - Test Acc: 85.94%\n",
      "Epoch [3/50] - Loss: 0.2119 - Train Acc: 91.69% - Test Acc: 81.25%\n",
      "Epoch [4/50] - Loss: 0.1654 - Train Acc: 92.83% - Test Acc: 91.67%\n",
      "Epoch [5/50] - Loss: 0.1041 - Train Acc: 95.44% - Test Acc: 82.81%\n",
      "Epoch [6/50] - Loss: 0.1699 - Train Acc: 94.79% - Test Acc: 89.06%\n",
      "Epoch [7/50] - Loss: 0.1309 - Train Acc: 95.77% - Test Acc: 89.06%\n",
      "Epoch [8/50] - Loss: 0.1247 - Train Acc: 95.44% - Test Acc: 83.33%\n",
      "Epoch [9/50] - Loss: 0.1019 - Train Acc: 95.93% - Test Acc: 88.54%\n",
      "Epoch [10/50] - Loss: 0.1070 - Train Acc: 95.60% - Test Acc: 90.10%\n",
      "Epoch [11/50] - Loss: 0.1191 - Train Acc: 97.07% - Test Acc: 90.10%\n",
      "Epoch [12/50] - Loss: 0.0964 - Train Acc: 96.58% - Test Acc: 88.54%\n",
      "Epoch [13/50] - Loss: 0.0815 - Train Acc: 97.39% - Test Acc: 88.02%\n",
      "Epoch [14/50] - Loss: 0.0932 - Train Acc: 96.58% - Test Acc: 91.67%\n",
      "Epoch [15/50] - Loss: 0.0542 - Train Acc: 98.37% - Test Acc: 91.67%\n",
      "Epoch [16/50] - Loss: 0.0698 - Train Acc: 97.72% - Test Acc: 91.67%\n",
      "Epoch [17/50] - Loss: 0.0601 - Train Acc: 98.70% - Test Acc: 94.79%\n",
      "Epoch [18/50] - Loss: 0.0592 - Train Acc: 97.56% - Test Acc: 85.94%\n",
      "Epoch [19/50] - Loss: 0.0907 - Train Acc: 96.74% - Test Acc: 93.75%\n",
      "Epoch [20/50] - Loss: 0.0583 - Train Acc: 98.37% - Test Acc: 90.62%\n",
      "Epoch [21/50] - Loss: 0.0623 - Train Acc: 98.21% - Test Acc: 88.54%\n",
      "Epoch [22/50] - Loss: 0.0562 - Train Acc: 98.21% - Test Acc: 91.15%\n",
      "Epoch [23/50] - Loss: 0.0910 - Train Acc: 96.09% - Test Acc: 84.90%\n",
      "Epoch [24/50] - Loss: 0.0825 - Train Acc: 97.23% - Test Acc: 91.15%\n",
      "Epoch [25/50] - Loss: 0.0989 - Train Acc: 95.93% - Test Acc: 91.15%\n",
      "Epoch [26/50] - Loss: 0.0274 - Train Acc: 99.35% - Test Acc: 93.23%\n",
      "Epoch [27/50] - Loss: 0.0373 - Train Acc: 98.53% - Test Acc: 89.58%\n",
      "Epoch [28/50] - Loss: 0.0500 - Train Acc: 98.05% - Test Acc: 89.58%\n",
      "Epoch [29/50] - Loss: 0.0664 - Train Acc: 98.21% - Test Acc: 91.67%\n",
      "Epoch [30/50] - Loss: 0.0289 - Train Acc: 99.35% - Test Acc: 91.15%\n",
      "Epoch [31/50] - Loss: 0.0406 - Train Acc: 98.53% - Test Acc: 92.19%\n",
      "Epoch [32/50] - Loss: 0.0536 - Train Acc: 98.53% - Test Acc: 91.67%\n",
      "Epoch [33/50] - Loss: 0.0218 - Train Acc: 99.19% - Test Acc: 92.71%\n",
      "Epoch [34/50] - Loss: 0.0786 - Train Acc: 97.72% - Test Acc: 89.58%\n",
      "Epoch [35/50] - Loss: 0.0387 - Train Acc: 98.70% - Test Acc: 91.67%\n",
      "Epoch [36/50] - Loss: 0.0779 - Train Acc: 97.56% - Test Acc: 89.06%\n",
      "Epoch [37/50] - Loss: 0.0312 - Train Acc: 99.02% - Test Acc: 93.23%\n",
      "Epoch [38/50] - Loss: 0.0596 - Train Acc: 97.88% - Test Acc: 91.67%\n",
      "Epoch [39/50] - Loss: 0.0555 - Train Acc: 97.39% - Test Acc: 89.06%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 163\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% - Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    161\u001b[39m         scheduler.step()\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs)\u001b[39m\n\u001b[32m    136\u001b[39m outputs = model(inputs)\n\u001b[32m    137\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m optimizer.step()\n\u001b[32m    141\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#self-supervised learning (SSL) module using SimCLR for fundus images\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Lower batch size for memory efficiency\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Self-Supervised Learning (SSL) using SimCLR\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x).last_hidden_state[:, 0, :]\n",
    "        return self.projection_head(features)\n",
    "\n",
    "vit_encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "simclr = SimCLR(vit_encoder).to(device)\n",
    "\n",
    "# CycleGAN Placeholder for Domain Adaptation\n",
    "class CycleGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "cycle_gan = CycleGANGenerator().to(device)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Feature Fusion using Attention-based Weighting\n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Model initialization\n",
    "model = HybridModel().to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=50)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8f50a-fd24-4bd8-886e-ca51039ba1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c39b33-03a5-4db2-b4d1-5c5d4f4fbaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2e886-3396-49fd-a3dc-eb01eeb06fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c340c-5e17-43f8-9617-c314d7f01166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1457aeab-6c0c-4f26-a3fd-95a89d6f6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.4238 - Train Acc: 81.92% - Test Loss: 0.3009 - Test Acc: 88.54%\n",
      "Epoch [2/50] - Loss: 0.2417 - Train Acc: 89.90% - Test Loss: 0.2769 - Test Acc: 89.58%\n",
      "Epoch [3/50] - Loss: 0.2284 - Train Acc: 91.21% - Test Loss: 0.2473 - Test Acc: 91.67%\n",
      "Epoch [4/50] - Loss: 0.2452 - Train Acc: 88.60% - Test Loss: 0.2812 - Test Acc: 87.50%\n",
      "Epoch [5/50] - Loss: 0.1847 - Train Acc: 92.67% - Test Loss: 0.2573 - Test Acc: 91.15%\n",
      "Epoch [6/50] - Loss: 0.1752 - Train Acc: 93.16% - Test Loss: 0.4435 - Test Acc: 80.73%\n",
      "Epoch [7/50] - Loss: 0.1398 - Train Acc: 93.97% - Test Loss: 0.2598 - Test Acc: 91.67%\n",
      "Epoch [8/50] - Loss: 0.1385 - Train Acc: 94.79% - Test Loss: 0.2559 - Test Acc: 89.06%\n",
      "Epoch [9/50] - Loss: 0.1000 - Train Acc: 96.09% - Test Loss: 0.3342 - Test Acc: 84.90%\n",
      "Epoch [10/50] - Loss: 0.1023 - Train Acc: 95.77% - Test Loss: 0.4553 - Test Acc: 85.42%\n",
      "Epoch [11/50] - Loss: 0.1054 - Train Acc: 96.09% - Test Loss: 0.3717 - Test Acc: 85.42%\n",
      "Epoch [12/50] - Loss: 0.1329 - Train Acc: 95.28% - Test Loss: 0.3348 - Test Acc: 89.58%\n",
      "Epoch [13/50] - Loss: 0.1213 - Train Acc: 96.42% - Test Loss: 0.3672 - Test Acc: 90.10%\n",
      "Epoch [14/50] - Loss: 0.1190 - Train Acc: 97.23% - Test Loss: 0.2118 - Test Acc: 91.67%\n",
      "Epoch [15/50] - Loss: 0.0971 - Train Acc: 95.11% - Test Loss: 0.2974 - Test Acc: 89.06%\n",
      "Epoch [16/50] - Loss: 0.1112 - Train Acc: 95.77% - Test Loss: 0.2575 - Test Acc: 91.15%\n",
      "Epoch [17/50] - Loss: 0.1163 - Train Acc: 96.25% - Test Loss: 0.2806 - Test Acc: 92.71%\n",
      "Epoch [18/50] - Loss: 0.1016 - Train Acc: 96.25% - Test Loss: 0.1843 - Test Acc: 93.23%\n",
      "Epoch [19/50] - Loss: 0.0849 - Train Acc: 96.91% - Test Loss: 0.3494 - Test Acc: 89.06%\n",
      "Epoch [20/50] - Loss: 0.0685 - Train Acc: 97.23% - Test Loss: 0.2206 - Test Acc: 91.15%\n",
      "Epoch [21/50] - Loss: 0.0886 - Train Acc: 97.39% - Test Loss: 0.2573 - Test Acc: 93.23%\n",
      "Epoch [22/50] - Loss: 0.0478 - Train Acc: 97.88% - Test Loss: 0.3954 - Test Acc: 86.46%\n",
      "Epoch [23/50] - Loss: 0.0810 - Train Acc: 97.39% - Test Loss: 0.2265 - Test Acc: 89.58%\n",
      "Epoch [24/50] - Loss: 0.0893 - Train Acc: 96.91% - Test Loss: 0.3362 - Test Acc: 87.50%\n",
      "Epoch [25/50] - Loss: 0.0598 - Train Acc: 97.39% - Test Loss: 0.3598 - Test Acc: 89.06%\n",
      "Epoch [26/50] - Loss: 0.0495 - Train Acc: 97.72% - Test Loss: 0.2406 - Test Acc: 91.67%\n",
      "Epoch [27/50] - Loss: 0.0328 - Train Acc: 98.70% - Test Loss: 0.2293 - Test Acc: 92.71%\n",
      "Epoch [28/50] - Loss: 0.0442 - Train Acc: 98.21% - Test Loss: 0.3088 - Test Acc: 90.10%\n",
      "Epoch [29/50] - Loss: 0.0518 - Train Acc: 97.72% - Test Loss: 0.5068 - Test Acc: 88.02%\n",
      "Epoch [30/50] - Loss: 0.0687 - Train Acc: 98.70% - Test Loss: 0.3069 - Test Acc: 90.62%\n",
      "Epoch [31/50] - Loss: 0.1166 - Train Acc: 96.74% - Test Loss: 0.2555 - Test Acc: 92.19%\n",
      "Epoch [32/50] - Loss: 0.0637 - Train Acc: 98.05% - Test Loss: 0.3054 - Test Acc: 91.15%\n",
      "Epoch [33/50] - Loss: 0.0601 - Train Acc: 97.88% - Test Loss: 0.2546 - Test Acc: 90.62%\n",
      "Epoch [34/50] - Loss: 0.0333 - Train Acc: 98.70% - Test Loss: 0.2515 - Test Acc: 91.67%\n",
      "Epoch [35/50] - Loss: 0.0542 - Train Acc: 98.53% - Test Loss: 0.4156 - Test Acc: 89.58%\n",
      "Epoch [36/50] - Loss: 0.0711 - Train Acc: 98.05% - Test Loss: 0.4053 - Test Acc: 92.71%\n",
      "Epoch [37/50] - Loss: 0.0294 - Train Acc: 98.86% - Test Loss: 0.3194 - Test Acc: 91.67%\n",
      "Epoch [38/50] - Loss: 0.0599 - Train Acc: 97.88% - Test Loss: 0.2631 - Test Acc: 92.71%\n",
      "Epoch [39/50] - Loss: 0.0527 - Train Acc: 97.88% - Test Loss: 0.3141 - Test Acc: 92.71%\n",
      "Epoch [40/50] - Loss: 0.0329 - Train Acc: 98.70% - Test Loss: 0.3835 - Test Acc: 88.02%\n",
      "Epoch [41/50] - Loss: 0.0296 - Train Acc: 98.70% - Test Loss: 0.3252 - Test Acc: 92.19%\n",
      "Epoch [42/50] - Loss: 0.1027 - Train Acc: 97.39% - Test Loss: 0.4610 - Test Acc: 88.54%\n",
      "Epoch [43/50] - Loss: 0.0527 - Train Acc: 97.72% - Test Loss: 0.4394 - Test Acc: 87.50%\n",
      "Epoch [44/50] - Loss: 0.0643 - Train Acc: 98.53% - Test Loss: 0.2680 - Test Acc: 92.71%\n",
      "Epoch [45/50] - Loss: 0.0481 - Train Acc: 98.70% - Test Loss: 0.3176 - Test Acc: 90.62%\n",
      "Epoch [46/50] - Loss: 0.0212 - Train Acc: 99.19% - Test Loss: 0.3443 - Test Acc: 91.15%\n",
      "Epoch [47/50] - Loss: 0.0050 - Train Acc: 100.00% - Test Loss: 0.2658 - Test Acc: 93.23%\n",
      "Epoch [48/50] - Loss: 0.0285 - Train Acc: 99.19% - Test Loss: 0.3652 - Test Acc: 91.67%\n",
      "Epoch [49/50] - Loss: 0.0437 - Train Acc: 98.86% - Test Loss: 1.1947 - Test Acc: 81.25%\n",
      "Epoch [50/50] - Loss: 0.0610 - Train Acc: 98.70% - Test Loss: 0.2413 - Test Acc: 94.27%\n"
     ]
    }
   ],
   "source": [
    "#imporved MOST COMPLEX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Self-Supervised Learning (SSL) using SimCLR\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, base_encoder, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = base_encoder\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x).last_hidden_state[:, 0, :]\n",
    "        return self.projection_head(features)\n",
    "\n",
    "vit_encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "simclr = SimCLR(vit_encoder).to(device)\n",
    "\n",
    "# CycleGAN Generator\n",
    "class CycleGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "cycle_gan = CycleGANGenerator().to(device)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Loss: {avg_test_loss:.4f} - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "\n",
    "# Initialize and train model\n",
    "model = HybridModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123e990-c621-4666-985e-b1454d28823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8349b6c-6b76-4a42-a9dc-c1d4481e8f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746e17b-cd6a-4a38-898d-aac9c930f204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf0285-0bf2-4f3b-adfd-dffad0285a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5421558-47e0-4af9-b30c-2e23bceea9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b44b6-794d-4482-b377-a63059bff1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ec0bd-63ad-4922-b126-830dc64bf65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab944bd1-7338-439b-b83f-e81a3267639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.7258 - Train Acc: 73.29% - Test Loss: 0.5879 - Test Acc: 77.60%\n",
      "Epoch [2/50] - Loss: 0.4609 - Train Acc: 79.97% - Test Loss: 0.9108 - Test Acc: 80.73%\n",
      "Epoch [3/50] - Loss: 0.3470 - Train Acc: 89.74% - Test Loss: 0.6764 - Test Acc: 81.25%\n",
      "Epoch [4/50] - Loss: 0.3152 - Train Acc: 89.25% - Test Loss: 0.6906 - Test Acc: 80.73%\n",
      "Epoch [5/50] - Loss: 0.3581 - Train Acc: 86.97% - Test Loss: 0.4804 - Test Acc: 85.94%\n",
      "Epoch [6/50] - Loss: 0.2913 - Train Acc: 90.55% - Test Loss: 0.2753 - Test Acc: 90.10%\n",
      "Epoch [7/50] - Loss: 0.2512 - Train Acc: 90.23% - Test Loss: 0.5208 - Test Acc: 88.02%\n",
      "Epoch [8/50] - Loss: 0.2036 - Train Acc: 92.35% - Test Loss: 0.3797 - Test Acc: 86.98%\n",
      "Epoch [9/50] - Loss: 0.2638 - Train Acc: 89.58% - Test Loss: 0.3342 - Test Acc: 85.42%\n",
      "Epoch [10/50] - Loss: 0.2190 - Train Acc: 93.81% - Test Loss: 0.5041 - Test Acc: 86.46%\n",
      "Epoch [11/50] - Loss: 0.2753 - Train Acc: 92.18% - Test Loss: 0.4595 - Test Acc: 87.50%\n",
      "Epoch [12/50] - Loss: 0.2209 - Train Acc: 91.69% - Test Loss: 0.4952 - Test Acc: 83.33%\n",
      "Epoch [13/50] - Loss: 0.2577 - Train Acc: 94.30% - Test Loss: 0.4457 - Test Acc: 88.02%\n",
      "Epoch [14/50] - Loss: 0.1139 - Train Acc: 96.42% - Test Loss: 0.3432 - Test Acc: 92.19%\n",
      "Epoch [15/50] - Loss: 0.2508 - Train Acc: 94.46% - Test Loss: 0.3472 - Test Acc: 86.46%\n",
      "Epoch [16/50] - Loss: 0.1413 - Train Acc: 94.79% - Test Loss: 0.3062 - Test Acc: 86.46%\n",
      "Epoch [17/50] - Loss: 0.1317 - Train Acc: 96.58% - Test Loss: 0.4494 - Test Acc: 89.06%\n",
      "Epoch [18/50] - Loss: 0.0881 - Train Acc: 96.42% - Test Loss: 0.6453 - Test Acc: 85.94%\n",
      "Epoch [19/50] - Loss: 0.1124 - Train Acc: 96.74% - Test Loss: 0.3324 - Test Acc: 91.67%\n",
      "Epoch [20/50] - Loss: 0.0721 - Train Acc: 97.56% - Test Loss: 0.3170 - Test Acc: 91.67%\n",
      "Epoch [21/50] - Loss: 0.0805 - Train Acc: 97.23% - Test Loss: 0.3639 - Test Acc: 93.23%\n",
      "Epoch [22/50] - Loss: 0.0559 - Train Acc: 97.72% - Test Loss: 0.2804 - Test Acc: 92.71%\n",
      "Epoch [23/50] - Loss: 0.0660 - Train Acc: 97.72% - Test Loss: 0.2398 - Test Acc: 90.62%\n",
      "Epoch [24/50] - Loss: 0.1066 - Train Acc: 96.74% - Test Loss: 0.3126 - Test Acc: 91.67%\n",
      "Epoch [25/50] - Loss: 0.0735 - Train Acc: 97.39% - Test Loss: 0.2653 - Test Acc: 93.23%\n",
      "Epoch [26/50] - Loss: 0.0507 - Train Acc: 98.21% - Test Loss: 0.3328 - Test Acc: 91.15%\n",
      "Epoch [27/50] - Loss: 0.0519 - Train Acc: 98.21% - Test Loss: 0.3761 - Test Acc: 91.15%\n",
      "Epoch [28/50] - Loss: 0.0893 - Train Acc: 97.56% - Test Loss: 0.4157 - Test Acc: 90.10%\n",
      "Epoch [29/50] - Loss: 0.0581 - Train Acc: 98.70% - Test Loss: 0.3914 - Test Acc: 91.15%\n",
      "Epoch [30/50] - Loss: 0.0647 - Train Acc: 97.56% - Test Loss: 0.3166 - Test Acc: 92.19%\n",
      "Epoch [31/50] - Loss: 0.0244 - Train Acc: 98.70% - Test Loss: 0.3339 - Test Acc: 89.58%\n",
      "Epoch [32/50] - Loss: 0.0705 - Train Acc: 98.37% - Test Loss: 0.4398 - Test Acc: 90.10%\n",
      "Epoch [33/50] - Loss: 0.0439 - Train Acc: 98.21% - Test Loss: 0.3890 - Test Acc: 90.62%\n",
      "Epoch [34/50] - Loss: 0.0298 - Train Acc: 99.35% - Test Loss: 0.3719 - Test Acc: 92.19%\n",
      "Epoch [35/50] - Loss: 0.0435 - Train Acc: 98.86% - Test Loss: 0.4304 - Test Acc: 91.15%\n",
      "Epoch [36/50] - Loss: 0.0582 - Train Acc: 98.21% - Test Loss: 0.4639 - Test Acc: 88.54%\n",
      "Epoch [37/50] - Loss: 0.0377 - Train Acc: 98.70% - Test Loss: 0.3765 - Test Acc: 90.62%\n",
      "Epoch [38/50] - Loss: 0.0542 - Train Acc: 99.02% - Test Loss: 0.3970 - Test Acc: 90.62%\n",
      "Epoch [39/50] - Loss: 0.0113 - Train Acc: 99.51% - Test Loss: 0.2929 - Test Acc: 93.75%\n",
      "Epoch [40/50] - Loss: 0.0536 - Train Acc: 98.86% - Test Loss: 0.3648 - Test Acc: 92.19%\n",
      "Epoch [41/50] - Loss: 0.0359 - Train Acc: 98.70% - Test Loss: 0.4259 - Test Acc: 92.71%\n",
      "Epoch [42/50] - Loss: 0.0412 - Train Acc: 98.86% - Test Loss: 0.3488 - Test Acc: 93.23%\n",
      "Epoch [43/50] - Loss: 0.0585 - Train Acc: 98.37% - Test Loss: 0.5652 - Test Acc: 90.62%\n",
      "Epoch [44/50] - Loss: 0.0148 - Train Acc: 99.51% - Test Loss: 0.4315 - Test Acc: 92.19%\n",
      "Epoch [45/50] - Loss: 0.0221 - Train Acc: 99.19% - Test Loss: 0.2633 - Test Acc: 92.71%\n",
      "Epoch [46/50] - Loss: 0.0589 - Train Acc: 98.21% - Test Loss: 0.3736 - Test Acc: 92.71%\n",
      "Epoch [47/50] - Loss: 0.0803 - Train Acc: 98.21% - Test Loss: 0.3826 - Test Acc: 91.15%\n",
      "Epoch [48/50] - Loss: 0.0296 - Train Acc: 98.86% - Test Loss: 0.3157 - Test Acc: 92.19%\n",
      "Epoch [49/50] - Loss: 0.0230 - Train Acc: 99.02% - Test Loss: 0.3132 - Test Acc: 91.67%\n",
      "Epoch [50/50] - Loss: 0.0397 - Train Acc: 99.02% - Test Loss: 0.3406 - Test Acc: 92.71%\n"
     ]
    }
   ],
   "source": [
    "#all final improved STABLE 90S\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "    transforms.ToTensor(),  # Convert to tensor first\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),  # Apply RandomErasing after ToTensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hybrid Model with Attention-based Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\", add_pooling_layer=False)\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.attention_weights = nn.Linear(feature_dim, 1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        attention_scores = torch.sigmoid(self.attention_weights(fused_features))\n",
    "        weighted_features = fused_features * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Loss: {avg_test_loss:.4f} - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step(avg_test_loss)\n",
    "\n",
    "# Initialize and train model\n",
    "model = HybridModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae28dbb-b426-4785-8278-66e38e3b7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"hybrid_model_stable.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df2822-20ff-4483-82a8-2d00f0023e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb03e0-f779-482d-b7d7-e75728d0ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb97fb-6871-4ffa-84f7-dad47bb62e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825a7de-0253-4c18-9b96-518a0e65116e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2024f-1925-4425-8ffd-0e827b2c85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63b5c3-e0b3-4581-9734-7c7c08b8a6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc5364-db20-4ac6-a55b-5d0e1c2997b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f47e9-6a09-478d-9b36-ecf76caa02b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11f72b-19b4-494b-8db1-5ce485c3c80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5be17-b5de-41e2-aa93-e9a6c31ba2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c21e60-e843-4b45-bb32-9a49ac26f2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15fc40-4916-4217-89bd-981ead20bb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db15f13-5405-40a7-b6d5-cc41e7a75317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c043e0-20ff-4ef5-aca4-ea28e8e1e2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab7bc27-a980-41dd-93a3-ef5703d1a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.6124 - Train Acc: 78.50% - Test Loss: 2.1411 - Test Acc: 60.94%\n",
      "Epoch [2/50] - Loss: 0.3689 - Train Acc: 84.36% - Test Loss: 0.5536 - Test Acc: 87.50%\n",
      "Epoch [3/50] - Loss: 0.3448 - Train Acc: 88.44% - Test Loss: 0.3465 - Test Acc: 83.33%\n",
      "Epoch [4/50] - Loss: 0.2550 - Train Acc: 91.86% - Test Loss: 0.6841 - Test Acc: 77.60%\n",
      "Epoch [5/50] - Loss: 0.2697 - Train Acc: 91.86% - Test Loss: 0.2776 - Test Acc: 92.19%\n",
      "Epoch [6/50] - Loss: 0.2256 - Train Acc: 92.18% - Test Loss: 0.3685 - Test Acc: 85.94%\n",
      "Epoch [7/50] - Loss: 0.1963 - Train Acc: 92.18% - Test Loss: 0.3147 - Test Acc: 90.62%\n",
      "Epoch [8/50] - Loss: 0.2103 - Train Acc: 94.30% - Test Loss: 0.2565 - Test Acc: 90.10%\n",
      "Epoch [9/50] - Loss: 0.1533 - Train Acc: 95.28% - Test Loss: 0.3526 - Test Acc: 90.10%\n",
      "Epoch [10/50] - Loss: 0.1417 - Train Acc: 94.63% - Test Loss: 0.3366 - Test Acc: 91.15%\n",
      "Epoch [11/50] - Loss: 0.1214 - Train Acc: 94.79% - Test Loss: 0.2848 - Test Acc: 89.58%\n",
      "Epoch [12/50] - Loss: 0.1928 - Train Acc: 95.60% - Test Loss: 0.3281 - Test Acc: 90.62%\n",
      "Epoch [13/50] - Loss: 0.1424 - Train Acc: 93.97% - Test Loss: 0.2907 - Test Acc: 89.06%\n",
      "Epoch [14/50] - Loss: 0.1000 - Train Acc: 96.25% - Test Loss: 0.3941 - Test Acc: 90.62%\n",
      "Epoch [15/50] - Loss: 0.1381 - Train Acc: 96.42% - Test Loss: 0.4104 - Test Acc: 91.15%\n",
      "Epoch [16/50] - Loss: 0.1406 - Train Acc: 95.77% - Test Loss: 0.6845 - Test Acc: 81.25%\n",
      "Epoch [17/50] - Loss: 0.1989 - Train Acc: 93.49% - Test Loss: 0.4252 - Test Acc: 90.10%\n",
      "Epoch [18/50] - Loss: 0.1723 - Train Acc: 93.65% - Test Loss: 0.3078 - Test Acc: 90.62%\n",
      "Epoch [19/50] - Loss: 0.1694 - Train Acc: 94.46% - Test Loss: 0.5093 - Test Acc: 85.94%\n",
      "Epoch [20/50] - Loss: 0.2343 - Train Acc: 93.16% - Test Loss: 0.4609 - Test Acc: 88.02%\n",
      "Epoch [21/50] - Loss: 0.1513 - Train Acc: 95.93% - Test Loss: 0.5077 - Test Acc: 86.98%\n",
      "Epoch [22/50] - Loss: 0.1674 - Train Acc: 93.81% - Test Loss: 0.2944 - Test Acc: 90.10%\n",
      "Epoch [23/50] - Loss: 0.1609 - Train Acc: 93.32% - Test Loss: 0.3043 - Test Acc: 90.10%\n",
      "Epoch [24/50] - Loss: 0.1914 - Train Acc: 94.95% - Test Loss: 0.4775 - Test Acc: 90.62%\n",
      "Epoch [25/50] - Loss: 0.1417 - Train Acc: 95.77% - Test Loss: 0.3280 - Test Acc: 92.71%\n",
      "Epoch [26/50] - Loss: 0.1079 - Train Acc: 95.44% - Test Loss: 0.2869 - Test Acc: 89.06%\n",
      "Epoch [27/50] - Loss: 0.1088 - Train Acc: 96.42% - Test Loss: 0.2532 - Test Acc: 91.15%\n",
      "Epoch [28/50] - Loss: 0.0844 - Train Acc: 97.07% - Test Loss: 0.3204 - Test Acc: 91.67%\n",
      "Epoch [29/50] - Loss: 0.1113 - Train Acc: 96.74% - Test Loss: 0.3107 - Test Acc: 91.15%\n",
      "Epoch [30/50] - Loss: 0.0610 - Train Acc: 98.37% - Test Loss: 0.4233 - Test Acc: 93.23%\n",
      "Epoch [31/50] - Loss: 0.1523 - Train Acc: 96.74% - Test Loss: 0.2862 - Test Acc: 93.75%\n",
      "Epoch [32/50] - Loss: 0.0719 - Train Acc: 97.23% - Test Loss: 0.2893 - Test Acc: 92.71%\n",
      "Epoch [33/50] - Loss: 0.1650 - Train Acc: 97.56% - Test Loss: 0.3695 - Test Acc: 90.62%\n",
      "Epoch [34/50] - Loss: 0.0861 - Train Acc: 97.88% - Test Loss: 0.3952 - Test Acc: 91.67%\n",
      "Epoch [35/50] - Loss: 0.0976 - Train Acc: 97.07% - Test Loss: 0.4922 - Test Acc: 91.67%\n",
      "Epoch [36/50] - Loss: 0.0400 - Train Acc: 99.02% - Test Loss: 0.4734 - Test Acc: 94.79%\n",
      "Epoch [37/50] - Loss: 0.0729 - Train Acc: 98.05% - Test Loss: 0.5899 - Test Acc: 89.58%\n",
      "Epoch [38/50] - Loss: 0.1138 - Train Acc: 96.09% - Test Loss: 0.8668 - Test Acc: 89.06%\n",
      "Epoch [39/50] - Loss: 0.1740 - Train Acc: 94.95% - Test Loss: 0.5345 - Test Acc: 90.10%\n",
      "Epoch [40/50] - Loss: 0.1442 - Train Acc: 94.95% - Test Loss: 0.3810 - Test Acc: 91.67%\n",
      "Epoch [41/50] - Loss: 0.1512 - Train Acc: 95.44% - Test Loss: 0.4440 - Test Acc: 89.06%\n",
      "Epoch [42/50] - Loss: 0.1517 - Train Acc: 96.42% - Test Loss: 0.3873 - Test Acc: 91.15%\n",
      "Epoch [43/50] - Loss: 0.1349 - Train Acc: 95.77% - Test Loss: 0.6831 - Test Acc: 93.75%\n",
      "Epoch [44/50] - Loss: 0.1225 - Train Acc: 96.42% - Test Loss: 0.2535 - Test Acc: 93.23%\n",
      "Epoch [45/50] - Loss: 0.0687 - Train Acc: 97.72% - Test Loss: 0.3947 - Test Acc: 91.15%\n",
      "Epoch [46/50] - Loss: 0.0831 - Train Acc: 97.56% - Test Loss: 0.2336 - Test Acc: 91.67%\n",
      "Epoch [47/50] - Loss: 0.2800 - Train Acc: 95.60% - Test Loss: 0.2601 - Test Acc: 91.67%\n",
      "Epoch [48/50] - Loss: 0.0411 - Train Acc: 98.37% - Test Loss: 0.5446 - Test Acc: 90.62%\n",
      "Epoch [49/50] - Loss: 0.0575 - Train Acc: 98.70% - Test Loss: 0.3474 - Test Acc: 91.67%\n",
      "Epoch [50/50] - Loss: 0.0503 - Train Acc: 98.37% - Test Loss: 0.3698 - Test Acc: 92.71%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       117\n",
      "           1       0.91      0.91      0.91        75\n",
      "\n",
      "    accuracy                           0.93       192\n",
      "   macro avg       0.92      0.92      0.92       192\n",
      "weighted avg       0.93      0.93      0.93       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#heavily improvised 93pct saved with stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hybrid Model with Advanced Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\", add_pooling_layer=False)\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        \n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, batch_first=True)\n",
    "        \n",
    "        self.attention_weights = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        attn_output, _ = self.cross_attention(fused_features.unsqueeze(1), fused_features.unsqueeze(1), fused_features.unsqueeze(1))\n",
    "        attn_output = attn_output.squeeze(1)\n",
    "        \n",
    "        attention_scores = torch.sigmoid(self.attention_weights(attn_output))\n",
    "        weighted_features = attn_output * attention_scores\n",
    "        \n",
    "        weighted_features = self.batch_norm(weighted_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        running_test_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "                all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Loss: {avg_test_loss:.4f} - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "    \n",
    "    torch.save(model.state_dict(), \"hybrid_model.pth\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Initialize and train model\n",
    "model = HybridModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c7b2b-4a65-4c96-92d9-e0df174fc8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1bf571-a2fd-40b7-8a1c-1066cb2360aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d43ca-9512-4f50-81b4-3089a667a80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc0bf1-1145-4c13-9a32-592f711c48fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b157c3d-122d-4c0c-b23c-7c773483a5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca62873-0292-4e2a-a4e1-595efa01e707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61a656-09a3-4f8c-9769-0ff6b161ec28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d7561-11e3-4cbc-a5f0-ab18cbbba6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7047819-da81-4b24-bbae-a22ffde94047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2410a2-1a4b-4a54-b67c-485a2897acbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd906ab-9b89-4a14-ae83-251190a55dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431364-c45d-48f5-be78-ca3bccf6d257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a693773-4c1c-4c4e-998c-5eef1446e6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2cf0d-c3ba-456f-954d-d8655400b832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3612ea53-16e5-4511-8765-fc35cb7bba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.8787 - Train Acc: 77.36% - Test Loss: 0.6913 - Test Acc: 70.83%\n",
      "Epoch [2/50] - Loss: 0.4039 - Train Acc: 83.71% - Test Loss: 0.3116 - Test Acc: 86.46%\n",
      "Epoch [3/50] - Loss: 0.3205 - Train Acc: 86.16% - Test Loss: 0.2722 - Test Acc: 89.58%\n",
      "Epoch [4/50] - Loss: 0.2755 - Train Acc: 89.58% - Test Loss: 0.3223 - Test Acc: 85.42%\n",
      "Epoch [5/50] - Loss: 0.2383 - Train Acc: 90.88% - Test Loss: 0.3468 - Test Acc: 86.98%\n",
      "Epoch [6/50] - Loss: 0.2814 - Train Acc: 87.62% - Test Loss: 0.3247 - Test Acc: 87.50%\n",
      "Epoch [7/50] - Loss: 0.1586 - Train Acc: 93.32% - Test Loss: 0.2752 - Test Acc: 88.02%\n",
      "Epoch [8/50] - Loss: 0.1765 - Train Acc: 91.86% - Test Loss: 0.3134 - Test Acc: 85.42%\n",
      "Epoch [9/50] - Loss: 0.3076 - Train Acc: 91.04% - Test Loss: 0.3870 - Test Acc: 85.42%\n",
      "Epoch [10/50] - Loss: 0.2230 - Train Acc: 91.86% - Test Loss: 0.3073 - Test Acc: 90.62%\n",
      "Epoch [11/50] - Loss: 0.1510 - Train Acc: 93.16% - Test Loss: 0.2928 - Test Acc: 89.06%\n",
      "Epoch [12/50] - Loss: 0.1629 - Train Acc: 94.79% - Test Loss: 0.2326 - Test Acc: 90.10%\n",
      "Epoch [13/50] - Loss: 0.1596 - Train Acc: 95.44% - Test Loss: 0.3012 - Test Acc: 90.62%\n",
      "Epoch [14/50] - Loss: 0.1118 - Train Acc: 95.93% - Test Loss: 0.3596 - Test Acc: 90.62%\n",
      "Epoch [15/50] - Loss: 0.1185 - Train Acc: 95.44% - Test Loss: 0.3142 - Test Acc: 89.58%\n",
      "Epoch [16/50] - Loss: 0.1238 - Train Acc: 96.74% - Test Loss: 0.2776 - Test Acc: 90.10%\n",
      "Epoch [17/50] - Loss: 0.0940 - Train Acc: 97.07% - Test Loss: 0.3094 - Test Acc: 91.67%\n",
      "Epoch [18/50] - Loss: 0.1158 - Train Acc: 95.60% - Test Loss: 0.3019 - Test Acc: 85.94%\n",
      "Epoch [19/50] - Loss: 0.0974 - Train Acc: 96.09% - Test Loss: 0.4009 - Test Acc: 84.90%\n",
      "Epoch [20/50] - Loss: 0.1019 - Train Acc: 96.42% - Test Loss: 0.2478 - Test Acc: 91.67%\n",
      "Epoch [21/50] - Loss: 0.0671 - Train Acc: 97.23% - Test Loss: 0.3522 - Test Acc: 90.62%\n",
      "Epoch [22/50] - Loss: 0.0969 - Train Acc: 97.23% - Test Loss: 0.2313 - Test Acc: 89.06%\n",
      "Epoch [23/50] - Loss: 0.0776 - Train Acc: 97.56% - Test Loss: 0.2465 - Test Acc: 90.10%\n",
      "Epoch [24/50] - Loss: 0.0589 - Train Acc: 98.37% - Test Loss: 0.3638 - Test Acc: 88.02%\n",
      "Epoch [25/50] - Loss: 0.1012 - Train Acc: 96.09% - Test Loss: 0.3384 - Test Acc: 88.02%\n",
      "Epoch [26/50] - Loss: 0.0529 - Train Acc: 98.86% - Test Loss: 0.2850 - Test Acc: 90.10%\n",
      "Epoch [27/50] - Loss: 0.0777 - Train Acc: 97.72% - Test Loss: 0.3710 - Test Acc: 89.06%\n",
      "Epoch [28/50] - Loss: 0.0753 - Train Acc: 97.39% - Test Loss: 0.2887 - Test Acc: 90.62%\n",
      "Epoch [29/50] - Loss: 0.0785 - Train Acc: 97.07% - Test Loss: 0.3068 - Test Acc: 89.06%\n",
      "Epoch [30/50] - Loss: 0.0527 - Train Acc: 98.21% - Test Loss: 0.2150 - Test Acc: 93.23%\n",
      "Epoch [31/50] - Loss: 0.0648 - Train Acc: 97.88% - Test Loss: 0.2937 - Test Acc: 88.02%\n",
      "Epoch [32/50] - Loss: 0.0416 - Train Acc: 98.86% - Test Loss: 0.2497 - Test Acc: 90.62%\n",
      "Epoch [33/50] - Loss: 0.0448 - Train Acc: 98.21% - Test Loss: 0.3290 - Test Acc: 91.15%\n",
      "Epoch [34/50] - Loss: 0.0539 - Train Acc: 97.56% - Test Loss: 0.3614 - Test Acc: 90.10%\n",
      "Epoch [35/50] - Loss: 0.0461 - Train Acc: 98.53% - Test Loss: 0.2551 - Test Acc: 94.27%\n",
      "Epoch [36/50] - Loss: 0.0600 - Train Acc: 97.88% - Test Loss: 0.3142 - Test Acc: 90.62%\n",
      "Epoch [37/50] - Loss: 0.0693 - Train Acc: 98.53% - Test Loss: 0.2272 - Test Acc: 91.67%\n",
      "Epoch [38/50] - Loss: 0.0516 - Train Acc: 98.53% - Test Loss: 0.3278 - Test Acc: 91.15%\n",
      "Epoch [39/50] - Loss: 0.0442 - Train Acc: 98.37% - Test Loss: 0.2625 - Test Acc: 91.15%\n",
      "Epoch [40/50] - Loss: 0.0767 - Train Acc: 98.37% - Test Loss: 0.2541 - Test Acc: 93.23%\n",
      "Epoch [41/50] - Loss: 0.0383 - Train Acc: 99.02% - Test Loss: 0.2095 - Test Acc: 94.27%\n",
      "Epoch [42/50] - Loss: 0.0304 - Train Acc: 99.19% - Test Loss: 0.2323 - Test Acc: 91.67%\n",
      "Epoch [43/50] - Loss: 0.0533 - Train Acc: 97.72% - Test Loss: 0.3249 - Test Acc: 92.19%\n",
      "Epoch [44/50] - Loss: 0.0445 - Train Acc: 98.37% - Test Loss: 0.2687 - Test Acc: 91.15%\n",
      "Epoch [45/50] - Loss: 0.0357 - Train Acc: 98.86% - Test Loss: 0.3034 - Test Acc: 92.19%\n",
      "Epoch [46/50] - Loss: 0.0595 - Train Acc: 97.88% - Test Loss: 0.2903 - Test Acc: 89.06%\n",
      "Epoch [47/50] - Loss: 0.0968 - Train Acc: 99.19% - Test Loss: 0.2895 - Test Acc: 91.15%\n",
      "Epoch [48/50] - Loss: 0.0358 - Train Acc: 98.53% - Test Loss: 0.3596 - Test Acc: 91.67%\n",
      "Epoch [49/50] - Loss: 0.1358 - Train Acc: 98.37% - Test Loss: 0.2764 - Test Acc: 91.15%\n",
      "Epoch [50/50] - Loss: 0.0330 - Train Acc: 98.86% - Test Loss: 0.2640 - Test Acc: 90.62%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgj1JREFUeJztnQd4FHXXxU8aCQmh9957kyLSVRBERFDsDUWxYe9+dsUX9fW19wYqWFARxYYUqdJ779J7SYCQvt9z/pPZbELKbrKb3WzO73mWnW2zs5Nl58y9594b4nA4HBBCCCGECCBC/b0BQgghhBDZkUARQgghRMAhgSKEEEKIgEMCRQghhBABhwSKEEIIIQIOCRQhhBBCBBwSKEIIIYQIOCRQhBBCCBFwSKAIIYQQIuCQQBFCCCFEwCGBIkSA8/777yMkJARdunTx96YUSw4cOICHH34YzZs3R3R0NGJiYtCxY0eMGjUKx48f9/fmCSFyIUSzeIQIbLp37469e/fi33//xebNm9G4cWN/b1KxYfHixbjoootw8uRJXH/99UaYkCVLluDbb79Ft27d8Ndff/l7M4UQOSCBIkQAs337djRs2BATJ07E7bffjpEjR+LZZ59FIHLq1CkTnQgUGB1p3bo1UlNTMXPmTBNByR5Z+eSTT/DUU08F3WcXIhhQikeIAGb8+PGoUKECBg4ciMsvv9zczu1g/MADD6B+/fqIjIxE7dq1ceONN+Lw4cPO5yQmJuK5555D06ZNERUVhRo1auCyyy7D1q1bzeM8iDOVxGtXGLnh/WPHjnXed9NNN6FMmTLmtYxQxMbG4rrrrjOPzZkzB1dccQXq1q1rtqVOnTpm206fPn3Gdm/YsAFXXnklqlSpgtKlS6NZs2Z48sknzWN///23ed+ffvrpjNd9/fXX5rH58+fnuu8++ugj7NmzB6+//voZ4oRUq1Ytizjh+rh/ssN9ys9rw/3A586aNQt33XUXqlatavb3Dz/84Lw/p23hY2vWrMny2fk3rVixovl7dOrUCb/88kuun0eIkka4vzdACJE7FCQUEaVKlcI111yDDz74wKQtOnfu7HwO0xc9e/bE+vXrMXz4cHTo0MEIEx7sdu/ejcqVKyMtLQ0XX3wxpk+fjquvvhr33XcfTpw4galTp5qDZqNGjTzeNkYm+vfvjx49euC1114z/g7y/fffIyEhAXfeeScqVaqERYsW4Z133jHbwsdsVq1aZbY7IiICt912mxECFDyTJ0/GSy+9hHPPPdeIG+6DSy+99Iz9wm3u2rVrrtvHz0/RQxHgCyhOKKyeeeYZE0GhiKRomzBhAnr37p3lud999x1atWplIjpk7dq1JnVXq1YtPP744yb6wtcNGTIEP/744xmfV4gSCVM8QojAY8mSJUy/OqZOnWpup6enO2rXru247777sjzvmWeeMc+bOHHiGevga8jnn39unvP666/n+py///7bPIfXrmzfvt3cP2bMGOd9w4YNM/c9/vjjZ6wvISHhjPtGjx7tCAkJcezYscN5X69evRyxsbFZ7nPdHvLEE084IiMjHcePH3fed/DgQUd4eLjj2WefdeRFhQoVHO3atXO4Cz9PTuusV6+e+bw23A98bo8ePRypqalZnnvNNdc4qlatmuX+ffv2OUJDQx0vvPCC874+ffo42rRp40hMTMzyubt16+Zo0qSJ29ssRDCjFI8QAQqjBExDnHfeeeY2UwRXXXWVMXcyImLDM+527drleNbN19jPYSTlnnvuyfU5BYFRkuwwamHDyAKjOTSjUgMsX77c3H/o0CHMnj3bRHyYCspte5imSkpKMukT12gEozc0veZFfHy8ST35ihEjRiAsLCzLffz7HDx4MEuajNuenp5uHiNHjx7FjBkzTGqLUSzuH16OHDliIlI0QjM1JURJRwJFiACEAoRChOKERtktW7aYC0uNae5kqsaGaRE7dZAbfA79HeHh3svqcl30XmRn586dxrNBbwVTHkyD2CmPuLg4c71t2zZznd920zvCdJar94bL55xzTr7VTGXLljUCwFc0aNDgjPsuvPBClCtXzogoGy63b9/eeH8I/44Ua08//bTZN64X2wBNkSNESUceFCECEJ5h79u3z4gUXrLDg3S/fv28+p65RVJcozWu0AAbGhp6xnMvuOACEyV47LHHjMCgv4IRAYoWRhI8hVEUemboYWE0ZcGCBXj33XfzfR3fe8WKFUhOTjYenoKS2+d3jRS57hP6SGjsZf8aisl58+bhP//5j/M59j5gbxZGTHJCpeRCSKAIEZBQgLA65L333jvjMZYc8wD44YcfmoMkzaKu1SE5wecsXLgQKSkpxpSaE6wWItmbl+3YscPt7V69ejU2bdqEL774wggLG5pxXWHpNMlvuwlNvQ8++CC++eYbUwnE7bfTJXkxaNAgU+XD9BYNxvnBz5/9s1PcUCh6AreNn59RLhqXGS1x3V77s/Nz9O3b16N1C1GSUIpHiACDB2GKEFbdsAIl++Xuu+82qQu7JHXo0KFYuXJljuW4dpsjPoc+h5wiD/Zz6tWrZzwV9Ia4wkiAu9ieDNf2Slx+6623sjyP6YxevXrh888/NymhnLbHht6ZAQMGYNy4cUa4MY3C+/LjjjvuMKXUDz30kBFN2WEahd1kXUVc9s/+8ccf5xpByQ2KDqa3mNrh5eyzz86SDqLwZIUSS49zEj/05wghFEERIuCg8KAAueSSS3J8nP4LHuB5sOaZ+SOPPGKMmOw9QtMpu6UyxcL1MMpCAy2jGV9++aWJRLDsl+W9NLBOmzbNlMsOHjzYeCe4DpYEM93DA/avv/7qkR+CaRW+jukLpnXoA2EE49ixY2c89+233zYlyiyLZpkxD+LsufLbb7+Z1Iwr3H67XPjFF190a1sYEaFoY58WekBcO8kuW7bMRGRcy5RvvfVWI2oo5pimouibMmWKW2LIFUZGWBrO1Bz3MUuws8PIGD97mzZtjNmWURWmgxjxYSqL7y1EicffZURCiKwMGjTIERUV5Th16lSuz7npppscERERjsOHD5vbR44ccdx9992OWrVqOUqVKmXKkVkaaz9ul/8++eSTjgYNGpjXVq9e3XH55Zc7tm7d6nzOoUOHHEOHDnVER0ebMt3bb7/dsWbNmhzLjGNiYnLctnXr1jn69u3rKFOmjKNy5cqOESNGOFauXHnGOgjXfemllzrKly9vPnOzZs0cTz/99BnrTEpKMttTrlw5x+nTpz3an3v37nU88MADjqZNm5r34Gfr2LGj46WXXnLExcU5n5eWluZ47LHHzDbzOf3793ds2bIl1zLjxYsX5/qeLA3nc1havWvXrhyfw/1+4403mr8D/x7821188cWOH374waPPJ0Swolb3QoiAh2XFNWvWNL6Szz77zN+bI4QoAuRBEUIEPJMmTTLeDFfjrRAiuFEERQgRsLDyiC3x6TuhF4TeESFEyUARFCFEwMLZQ+xWy8oXmnyFECUHRVCEEEIIEXAogiKEEEKIgEMCRQghhBABR7Fs1MZZFnv37jWTSgsziVUIIYQQRQddJWxEybYB2Wd5BYVAoTipU6eOvzdDCCGEEAVg165dOU5DL/YChZET+wOylbYQQgghAp/4+HgTYLCP40EnUOy0DsWJBIoQQghRvHDHnuGxSZbTPtlumvkjvgE7PGbPLz3zzDNmiihHwXOy5+bNm7M8h4PMrrvuOiMuypcvj1tuuQUnT570dFOEEEIIEaR4LFA4nZPTUTmNMydeffVVM6WUU1TZBTImJgb9+/dHYmKi8zkUJ2vXrsXUqVPNtFSKHk4zFUIIIYQodKM2RlA4znzIkCHmNlfFyMpDDz1kxq2TuLg4VKtWDWPHjsXVV1+N9evXo2XLlli8eDE6depknvPnn3+akegcM87Xu5PD4mh4rlspHiGEEKJ44Mnx26t9ULZv3479+/ebtI4NN6RLly6YP3++uc1rpnVscUL4fJYbMeKSE0lJSeZDuV6EEEIIEbx4VaBQnBBGTFzhbfsxXnOuhivh4eGoWLGi8znZGT16tBE69kUlxkIIIURwUyw6yT7xxBMmHGRfWF4shBBCiODFqwKlevXq5vrAgQNZ7udt+zFeHzx4MMvjqampprLHfk52IiMjnSXFKi0WQgghgh+vCpQGDRoYkTF9+nTnffSL0FvStWtXc5vXx48fx9KlS53PmTFjhmlfT6+KEEIIIYTHjdrYr2TLli1ZjLErVqwwHpK6devi/vvvx6hRo9CkSRMjWJ5++mlTmWNX+rRo0QIXXnghRowYYUqRU1JScPfdd5sKH3cqeIQQQggR/HgsUJYsWYLzzjvPefvBBx8018OGDTOlxI8++qjplcK+JoyU9OjRw5QRR0VFOV8zfvx4I0r69OljqneGDh1qeqcIIYQQQhS6D4q/UB8UIYQQovjhtz4oQgghhBDeoFgOCxRCCCE84cjJJKzaHYfVe+LQskZZ9G2ZtV9XoDN55V6UCg9F/1Y5V7sGIxIoQgghgopTSalYsycOK3cfx8rdcVi56zh2HzvtfDwsNATTHuyNBpVjUBz4e+NB3PPNcrN8Y9d6eObilggPC/4EiASKEEKIYs/xhGS8MXUTFm4/ik0HTiA9B3dloyoxSEt34N8jCfjfXxvx7rUdEOgkpabh+V/WOm9/OX8Hth8+Zba9XOkIBDMSKEIIIYo1Ww+dxC1jFxvhYVO9bBTa1SmHdnXKo33t8mhduxzKRkVg3d54XPT2HPy6ah/u6B2H1rXKIZD5dM5287mqxEbiiQHN8eRPazBn82Fc9v48fDasM+r7KApEIcdIkz8J/hiREKLYh+v/76fVmLP5EIKN1LR0cyb/6ZxtSM/plF/ky9zNh3Hpe/PMQbxW+dL44LoOWPh/fbDg//rgoxs64a5zG6Nb48pGnJCWNcviknZWz63/Ttno021bsO0IHvl+JdbujSvQ6/ccP413Zmw2y09e1AKXdaiN7+/oihrlorD10CkMeX+eeQ9vs2j7UfR/czb+2XIY/kQCRQgR0ExYsgtfL9yJO75ail1HM8+Qg4FX/tyAd2Zswajf1uOOcUuNGBPuM27BDgwbswjxianoULc8fr67Owa0qYFqZTP7buXEgxc0RXhoCGZtOuSTAzzTTY/+sBJXf7wA3y/djZvGLMaB+ESP1/PSb+uQmJKOs+tXxOD2lqhixOfnkd1NZOh4Qgpu+Gwhvlu80yvbHZeQgsd/XIUrP5qPLQdP4o1pm+BPJFCEEAENDyLkVHIaHvlhZdBEGn5esQefzNluliPCQvDXugO44sP52Hs808wpco88PffLWjw1aY1JRQxpXxNfjzgHlctEuvV6pkWuPruOWX71zw3wVjswrmfS8j3o879ZmLBkt7mvUkwpHDqRhLvGL0NyarpHkaHfV+8HsyzPD26FkJDMdEvVslH47rZzcHHbGkhJc+CxH1cbMcN9UdDt5vexz+sz8e1iaxjvNWfXxac3doY/kUARQgQsiSlpzjNcHsQXbDuKL+b/i+IOfRCP/bjKLN91biN8e1tXVC5TCuv2xWPwe/OwYtdxf29iwBKfmIJbvliCsf9Y34NH+jfDG1e1R1REmEfruff8JoiKCMWynccxbX3WAbYFYceRU7jx80W4/7sVOHIqGU2qlsEPd3TFj3d2Q9mocCzdcQwv/Jppds0LCplnf1ljlm/sWh8tapzZ0Iyf951rzsJ9fZqY2xS7t325BCc9jMIxKjlszGLc9+0KHD6ZjMZVy5g00ujL2qBctH9NuOokK4QIWGZvOmR+9Gl4HHleIzz981pEhofi9/t6olGVMiiOMPw/6N252HX0NHo1rYIxN3U2ZsTdxxJwy9gl2HjghPmMr13RDoMyvBLeYuG2I3hz2mZcd05dXNy24Os+eCIRz0xai00HT+T7XHo/2tYuh7a1y6N9nXJoWLkMQgtovtx5JAG3fLEYmw+eNOLijSvbm5ROYVJsH8zcimbVYs13qiCm0JS0dHwyZxvemrYZSanpplfJvec3xm29Gpll8veGgxj+xWLwaPvq0La4srMVvcmNj2dvxX9+32BE6/SHzs23WueXlXuN14XvX6diafRuWgXtzP4uj4ZVyuT4ubjdn8/dbtI4TCOVCgvF3ec3xu29GyIy3DOx56vjtwSKECJgefHXdfhs7nZc2ak2Xhna1ogVVjDwh5dnp8WtFwRD8DePXWyEFw8kk+/ugfLRpZyP8+z3vm+WY/oG64yeZ8f3922SJbxfUHimfPE7cxF3OsXcvrdPEzxQgHUz+nPrF4uxN85zTwWJjQw3PgpTXVPHEi40fea3HTRu0qdz9FQyqpWNNBUsha3Aoeei56szjIfl9SvbGROqJyzbeQz/N3E1Nuy3hFq3RpXw0qVtcuyv8s70zfjf1E1GCEy4o6v5DucEvSrnvzbTpDT/e3lbXNEpbzFjs3znMdz21VKTTnIlplQY2tTOrGZqW6e8ec4TE1dj/b5485xzGlbEfy5tY8SMr5FAEUL4Ff6svDV9M6asPYBPh3Uy1RUF4YLXZ5mz5feu7YCBbWsYfwarC04kpprQ/sjzGqM4Qb/D+zO3mrP/iXd2NxUlOYmYl/9Y7/Sn0GfAaIqnKQxXTien4bIP/jEHJJar2gcx7tP/ebDuqesO4L5vlyMhOQ0NK8fg2UtaoXQ+r+UBdxUbpu2yurieTkk74zmxUeHmwJ0Xx0+nmH3TplY5853KzwjrLu/P3IJX/9yI2hVKY8ZD5zqjHnlBH9Rrf23EB7O2mqhIhegIPDWwJS7rUCtXocXX3D5uqdmHFGST7+mRo2fm3m+Wm4jIWXXL48c7unkUbaLgmrPlkGlMl9f+tikfHWGqgy7vWNsrItgdJFCEEH7l9amb8Pb0zU6PxaMXNi9QiWX3l2cYk+Dyp/s58+E/Lt2Nh75faTwpP4/skeNBPhD5c80+3DFumVl+6+r2GNy+Vp7PZ2UGe16kpjvM2e8nN3Q05khP4U88fRE/r9hrUgY8MDKC41x37XL45MZOea6b6/h49ja8bAylQI/GlY1o9NSjQHMrBac5gGZ0eGVKy11z58A2llgrXcp7KQiKt97//RsHTyTh+UtaYVi3+nk+n5VWD3y3wpiaCUUJxUnFmMxIWG6cSEwxHqNth06hS4OKGHdrF0S4CDP6rVj5Q60w+e4ehY4QcX9vOZR1fzPaw/196Vnc7hao5Kax2FtIoAgh/MaHs7bi5T82OG/XrRiNWY+c6/EZ2jeLdpowdMd6FYzR0IY/WQxl80y0efVY/HJ3D7fOer3Jb6v2GRPjOQ0rGRNj5/oV8vx8mw+cwJD35pmw/a09GuCpi1u69T7ztx7BneOXmnJSnnUzctCqpmcHLabImCpjWe34W7ugS8NKzoMhUyb2uilScjog0rD55E+rTbksuf6cunh2UKssB9bCCoRdxxKM8MkLRmrqVoqGL/hqwQ48PWmNiWjwuxoTmXMPU0bwaNBlJIrfOfpJhpyVt9DMDst3+V1gOu/m7vXNvrQ9IRe/PdcItuu61DWpIl8ZzymyilqY2GiasRDCL3w1/1+nOKFRkAeVnUcTTKjZU2ZttMqLafhzhUKA+XKesfJs8K3pRdurgZEd9opgxQO7kbJnxIC35pheLQnJqTlWnVBQUZzQo/D4APejSV0bVcKku7qjYZUY7ItLNGXIf63d7/brKXD+8/t6s/zkwBZOcUIorrjuRi7rnpJt3fR7XP/pQiNOGMl6blBLvDi4tdfECWE0pGm1WDSrnvfFV+KEXN25DupVisbhk0kYM89KrWWHlVWMflCcMBL1zYhzPBYnhFUy/7uynVkeM+9f/LTcEn5fzd9hxAnTRUxf+gqm8/wlTjxFAkUI4RV+WLrbVNmQu89rjAf7NcP5Laqa2zyQewLPJudldLFkpUt26KMYNaS1WWYVBg2CRQF9BKyWOJGUalIj15xdx/hJKJTY7bbLf6bjhcnrzKwU+/kPfrfC3KYPh2Whnhp72bPjp7u6m7QKvR/0MTBKlV/wm2f7d3+9zBnOvymH1AXXPfGu7ujZpLLxKjCiwv3JddtRn0X/HjXG1s9v6oybujcoMq9CUULBxeZt5KNZ23DsVHKWx+kJueqj+ca7w6jdpJHdTWSvoHAi8T3nW/6px39cjZkbD5o5QoTpUFfjdElGKR4hhFdSHvd8s8wMaGPYmtNWeSCzfRc8OM997Dy3D26L/z1qzuh5NrnkqQtyLf+kYZPeCho2f7u3p1e9CTnx5fx/8czPa40o+eO+XqZag8bE75fuMmmCHS6zYHjQZ+qEDbuYDqDhkdUUBYWijeKH70NobHzp0tY5loQyjM/IzqrdcWhVsyx+uKNbnvuGXoUXfl1nBtGRvi2qmZJkCjFWG30+rDOaVItFMEMxyRk9FJu392qIJy5qYYQay7Jp+CZ9mlfFW9echTK5pIA8gcKRJdMzMyKFhOXYFKP+noHjS5TiEUIUGTM2WJUdFCcMldvihJzbrKopc2RahA2xPE3v9GxSJc8f6xcuaW1KTrcdPoVXp2T6XnwBoyB2uuSJAS2cpaQ0it7asyH+fuhcjL25M85vXtWYHFkObXcTZUqqMOLEPst/cUhrvDC4ldknjFgx/XLkZNayUh5U6aegOKHA+/D6jvkKN0Z1Xhicue5p6w8YcUJvDdNAwS5OCKtlHsswc7MJ3L+HT+Geb5Y7xcmIng3w8Y2dvCJOCPfzW1edZVJLNvwbBLM48RQJFCFEgeEwMUZIWA3CWSE09rlGSZjv7tequln+ddVej9vbZ/efZIfi4OWhbZ0HFXoufAHPdh+asMI0tKKP5IZz6uV4gKMgYypk1sPn4bZeDU3kiKF8Rju8BU25bO7GtMvif4+ZgXGbDmQ2TBu3cKfTM/LONR1Qp2K0x+um+KJRk1UmxcWv4A3ObVbFiDI2PLvwrdkmNUlz8StD2+DJgS29Lh74/f3oho7GY8RGhLn1RimpKMUjhCgQS3ccxQ2fLTK+iH4tq+G96zrkaJ6cvv6AqXyoGhuJ+U/0yfdHnkbFTqOmmeVFT/ZB1dj8S2tZ7cOqH3ZgHdK+Fm7oWq/QJZo5VSbx7HnKA70K3NfFm2w5eALDxy4xJmSKlXeutVIPLFOlYHxiQHPc3ruRvzez2GGnF+0+IYxA0VAsvINSPEIIn8LGW5zQSnFCrwUPjrlVdjBNw1kk7DPBH//8mLPZip60rFHWLXFiV6jYZ77fLdllOqZe9v48MwDNkwFtObFhfzxe/8syMD4zqGVAiBPSuKpl1jy7QUWTjhk+drERghQnbMDGCI7wnM71K5rePYzeMb0lceI/vJNME0IEPQy2zttyxAzrY1SEnhOOgf/4hk55zu6gQZRVC0w7MM2T3w/+7E1W9U7vZnmnd1xh5GDC7V3NQDYaPf9Ys894XpbtXIEXy6zD1Z3r4toudVHTQ3FBcfPQhJVITks3BskrvJiq8QYstR53SxdnnxK2sedcGfbnCMZqm6KiII0FhfeRQBFC5An7eLB7K6tH2AHThgfsN69u71blzMXtapoD6B+r9+O5Qa1yLbVlJQW7nLrjP8kOD8id6lc0l4MnWuDbRbtMb5L98Yl49+8tpi35BS2q4cZu9dC1YSW3DuB83dq98SbUP3poVn9NoGAahl3e1qS0uO/Y+Cu3RmNCFCf0LRZC5MjG/SdMWe1Py/eYVI4dqRjawfJ4MMXgLjSW8myfY+gXbDuKHk0q5/g8igE+h+/ToW7B+0wwNcRheHee28h0nOXn4Pv+uXa/uTSpWsZ8Bg6Hy60qg23B3/t7i1lmzxV3003+gMKJLdrza9MuRHFCAkWIEgIrUWZsOIiDJ/KeQpuSmo4/1uzHwu2ZfhEe0G/sWg+X5nFAzwv6Uy5sXd1ENJjmyU2gzNp00ClovNG+nu97UZsa5kLB9dWCfzFx2R4zD4b9TDgkjrNUbswmuNhHhPN+uM8GtauJi9vWLPS2CCE8QwJFiBIAUyeP/bjK9M5wF1bbsDqHkQZ3UyJ5wam8FCgUP+z3kJMAscuLc+oeW1jYLn3UkDbGXzBx6W58mZGyomeFF4oiltn2bVEV//tro5mZwo61L1xizUoRQhQtEihC+AAO42Kzq0ZVyni13LWg5tbnJ6814oSi47xmVZFft/Vm1cuaNu41ynmvYqVLg0rmgM924Wxjf15zqw2+q9fFbubmqf/EE8pGRZiW7UyH/LP1CL7451/zt+IyL9XLRuFARpSJ/S8quDGlVgjhfSRQhPAiWw+dNEO/aCpl6Sf7U8x69Dy3RrH7Spy88udGfDF/h+lu+toVbXHpWf6pRKE4uqh1dbMtk1ftPUOgsOkbUypsWuVJc7GCwohQ98aVzYWdbscv2IFvF+8yplpyVac6OL95NZ9vhxAiZyRQhCgkPKiy7JZVLmxvbsN+ZBQpH8zcYrpQ+gOaPNlkjLw0pI3fxIlrNQ8FytS1B4zPg51mPe0e6wvY24SpHxprf1+9z8zUUR8RIfyLBIoQBYQzUNgUbPyCneYMnDBKwfLbG7rWN76Pm8cuNgfkm7s38LgHR2H5bO52vJbRYOypgS1MHxB/07FuBTNAb19coimJtdvgM9Jjz9/xhf/EXSiYWNkjhPA/EihCeMjJpFS8MHktJq3Y6+xSyqFsV3aug+u71HOmJ3jQ7dKgoqmGeXv6ZufMmKKAbd9f/HWdWeYYeQ6zCwQ4r2Zgmxr4dO52M+fEFig0pO6NSzTG2XMaqHOnEEKt7oXwmFf+2GCm1FKccDz6a1e0MzNmOOHW1TtBj4PdkXLCkl3mIFwUsL37//202izf3ruhGVYXSDDNQ2hMPZ3RX8VO71DQudP4TQgR/EigCOEBa/bEYfzCHWaZU0h/ubuHmVTr6qVwpWO9CujbopppC//61I0+374pa/fjwQkrwRGgnLj7+IXNA677abva5VCnYmnT/I19WfztPxFCBCYSKEK4CT0lz/y8xogNNu/ifBl3eKR/M+NN+X31fjNkz1fwIH/P18uNaXdoh9p4/pJWASdOCLdpYBsrisKmbYyi2E3hOO5eCCGIBIoQbjJx+R7TpyO6VBj+76LmHjUIu7R9LbP83ynej6Kwf8jnc7fj9q+WmKF29Hiwfwf9HoHKoHY1zDUjKNM3HDDpsprlokzfGCGEIDLJCuGmCHj5j/VmmaWonjYwe+CCpqb3B8uQ2e+jW+OcW70XdlbO+c2r4o2r2uc6jC9QaFmjLBpWjsG2w6cw+vcNzunFgRjxEUL4BwkUIdzgjambcPhksmkiNrx7A49fT/PstWfXNSXHr0zZiEmNCtY6PiUt3fhM2Jp9UfZZOd3qm+Zi3phh42v42dn6/u0ZW5wl2vKfCCFckUARIh827I83goDQ11FQAXD3+U3w/dLdZkrulLUHzPA8dzkYn4ivF+005cMH4pOcnVn7t6qGG86pj3MaVix20QdW81Cg2J/FG1ElIUTwIIEiRB6wlwmn3tJ4OqB1dfRsUvCzfM6hYfTl3b+34LW/NuKCltXMgTkv4k6n4L9TNuDbRbuQSncugMplInHt2XVwTZe6Xp2VU9Q0rRaLptXKYNOBk6aBG2fkCCGEjQSKEHnwy8q9JpUSFRGKpy4ufLv623o3xLiFO0xPlInLduOKTnVyFUas+nlu8lozXM8uWb6xaz0MaF2jWKRx3IHTg5+atAaXdbBMxEIIYSOBIkoETJG8+Nt6LN95zJhcr+hYO9+UCDvG/ud3yxh793mNzbyWwsIowV3nNsJ/ft+AN6dtNuXK2Xuo7D6WYKI2do8QmklHXdoa3RoFXwrkui510a9VNVQpE+nvTRFCBBjBcRomRB69SzjEr8//ZmHyyr3Yfew0Hv1hFa75ZIGZPJwXbE9Pv0f9StEY4cXBcYwaVC8bZU3QXbjTeX9qWjo+nbMNF7w+24iTUmGhuK9PE/xxf8+gFCeEIrFqbFSx888IIXyPBIoIWliGe/mH/+DpSWvMVGF2MGX0hOmaBduOYsCbc/DWtM1ISrVKdF3ZcvCE6S1Cnh3UCpHh3mu/zojJfX2bOKcNM1Kzencchrw/D6N+W4/TKWk4u0FF/H5fT1Oe7M33FkKI4kKIg8nuYkZ8fDzKlSuHuLg4lC1b1t+bIwKMxJQ0E/34ePY2YyyNKRVmurlywjBNqbuOJhjfg91evVGVGIy+rK0RBYT/Ja7/bCHmbTli2tR/OqyT17eR0ZJ+b8w2fUAonFbviTMdasuVjjBN4K7oWCegG60JIYSvj98SKCKomLv5MJ6ctBo7jiSY2/1aVsPzg1udUe3Cr/3kVfvMVGL2NyHXnF0Hj1/YAvO2HsZd45cZI+q0B3qjbqXMAYDehG3e7/56ufP24PY18dTAlqbaRwghghFPjt8yyYqg4MjJJJMeYVdVQo/Hc5e0yrXXCD0Pl7SriV5NKuPlPzbg28W78M2iXZi67oDTD3Fn70Y+EyfkotY1cFGbffj3cAIeG9BcjcqEEMIFRVBEsWfFruMY8eUSU45LbTGsa3081K8pYj3oq8FS4icmrsLWQ6fM7doVSmPag71znVIshBDCcxRBESWqT8kj369EUmq6aff+3yvaoX2d8h6vxzalfjhzG/5cux/PDmopcSKEEMFWxXPixAncf//9qFevHkqXLo1u3bph8eLFzsdvuukmE0Z3vVx44YW+2BQRpDDwx/k4936z3IiTPs2r4qeR3QskTmxYLcPqmj/u64lzGlby6vYKIYTwDJ9EUG699VasWbMGX331FWrWrIlx48ahb9++WLduHWrVsjpGUpCMGTPG+ZrISBkDhftVOg9/vxK/rtpnbt/WqyEeu7B5vm3jhRBClGCBcvr0afz444/4+eef0atXL3Pfc889h8mTJ+ODDz7AqFGjnIKkenX3h6UJYXeEHfHVUjNwLzw0BC9d2hpXda7r780SQggR6AIlNTUVaWlpiIqKynI/Uz1z58513p45cyaqVq2KChUq4PzzzzfCpVKlnMPqSUlJ5uJqshElj7V743DrF0uwLy4R5aMj8OH1HZWKEUKIIMXrHpTY2Fh07doVL774Ivbu3WvEClM88+fPx759+5zpnS+//BLTp0/HK6+8glmzZmHAgAHmuTkxevRo4/q1L3Xq5DxgTQQvU9bux+UfzDfihI3VJt3VXeJECCGCGJ+UGW/duhXDhw/H7NmzERYWhg4dOqBp06ZYunQp1q+3hq+5sm3bNjRq1AjTpk1Dnz593IqgUKSozLhk8NGsrXj5zw3gN7Vnk8p499oOpuOqEEKI4C0z9kkVD8UGoyInT57Erl27sGjRIqSkpKBhw5wHrvH+ypUrY8uWLTk+Tr8KP4jrRZQMFmw7gtF/WOLkxq71MOamzhInQghRAvDpsMCYmBjUqFEDx44dw5QpUzB48OAcn7d7924cOXLEPFcIVzhMj1zVqQ5eGNwa4WGabymEECUBn5QZU4wwc9SsWTMTFXnkkUfQvHlz3HzzzSaq8vzzz2Po0KGmiofpoEcffRSNGzdG//79fbE5opiyavdxzNl82JQP331+Y39vjhBCiCLEJ6ejzC2NHDnSiJIbb7wRPXr0MKIlIiLCeFJWrVqFSy65xPhSbrnlFnTs2BFz5sxRLxSRhff/3mquB7eriToVfTcTRwghROChWTwiINl84AQueGO2WZ76QC80qRbr700SQghR3E2yQhSWD2Za0ZP+rapJnAjhLdLTgN1LgbRUBCV7VwCnj/l7K4SXkEARAceuown4eeVes3zXufKeCOE1Fn8GfHo+MP8dBB1LxgAf9wZ+HOHvLRFeQgJFBBwfzd6KtHSH6XnSrhDD/4QQ2dg207rePA1Bxf7VwB+PWctbZyiKEiRIoIiAm7UzYclus6zoiRA+OJCTvcutdE8wkHQC+P4mIC2jmacjDdgy3d9bJbyABIoIKD6bux3JqenoULc8zmlY0d+bI0TwcPo4ELfTWk45BRzagGIPazx+fRA4sgUoWwvoMMy6f9Of/t4y4QUkUETAcDwhGeMW7DDLI89rjJCQEH9vkhDBw4E1WW/vWYpiz/JxwOoJQEgYcPnnQPtrrfs3Tw1eI3AJQgJFBAxf/LMDp5LT0Lx6LM5vXtXfmyNEcKZ3bHYvQbHm4Hrg90es5fOfAuqeA9TuDJSuCCQeB3Yt9PcWikIigSICglNJqRjzz3azrOiJED4UKFVbWdd7lqHYknwKmDAMSD0NNOoDdL/fuj80DGjSz1pWmqfYI4EiAoJvFu3E8YQU1K8UjYvaaCaTED4TKJ1utq4PrrUO9MURRk4ObwTKVAcu/QgIdTmUNc0YmSKBUuyRQBF+Jyk1DR/P3maW7zy3kZm9I4TwIqnJmaZYRhhiawCOdKuxWXFjxTfAivFASChw+WdAmSpZH2/cBwgNBw5vAo5YDR9F8UQCRfidH5fuwcETSahRLgqXnlXb35sjRPDBg3VaMhBZDihfF6jVsXgaZQ9tBH570Fo+9wmgfo8znxNVDqjXzVre/FfRbp/wKhIoJQiOXUpPD6zRS6lp6fhwlnWWM6JnQ5QK11dSCJ9V8FRvDdDf5RQoxcgom5xg9TtJSQAa9AZ6PpT7c5teaF1v/KPINk94Hx0NSghxp1PQdfQM3PLFYiNUAoXfVu/DzqMJqBhTClefXcffmyNEcPtPqrexrmt3Kn5G2T8fAw6uA2KqAkM/tQyx+QmUHfOAxPgi20ThXSRQSggrdx3H/vhE/L3xEKas3Y9AgNGc9/+2oifDu9dHdKlwf2+SEO6xZRrweitgUzFJIexfZV1Xa21d12jPYfZA3C7gxAEEPOt/BZZ9aW3z0E+AMvm0IajUCKjUBEhPtVrfi2KJBEoJYcfRBOfyf6dsNKkVf/Pn2v3YeOAEykSG44au9f29OUK4z6rvgfjdwNqfEPAwYpo9ghJVFqjSvPj4UBZ+aF13uwdoeK57r3FW80zx3XYJnyKBUoImBNtsPXQKE5fv8ev2nE5Ow0u/rXdGT8qVjvDr9gjhEfYBny3WA534vdbwPFa22KKEFBcfyrEdwL9zrOjJ2be5/7pmA6zrzVOCZ+5QCUMCpYSw44jV76BhlRhz/ebUTUhM8d9/2g9mbsGe46dRq3xp3KmhgKI4kZJo9eAoLgLFFlOVmwERUZn31y4mlTwrv7WuG/QCynvgU6vTxaroSTgS+J9R5IgESglhxxErgvJo/2aoXjYKe+MSMX7hTj9tyyl8mNH35OmLW6B0qTzMbkIEGuwnQm8DOX0USDiKgMaZ3snwn9jUcjHKpvs/5ZtremrlN9Zy++s8e21YBNC4r7Wspm3FEgmUEgCrdlgpQ5pUi8V9fZuY5ff+3oKTSUU/UOuFyevMxOKeTSqjf6vqRf7+Qnh16F6gR1EOZPOf2FRtCYSXBpLiA/cz7FwAHNsOlCoDtLjY89c3zUjzbJRAKY5IoJQADp9MRkJymml/ULtCaVzRsTYaVo7B0VPJ+HSOFckoKqavP4DpGw4iIiwEz13SSjN3RPEfuheoB3eb7AZZm7BwoGb7wPahsGMsaTkEKGWlpz2CXWXZcZZt/Y/7J2IsCo4ESglg51HLf1KzXGlEhochPCwUD/VrZu77ZPY2HDmZVCTbQc/L85PXmeXhPRqgUZUyRfK+QvjkgE9/Q6ALlKQTwNGMk5Bq2QQKCeSOsmzMtnaStdz+2oKtI7oiUOcca1nVPMUOCZQS5D+pWzHaed+A1tXRulZZnEpOw3sZvUh8DeftMNVUrWwk7j3fSjMJUawwJbsZKZ7mFwe+QDmw1rqOrQnEVMpdoOwOwAjKhl+B5BNA+XpA3a4FX4+GBxZbJFBKALb/pF6lTIESGhqCR/tbJYfjFuwwFTW+LnOm54U8ObAlYiLVlE0UQ5gmSIoDQiOAZhdZ9wXyQLrc0jvZBQp9NaxOCiRWfJ0ZPXGdVuwpdrnx9tlA0knvbJsoEiRQSgA77QiKi0AhNKl2bVgJyWnppuzYl4z6bR2SUtNxTsOKGNS2hk/fSwifH/CrNgeqtsgUKIFaBZNbBY8NBwfGVLGqkuxus4FA3G5g20xrud3VhVtX5aZAhfrWsMTts7yyeaJokEApQV1k61XMajKjQfWRCy0vyo/LdmPLwRM+ef9Zm9he/wDCQkPw/CWtZYwVxRfnAb+tlXpg87PU00C8fxsfFjiCkmVwYAD5UFZ9x3waUK+7JS4KAz+jhgcWSyRQSqgHxaZD3Qro17IaOOT4tSnej6IkpabhuV+sPPhN3eqjWfVYr7+HEEVeYsyZNqyCqdAgcH0oaanWcD1bUOWG3Q8lUHwo9Pms+KZw5tjs2AJl81/5R7v4+PLxwNw3C9+BNm4PMPUZ4Ni/hVtPCUUCJcg5lZSKwxlVOtlTPDYP929mTjI4G4dDBb3JZ3O3Y/vhU6hcJtLZf0WIYoudBrEjEpUaB65AOboVSE0EImIyhVRO1OoQWBEUCqUjm4GIaKDlYO+sk5EY9lI5eQDYtyL351FIfHkJ8PNdwLRngVmvFPw9U5OAb68B5r0FzHy54OspwUiglBCDbPnoiFzn3TStFovLzqptll+dssFr770v7jTemW79cP/fRc1RNkrzdkQx5vTxzF4atqejcuPANcra6Z1qrfI2mdoChQ3RTh2B31mZYY5tcQkQ6aWIa3gpoNH5uVfzMGqz+DPg/W7W3J+wSOv+Wa8C2wroW/nraWDfSmt5+xzrPYRHSKCUkPROvRzSO67c37cJSoWFYt6WI5i7+bBX3nvUb+txOiUNnepVwKVn1fLKOoXwe8luuTpA6QqBH0HJHu3JDX4W+3P4O4rCSqI1P1rL7a/x7rrtap7sAoWi86shwG8PAimngLrdgJELgLNusHwwE0cAJw969l7rfgEWfWQts1EcJ18rzeMxEiglpElb3Up5d2GsUzEa13apa5Zf+XMDUtIKV5Uwe9Mh/LZqH0JDgOcHq2OsCAJyMpwGtEBZ455AyTKXx88CZePvQGIcULY2UL+Xd9fd+AJrIjKjGpzwzIjG0rFW1IQVQ2z7f+ErwE2/ARUbAgNetcYBMC1EkeKuH4VC5Oe7reXu9wG1O1vLO+Z59/OUACRQSkoPlHwiKOTu8xsjplQYVu+Jw8Pfr0QanbMFYPXuOIwcv8wsX39OPbSqmdFxU4hgFSjHd1ieg+JUweNKbVug+Nkoaw8GZGlxYXqf5ESZKpmfk8Jk3FBg8n1WMzh2m71zHnDOHZnvWyoauGKs5YWhgJnzev7vkZoMfH+z1Sun9tnA+U9b/hfy71zvfp4SgARKSangycUg6wqNrO9cexbCQ0Pw84q9ePKn1WbQoCds3H8CN3y+ECeSUtGlQUU8MSCjV0RJZOvfwIGMKgpfw7POld+pEVVRp0zKVLPMl470wArhnzgAnDpopRcYBcgPV6Osu//n+f3mMD9vcWI/sGWatdzOy+md7NU8NL9unQ6ERwH9XgJu/h2o1OjM51dpBgz8n7U88z/5i4xpzwF7lwFR5YHLP7cmKtfvYT32bxFEUHYvBdb+FLh9eTxEAqWERFByKjHOifObV8NbV59lUjPfLt5lZue4K1JYrXP9ZwtxPCEF7euUx2c3dUbpUmEokfDHiHntb64qmvf7513gp9uACTcGzY9TQJGWAhzakFlibMPUpX1gC6Q0jx09YYSHkYD84JyesFLA6WOZs3vyYt3P1vf78/7AzyMtgVxYVk2whF6dLpnmY29j+1AIUy93zAW63Q2E5vE7xVLndtda2/bjrcCpXDx6G34HFrxnLQ/5AChfx1rm52G/nLidwLEd8AnJp4DfHwU+PR/4/iZg7MDANG57iARKEJOalo49x06f0eY+Pwa2rYFXL29nlsf+8y/+91f+/VF2H0vAdZ8swKETSWhRoyy+uPlslCnJ7exnjs404CXG+/797IMnzwrnven79ytpHN5kdSKNLGs1aHOlUpPAEygHPEjv2FUudq+UPVZ6Nm+PxT2Zt5ePA97vCmyZXsjeJ1/7NnpiVzRd+LIVFRk+BajsZuuDi/5rdaQ9sQ/46fYzTwKO7wIm3WktnzMSaJ4xBoFElgFqnuW7NM+Of4APumeachkV2vkP8GEPYOHHxfqERQIliNl7PBGp6Q6UCg9Ftdgoj157ecfaeHFwK7P87t9bnHN0cuJgfCKu+3Qh9sYlomGVGHx1y9koF12CS4oZPWGpok1RhP7ZGtxmxihgx3zfv2dJwlmy2/pMb0QgGmVdt9dd3PGhZPdYDJts9VhhJ91xlwG/3FswQc7eJIfWW+W9rS6FTznnTqDzrXlHTbJDkUE/Cg/+TEP981bW6NoPw4HE41ZX3r7Pnfl6O83jTaNscgLw5xPAmIusEvGytYDrfwRGLgTq9wRSEoA/HrH6ugRS+tEDJFCCmB12BU/FaDMc0FNu6FofTwywBgr+d8pGjJm3/YznHD2VbMQJvS51KpbG17eeY7wsJZpZ2Zoy8cfD19it1mu0BxxpwI+3AAlHff++JYW8DKdOgbI1MFvyu4s7Le+zeywa9LLMpV3usB5f9gXwQTfLn+IJdufYFhcDpcsjIGH0hZU9ZPqLmf6bGS8CuxcBkeWsfcJoVHbq2T4UlxOXwrBzoRUhWfC+VQp91vXAXfOBxn2t0QA3/gJc9Jpl8OV7slJp8afFLpoigRLEuNsDJS9u790I9/WxwqD0o3y3eGfmSfvpFNzw2UJsPngS1ctGGXFSvZxnkZqgg5ELTk3ltFt7RPxRHwsUVo+wFJJc+YV1wKRgYchZzaF8P3TP9qAc3oyAgGfWdjTH3RSPq0DZt8qKlLjrsSgVAwzIKM9l+itul+VP+fUBIMmN+V58r9XfW8v0egQyHW4E2lxhnQQwakJjOjvFksHv5j43qG4XICTMSvnazf4KQsppYMqTlveHnYJjawDXfg8Mfg+IcqmWZJTv7BGWeGQVEfu7/PYQ8NVg3/lgfIAESkkwyHrgP8mtiduInlar7McnrsbPK/aYFvrDxy7G2r3xqBRTCuNu7WJ6qZR47OjJWddlhnV9HV5lTwfC8DMPEJePsULlbEg1/13fvndJgCIvzwhKhkBh1Yw3zKI5cfKQ+0L34HrL0MkpxbHV3H8P9v5g07a0pMyZQzY8qObmsbDh9/3Of4DOI6zbSz63oimrvgc2T839Mv8d4PRR62Db6DwENDRFX/wGULGRdRJAYzo5+zag5SW5v44dcZ0+lHkFHwHwYc+M/9MOS8wxatK0X95/02G/Wv1d2OeFJ0/8m/BvUwxOXkqwizH42emFCAphk7X/u6gFEpLTMH7hTjw4YSWaVYvFun3xKBsVjq9u6YLGVct4aauLMQz5sl8CHfs9Hsw0xPk6xWOnd5iD5g9ojbbAhf+xzpgYkmePhzoZzaJEwQQgD6A8A66SQ9k8z1xjqloChWkeu2TXGzAkv+Qza+AcTbr0fNTr5p0OsrlNNqbHgmke+3MYj8UteXssXL0aA18DWgyympVR2Ey81b33b3ulZ74Qf0GxQT/Kp30tMVejHdBvVP6vq9/d8vfwd8HTLrknDwJfXGJFQspUBwa9BTTLKJnOD0ZT2N+lyQVWxdXO+VZ0i91uL3knMxIWgCiCEsTs8FIExRYpLw5ujcvOqmUauFGcsKnbF8PPRsuaZb2wtUGAPRCMZYkV6gEVGxRNiocTU0k5l3ECnW4BWg4B0lOtUDTLR0XBsKMJrOKIyCWFaVeDeNOHYg+u+/1hy/Bo/pa35D8vx5MGbe74UNzxWGSnYW/grn+saAt9UfldGp4HdMmI0BQHeBJAkUJD75VfAuFu+O5oXCU75hasBDvllGV6ZtTEXXGSPdLHNFz//1jR1m1/W9VXy74M2GiKIijFgNPJaR73E2Hvkp1HbJNs3m3u3YVG21cvb2uu52w+ZPqlnFU3YyZJSWfXIus/PKMnPR+y7rPz0ayw4Vkomzb5Aub8CduDu54NX/K2VR3BA92kkcDV4637hWe4E5Hgjz8rNLxRycODBUPwHDbHgxKNjuc/BSwZY035ZZnrtRNy77RqCyr2NvEUu+U90wlk01/ueSxyizQwkhesMM2VU6orN9gPhVE4/n/kb0I5l/+v7pZgdxoORFdEgWGEqutIoEk/YNJdlvD85R6rr82gt7Oe5AQAiqAEOB/M3IoWz/yJP9fs9+h1R04l41RymjkesbrGW4SHheK1K9phwRN9cE7DSl5bb9BET9jDwf4RZyiWZyo01Nkiwpcpnuw/eEw98CyPDbg2/gYs/NB32xDMuBOR8FapcU6D62h05EHFWeaa4dvILSXkyQye7NhpHQohelkohtzxWIj8iSprpYM89aHsXwUcXGv5ylpf5p1tYcRv+J/ABS9a62Vaj9GU5eMDKpoigRLAsDPrG1OtJmmTV2YYIT2s4KlRNgqR4d7P62r4nws822SDNJ4d2dETwjNcW6z4Ms2TU4rHhsY8Oz/OM/L8mnCJM3HngO8UKAWs5MlxcN3LmYPrzPu3tu4j0563onbZod+JwoZCxt4mT4ipnPmd/XKI5b1x12Mh8qd+AcqNV2RETxitsadoewNGU7rfC9wxx0rtsbfNz3cBX18FxO9DICCBEqAwRfP85LVIzpgqvOjfox7NxcmcYuzHypqcShV9RVqqFTbN7+KLWTWu0RPbd2Jj/9j7spLHbtKWW8iYZ780LabT7Hiz7ypNigP8nnjyvWSZrN363S2BstXzM1D+/djkzDm4rovVgp0NxbKncTreBLQemlnmmr3XjZ2O4vydsAJm8O00z8n9QKlYqyrMHY+F8ECguOlDSS2CEmzOGxr+l2V+ZrR18xTg/S7Aym/9Hk2RByVAmbb+IGZuPISIMCtSwRbyjIrUrxzjYQ8U7/hPPIahQuY2L/sYaHO5b99r8zRg8r2ZqY68oNHvqq8sE5+3hnMx5M7oSS+X6IkNu2z6upInfveZHhRXjB/lXWvMPIUSu08OYYOnEkZ6GjDmQiuNcvsc90pwzbBHh1UCy+hCblCIcjBf8kmrJ01sdfe2iWLxk/Ot1zDqwem3RpiE5VHm+iawd7klnFiVcfXXmd4iZ7THgw6y2eHZ9JofrGX6mHIaoicKRt1zrO8Jfw8Y+czP87FlKpBwxBpK2eh8320XxWyPB6xhij/dYXnXmN5j6mfop/AXiqAEIIkpaSZ6Qkb0bIi2tcs7oyhF3QOlwGz6wzrLY3mkr8bQ88edpYzjh1rihCKBZwC5XWhgZRiTA7847dWbfU/aXpUZinfF15U8PMO3IyJ5/dixO+dln2aOtD8cQG3ZiwpOed292BID/7zt3mvcLdllhMGe0eOJD4V9QLg9FJcUTfkNrrO9DE5vEZunfVC4DrLZodeE3+WeD3vP8yAyfWG2D8Wdtvcrvs4swS5oRMwTqrYAbp1uCWU2m+Q4Az8igRKAfDhrK3YfO40a5aJw9/mN0bm+5dpevN0DgXLEsynGXscut6Rw4DAxb7N1hpWvX/6VdZslik/sBp4+lPvl8V1W6Jv9KiaOsM6oCwNLMTf/lRE9eTjn5/g6xWP7T/jDx6qJvGA3S54hsYnX7P+iRMG/9ayMNuVk8WdWb4n8OOCB4bQgRlk20yOMMlZp6v7reJBjuSjhSYBdFlyYEmMbpgrvXQ70ebrg6xC5w86u7qR5Th3O/H4UZYddCiH+nt21wJpZ5EckUAKMXUcTTOUOeWpgS0SXCsfZDSxj1GIPIih2DxRPphh79WDg2g9i7hve86MwYjD5fuCrS63UBgUAjYQDXs5/rDwf55knyza3zwLm/K9w22If8Hh2k1sY3Jni+dc3+dz80jvZ6f2Ydb16QmDNjvE16yYBhzdaQo4H79TT7kVRPBm656lAoR+GERRC4egpPHi0HGx5i76/yfp7ntibOTdGBCZ2P5T8BMrqH6zeN+wTU60lipzKjXMvZS8ifPLuJ06cwP3334969eqhdOnS6NatGxYvXux8nGbPZ555BjVq1DCP9+3bF5s3B8gcCz/zwq/rkJSaju6NK+GiNlYeu2O9iibF/O+RBBw8kZjvOhKSU41nxW8eFNP3I8kKQbPUliW2K8YXfr3bZllRk6VjMs2fbK1tG8/cNYQNfN1anjm64OPP6QHg2Q3zyb0eyf15bNiGEMubwDMinxlka7lfRtqkf0YU5TWUCFh6a4vJrncD5z/jEkU5lMfr0jI8KG6mTJwzedwUKLsWWt1ZWZlRpwChdOMtYifQepavZvwVmaI4v2ia8K8Phb8JnKWTV7XMyq8zGz+WUHwiUG699VZMnToVX331FVavXo1+/foZEbJnjxWOfvXVV/H222/jww8/xMKFCxETE4P+/fsjMTH/g28w8/fGg5i67gDCQ0Pw3KBWzlLecqUjTGt5snj7Mbf9J3xduWgfNQfLC/sMknnsHvdby4xWFDSKwsobtm1nV824nUD5ulbL74v+aw0q8xS2mWbIlAdp+lEKIhxmvmJdc3BYXiZCehPYgt5XRllnibGbERRybkYUZdV3mRUqwR49ObTBip50ud1q+c3ya3ZnzSuKwogEIy0RMWdWZ3kjgmKH79k0q6At3u1eN/QL8IBX2PSO8D30g7ETbV4+lANrLVM7/66tfVxkUJIEyunTp/Hjjz8aEdKrVy80btwYzz33nLn+4IMPTPTkzTffxFNPPYXBgwejbdu2+PLLL7F3715MmjQJJZWk1DQ8/4tljL25e300yRAkNmc3qOh2msdZweMvg6ydOuAPNssi6UBnFMU+I/AE+gQ+6mWNCrc7KTJqwjHvhYHzQio3A07sAybe5v4YcqZp6KmhCTi/6ElR+FBc5/B4UqXR+ALLxDy7AGkupiZY4jr2Ymu6qq+hwfjdswuWknONnpxzl3VAp/Dv/bh1H79XuQlU2yDL8Lo7AsIWKBSi3EfuCpSCpHeyR8X6vZh5uzAGWVHEaZ45eZtjm/YHYkpuQ0yvC5TU1FSkpaUhKirrzAqmcubOnYvt27dj//79JqJiU65cOXTp0gXz58/PcZ1JSUmIj4/Pcgk2Pp2z3aRwqsZG4t4+GXM9XLCNsovcMMr63yCbcQbJyEJEaaC7SxSFLd89ObhQPPDMkAfgGyZZk0S9Eb5m5MV05ixtNVmb92b+rzmxH/jmGqu0k7S/LnMGS15U9GGzNrtDrScRFHLu45kVPZ5GUWa9Aqz50fpx3fAbfM7Cjyz/yPQXgI1/ePba9b8Ah9Zb5eVd7si8nz/8zO2bKEouXVk9NZzyO8rvE30Dx3fkL+IPb7Iqy7xRPsrPxv4oFM1NMn9bRTE0ylLccvaO/RtTgvG6QImNjUXXrl3x4osvmqgIxcq4ceOM+Ni3b58RJ6Rataw9CHjbfiw7o0ePNiLGvtSpE7jTFwvCnuOn8c4My4PDqcGxUWemZewIyvr98YhPzPsgvyOjSZv/Iihbsp5RdrrZmvbKPDkPiO4y93Vrvg1NrddP9P4odp4ZX5Rxdj1jFLBjfu5RE/5gvNfFipzQW9PnWasfhTv4shdKQVI8pHYnoHFfK4riSWSCXU5dK4C84S3Kt1FVxo81mXRnpu/Go+jJnVZo3YZRFFukLfok5wF8ngoUGgrtdF9+BmRWf5G6XbNuV0Hh5xn6GfD4Tit9JQKbel0tHwp/K3ni4wpPmFhpGF3ZSkeWYHziQaH3hKmcWrVqITIy0vhNrrnmGoQW0BH8xBNPIC4uznnZtcuHc038wEu/rUNiSjrOrl8Rg9vXzPE51cpGmYiI6Yi9I28fys6jp/0cQckwPFfKiC6YKMp91jKNme5EUXb8A/z9krV80WtA1ea+2dazbgDaXGkdqH+85czOnOyX8u11VlkyDY08675tFtDzQff7Eviq3T2/DAVJ8djYaQ52jHQn/cR98eMIq3GZnZagYIn3bAyDR9iNqihweeDlVGaml9z5Dm341ZphElnWGjefHX4GluuyNfz8d/MoMfYgZeIUKPn4UOxIULMB8BoUKTLHFg9ojLaFb/YoSpbeJxEoyfhEoDRq1AizZs3CyZMnjZhYtGgRUlJS0LBhQ1SvblWmHDiQtVEWb9uPZYcip2zZslkuwcLczYfx++r9CAsNwfODM42xOeFuPxRvTzH2iJRE4HiGgHSdBULvSEwVK/TNA2Je8GyWY+VpYm17tW9d7KYz5+vWtvJgzzN0Hvh5YZkfWz5z0B7Nauc9Bdw6zfOSP9tg6W0PCg/cqRnG8rI5C9s8qdPZSi8wJZFfFIUVLRRpPLNjLxm2P2eYmn+j/P6ehcH+sW53lfWeFBusfmHEK9/oySuZ6Y+cZpgYL0qGYXjRx1nFKcUYG6jxLJfNq9zFnZk8ifGZ5sjC+k9E8cWuPnQ1yvI7yOZ79uiMEo5Pi5xZncNS4mPHjmHKlCnGFNugQQMjRKZPn+58Hj0lrOZhaqgkkZyajmd/sc7SbjinHlrUyFt4udMPJTUt3TR581uKx6QxHFbO37U1OHuQdLvXWp6TRxSFBxa2WGY/h8pNgYH/y2zj7St41mk6c0ZaxkVGbibcYEVUeMbOM53bZgK9HynYGY2d4uFsk2TLH+QV7FQHTcgFnZViR1EoBI7l4ZuggGHvGKbbuK/497R/QJm280WPl+yNqij0BmdEOugZsnuI5ARFJSMgnCXD9E5uNLvI+vuyDNw1inJgdabg8KRSzJ1KHjYZpCjkc9VGvuSS01yetROBtGSr704NmZ19IlAoRv78809jiGW58XnnnYfmzZvj5ptvNhEC9kgZNWoUfvnlF1OGfOONN6JmzZoYMmQIggYa72a8lOcP99h/tmProVOoXKYUHrgg/y6SdgRl5a440w4/J/bFJSI13YFS4aGoXjarUbnIDbLZhUXnW6y8KiMJtgksOyz7ZFifc0l4IIwsgyKBByk2eyP0WKyfbBkYz30CGPF34Wab8Oydgs3bUZTCpHdcu8s2PDfvKAp/QNkzhrCHDHvJEDYJoymUZk+7k6k3yalRFd+zM9NMsIRsTukl/p9zRk9uB6Kt/zc54hpFWegSRSloR1bXoYG+rt4RxRv6jxih4/8fe/SGHTEswb1PfC5Q6BMZOXKkESUUHz169DCiJSLCOvt89NFHcc899+C2225D586dTSqIgiZ75U+xhaWxfz0FzH41zx+qbxZZqZCH+zUzPUvyo0HlGCNmOOF41e64PEuM61QojdBQH0ce3DHIusIzUY73tkVA9lLMnQutSg0y4JWi74bZ8ebMngNVWwEjZlhGysLmgXkQtCt5vClQ8pti7HEUZbxlZHaFjczsdBsrCthDxnUmDOe2mNcWoIQ8P3JrVNVvlOULYYqL25b9e8QQOQUGoyddMyqu8qLZQKAaoygngAXvF27onv29p3hMtlKtZ6TKbIOsBErJhsLZ7lDMNM+hDKHP0RnsryR8I1CuvPJKbN261ZQHs3Ln3XffNdU3NoyivPDCC6Zqh83Zpk2bhqZNPZhDEei4huzsUHE2jpxMwvbD1g/YgNY13Fot95vTh5JLmiezgsdPU4xtgZJb+S3bc0dXslJBrtUZPHNlSoVmVZZLdhiGIodCgtOXb5lqpXTsoV7ewBeVPN4SKKwoaNA7I4qS0WXXmW67zUpNVWluNcbLjp3mYdkx/UfeIq9GVREZ0bVSZYCd/2QObLSjJzMzbne5Le/oiQ3N+70ftZYXfGh9Fws6dI/vVzrjPXMq3+YBiMKKETXTUVSUaFzTPLYgZ+O+MlX9ulmBgmbx+AJX05P9Q5cNuxKnSdUyHnV7tcuNc+uH4vceKHab79xy64yidLsnaxSFBxX2FmFPD3afZfmur30nucGGXGw7Hl7Ku+v1RSWPLVAKk+KxsUtu2YTONjnPe8PySzCNYwRBDqKXDfM4B4gVTizB9hb5Nari92vQW5mVYVv/zqyOYYM1ihe2tXeX5hdbUTNGUVjebptcC9KV1Y6iHN6ce/UOe5WU8AoNQYGS0Q9l+2xg5XfWsmuUsoQjgeLrCEpuAmWnJVA61c+huiAP7AjKsh3HkJbuyDXF4/8mbTmkeGzoIeBZJs8w1/xghdUZlmd/ER4ImToINnxRyWN7UAobQSH1ulndLTl4jsMd2ROGHirCyElulSwUdKywISs86HGTF1kaVeWRi+cEYHYqpimbFUbsJ2FHU84e4V70JKcoyvz3rJQWq85oQPaUvHwom6ZY10rvCNeGbRTELAyIKq/vhgsSKN6GOXvO/bCxc9nZoMAgHep6JlBY6RMbGY4TSalYvy8+1zk8fqngYcVLQkbb8Ip5VCfQ+GpHUaY9D0x91lrm+HhvplUCCZ+keLwoULJEUb4CfrjZSrexR8xZ1+f9OjvNs2VaptmvMGRpVNUv7+de+LIV+Th1CPisn5UW4uycrhnfL09ocYlVQk1xQugPKEgkL7deKPT3sC8Lu72ySZ4QFNH8/trQe1LQirwgRALFV+kdE9IPsVRxtlkfLC9emWFy7VjPM4HCfikdMl6T3YfC5nh+FShHMnLusTXyr77hGS6rW7h/eNZuqjNuRdDijKDssIyS3ogycN95K8Vj58MZRWGZI2cUMRLAHjH5HaTpN6p9tiVoXH1FhU3v8Mc6vzQImwAy6kZRYreX53erIPNLXKMohRm6l1upsR09qXOOZ9EdEdy4TmNXeicLEii+Su/wzM8+KGVL86zdG2dESoXoCFOZ4ym5DQ48eioZJ5NSzfGkdoXowEzvuPYesaMoHBfPsfH+8p0UBRQRNHxSjNmpmcJA4yrP9LnOgqQhcsMuuWVPGFPm7WZnUvuHleKiMD1RGIWzG1W5W2pZpaklpAiFiv29KggtBltRFFK7c8HW4dqszXVfOMuL+xd8+0TwYc9i4veuZgd/b01A4WavbuFxBIWqmJ0o6bOgQHGZI2MbZBk9yatzbG5kDg48ZqIm9jp2ZERP2P8kKqKA49uLSqCQbvdZFT38D8ops8EMvRrl61qDD+lD4bI30jtla1hn/t6iQU/g6q8t/4UnEYRWlwF/PA4cXGelWWq2L9j7sxqoII2q2l1tGWMp1lwbBHoK9+V13wPb51jG2YJgp3gS46yKIEZzkk5aRkgij4FwhYKVc5Q4lTqYT9IKgCIo3oSpHP5A2+Yn+wfenumRwbIMg6ydqvGUtrXLoVRYKA6fTDITkAOmgsc5g8dNgcJZNjQ5FvZgXVywI2reqOSxpxizgsbbNB9oVTJ5Agfe8XXEk4GQ2bGNtgVp893iYqt9f2Ghp4cRoYIKP6adytXJ+n+CM4sovJj6tRvdCUEoSmj4ZgWjyIIEii+iJ1VaWGdxbP6ULcXDiIczguKhQdaG0ZF2dcqdMZfHruAJmCnGIudSY28YZb1ZweMt7JQMK3A4hdhTTKOqJVajKg5KK85kN8q6do/VWbIQbiGB4k3+dUnvEDuCcmijs4kV5+QciE9CeGgI2tYu+Jh1Z5rHxYdiN2nzSwSFuXa7rFICJZ9Knn+9WMHjJYOsN2h4HlCmOnD6aGa3VE9wNqq6oPg3qnI1yrLhnbN7rPwnQriLBIovDLJ28x1OmGW/D1Y3ZJQe2+mdVjXLonSpgvtEOudglN2V4UGp648usqz6SEmwzn4r1Cv69y9xKR4vNmnzFkzZ2ZEPT9M8rGxyNqoKgjkkrgJl33LLj0aPTD2Xig0hRJ5IoHgLmuHY44DYP0IM5VbPmubJNMgWrszQMthaaZ2D8YlZUzz+iKDYoWymMdQhswhSPHab+wyvQ6BgiwumNLKV1+cJPRrB1KjKtVmbXV5MM7i3OxQLEcRIoHjdf9IcKFMl8/5cBUrB/Cc2ZaMi0KJ6WWea53RyGg6eSPJjD5R8ZvCITIFiV3cEW4qHsONszbOsuT6cRuwudsSFZsFgaFTlKlDssulmA/y6SUIUNyRQvJ3esVsX5yBQTrl0f+1Qr+D+kzP6oWw/6mzQVjYqHOWjS/lxBo/8J7nCWTZ2z5LC+FBSTmd27A0kk6xNu2szpyO7AwXb+snBk94hrExjj5q0pIyTkxCg8QX+3iohihUSKL4yyNq4lBqv3HkMHJ9Tq3xp1ChXutBvmWmUPYYdRwJkinFuQwKF91rex+/NbErGlEigwSgID84c2pfLqIcsrJ0EpCYClZsFT6Mq9r1xLRut3SlrZFUIkS8SKN6A4Xq710l2gVK5qTUELykemzetLVT/k+x0bmCtZ8P+eKzZY7XOr6sS48DGG1ON7R4oTO8EYskq27g3u9B9s6zd2p7Rk0D8PAXF9f9CMPhqhChi1EnWG+ycb01UpRjJXh5Jwyh9KftXIe7fZUxEo2Nd75z1Vo2NQv1K0aZZ208r9uRfYsy0As+42VTLm6SlZKYsJFB8P9XY20MCfZXmYdqGPVFMaW1I7q3tdy2wBui1zZiKHCy4RhMlUITwGAkUr5YX51JCWL2tESgRhxhBaVboCp7saR4KlF1HT+dewZOcAMwYBSx432ohfscc756pcgAeS6mZcuCgQOHbXih2k7ZAKjHODnuZcBoxpxJ/MSj/57PChW37gwlbrLPbbzWXibVCCLeQQPEG/87J2SCbzYfSKG07SkeEoXkNNwewudkP5fulGSWnOaV4di4EJt1pzYAhB1YDhzdbA9Z84T8JphB9wKd4AjiCwshhv1HAP+9Y4jW/1vC9H0fQwQndLLdmbxj9vxDCYyRQCgtD1LYRMNcISmtz1TJ0B9rXKo+IMO9Zf87OMMraOE2yrPT4+yXgn3et9BMjGxzIx4Zx/NH0qkDxcAZPScZO8TAKkppUsJLa4pDiIZxnU5LHxzOVek0h5hIJUcKRSbaw7Mjwn1RqAsRWz/k5TKvQyB9yGN1qeXfKMHueVIm1DnIcIMhJxti9BPiwp3X2ym2jH+Cu+UCn4daL7MZR3kIGWffhlGCmwvh3Ob4zeFM8QghRSCRQvN3ePidKl8e+EMs82yN2v1ffPiQkxBlFaVAhDGHTnwM+u8CKanAuyjXfAZd+AJSuADTpl2nqZeTHW2gGj/sw1F+YNA9nHtlt7gM9giKEEIVAAqWw7LAFSs9cn3L0VDJWp1otyZvBC4PistG1USW0DdmKMUkPA/PeBBzpVkUEoyZ2uaedXmBFET0BW6Z7bwMUQSlgJU8BBAqbmiWftJYVQRFCBDESKIXh9HFg36q8DbIcELjjGNY5rAF60UfXe3cbUpNw7YmxmBT1HGqm7ABiqgJXfw1c9rHVjyI7drmjPf69sCSdtAYFEjVp83Amz78FT+9wCGUpP/W8EUKIIkACpTDsXGB5CSo2yrNEcunOY1iXXi/LTB6vsHc58PG5CJ33OkIZFWl9OTByIdB8YO6vsQXK5qlAWmrht8GuDqK3wtv9VYKVwqR4nOkdRU+EEMGNqni8UV6cW/VOBhwQuNeRcVBiFU1qcuGmmvL1s/8LzPmfla5hv4mL3wBaXpL/a2t3tvwopkHWwry9M+7AkmWi9E7RpHjiAnSKsRBCeBlFULxikM3df5KSlo6Vu45jt6My0kqVBdKSgcObCv6eTCl9ch4w+1VLnLS61IqauCNOSFh4plnWG2kep0FW6Z0CNWuj6dUTVMEjhCghSKAUFJoVOQyN5BGFWLs3Hkmp6WbCcGiN1gVP87Cd/MyXLXHCuT/RlYArxlqXmMqercu0HveWQJFBtkCTbtnanQPyTnhY1aUUjxCihCCBUhj/CatlOLG0bM080zukY90KCGHLe2IPFnQXChoKk5mjgfRUoMUlwF0LrehJQWjUBwgNtyI5dgSkoEigFKzLql0i7Gmax9mkTSkeIURwI4FS2PROHtU7dgWPc4JxRsM2Z+TFHThw7ePzLJFC78jQz4Arvyzc6HaaWet2tZY3/1Xw9TA94UzxNCn4ekoiBZ3JY7e5V4pHCBHkSKD40H/icDiwZMdRs9yRAiVjJo8RG+54D2iG/fP/gPQUq/qGUZM2l3tnroddzbPxj4Kv49QhICnOmlRrGz+Fe9j7y5NKnvR0IH6vtawmbUKIIEcCpSAkxgP7VuTrP9kbl4gD8UkICw1Bu9rlrSZpTK2wgsY+0OTFym+AuJ1AmWqW1yS2mvc+gy1QdsyzPk9h0jv0VBRkpkxJxtkLZbtngpBilf4VTY0WQgQ5EigFgeW59J/wIJPHmaztP2lVsyxKlwoDIqKAys3cM8rSFDvnNWu5+33WxFdvUrmx5Ruhp2XrjIKtQ/6Twqd4PImg2AZZjjBgNZYQQgQxEig+7H/i9J/UrXDGZON8BQqjJxwmx86wHW+GTyhsV1kJFC/0QvHAgxKvGTxCiJKDBIqP/CdZKnjoP7Fx+lBW5R09me0SPfFVS3O73JhG2fQ0z1+vIYGFT/EkHAaSTnhYwSODrBAi+JFA8RQeTPauyLeC51RSKtbts7wdnernIFDyKjVe9R1wnHN1qgCdhsNnsJInshyQcATYs7TgERSmi4RnRJWz5ul4kuaxUzyq4BFClAAkUDyFvUPYwZU+gPK596JYufs40tIdqFkuCjXKufhHqmUIlKPbcj5zNtGT/1rL3e717UA49uNo3Kdg1TyMuPAzEEVQiibN40zxqAeKECL4kUDxFFtUsCeJu/1PXImpBMRmNHY7sPbMF66aYB2wOF+n8y3wOU4fyhTPXkd/DNv2h0UCZeWJKJJKHqV4hBAlCAkUT0k+ZV1HlvHcf2Lj2g/FFU4XtqMn3Rk9iYHPaXKBVbZ6cK0lOgoygydUX6MiqeRRikcIUYLQkcVTkk5a16VyFyhM7SzbedxzgbL6e+tsmnN2Ot+KIiG6IlCni+dRFGcFj4YEFslUYzbtO3nAWlaKRwhRApBA8ZTkE/lGUJb8exRxp1NQrnQEWtQoe+YTcio1NtGTV63lbvcUTfSkMMMDVWJctO3uT+xjb2IrpebpcEghhCiGSKD4IIIyZa11ptunRVVEhOWwi+2hgQfXWcKErPnBMp2ysqPzCBQpTQdY19tnZ34+twWKZvAU2oNyfJdljnYrvVPTO6MOhBAiwJFAKagHJReBwvk7U9buN8sXtqqe+5lzRAyQmggc3WpVxDgrd+7O19/idao0A8rXs0yv22a69xpFUAoP29WXirWqwpaPy/u58bZBVoZkIUTJQALFU5IzIgy5iIi1e+Ox5/hplI4IQ6+muUwcpqm0WqvMNM+aH60DPiuDzr4NRQ7PyD3pKptyOnOqrgRKweH3oPcj1vKfjwP78+iNY+9vCRQhRAlBAqWgZca5eET+XGNFT3o3rYKoiLDc12MbZfcuB2ZleE+6MnoSC7/Q7EKXrrLpeT/X7n8SVd4y2YqC0/UeoPEFVjTt+5tyT7E5S4wlUIQQJQMJlAKneHIWEs70Tutc0jvZBcrSscCRzdbB3h/RExt2xWXaipUi+5a7n96RH6LwUZRLP7J64/B78NtDzBPmnuJRibEQooQggeLFFM/WQyex+eBJhIeG4LzmVfNej22UtdfH6ElUDhU/RUV4JNDoPPfKjeU/8S5s3nf5Z1Y/mlXfAiu+zt0kqwiKEKKEoJntXqzisaMnXRtVMiXGeVK1hXVAcqRbc1m6+DF64lrNs36y5YnJ60x9y3TrWjN4vEe9bsB5/wfMGAX8/jBQqyNQtXnm4xIoQogShgRKQfug5ChQDriX3jGvj7ZKdA9vzIielIPfadKPjlkrQjL53vyfrxJj79LjIeDfecC2vy0/yogZ1veEojjRavynFI8QoqQggeKlVvf74k5j5a7jxpJxQctq7q1rwMtWNIICJRAoUwW46L+ZEZK8iK2eWfkjvOdHuexj4MMewKH1wB+PAIPfy/SfRJb1bxpQCCGKs0BJS0vDc889h3HjxmH//v2oWbMmbrrpJjz11FMIyTBU8vYXX3yR5XX9+/fHn3960Mk0wFI8f2VETzrWrYCqsVHuravR+dYlkDh7hHUR/qFMVWDop8CXg63eKPV7ZXaOVXpHCFGC8LpAeeWVV/DBBx8YAdKqVSssWbIEN998M8qVK4d7781MG1x44YUYM2aM83ZkZCSKBbapNVuZse0/6Z9bczYh3KVBL6D3Y8DM0cCvDwCdh1v3K70jhChBeF2g/PPPPxg8eDAGDhxobtevXx/ffPMNFi1alOV5FCTVqxezgzk7vqYkWMsu/UqOnUrGwu1HzbIEivAKvR4B/p0L/DsH+Ocd675yEihCiJKD18uMu3XrhunTp2PTpk3m9sqVKzF37lwMGJAx7yWDmTNnomrVqmjWrBnuvPNOHDlyJNd1JiUlIT4+PsvFr/6TbCmeaesPmAnGHAxYt1K0f7ZNBBehYVaqJ8alG7FSPEKIEoTXIyiPP/64ERDNmzdHWFiY8aS89NJLuO6667Kkdy677DI0aNAAW7duxf/93/8ZATN//nzzmuyMHj0azz//PAImvRMabvUNyVa907+Vm+ZYIdyBRmSaZr+6zJpkXFYCRQhRcvC6QJkwYQLGjx+Pr7/+2nhQVqxYgfvvv9+YZYcNG2aec/XVVzuf36ZNG7Rt2xaNGjUyUZU+ffqcsc4nnngCDz74oPM2BVCdOnXgP4NsjLOD6qmkVMzefMj98mIhPIEmalZWrZ0ENO3v760RQojiK1AeeeQRE0WxRQgFyI4dO0wUxBYo2WnYsCEqV66MLVu25ChQ6FcJCBOt0yCb6T+ZtekQklPTUa9SNJpV89McHRHcqLJKCFEC8boHJSEhAaHs5+AC0zbpeQyg2717t/Gg1KhRA8Wtzb09HJDmWLuMWgghhBABFkEZNGiQ8ZzUrVvXpHiWL1+O119/HcOHW6WSJ0+eNH6SoUOHmioeelAeffRRNG7c2PRCCWhcUzzUK6np+HvDQbOs6h0hhBAigAXKO++8g6effhp33XUXDh48aLwnt99+O5555hlnNGXVqlWmT8rx48fN4/369cOLL74YGGkct1I8VgTln62HcSIpFVVjI3FWnfL+3TYhhBAiiPC6QImNjcWbb75pLjlRunRpTJmSz7TcgE/xxGZpzsbW9qGhSu8IIYQQAetBCWpc2tyz78nUdR4MBxRCCCGE20igFLDN/dIdx3D4ZDLKRoXjnIaV/L1lQgghRFAhgVLAScZ2eqdvi2qICNNuFEIIIbyJjqyekHTCXDlKZQqUfqreEUIIIbyOBEoBUjz7T4dh97HTiIoIRe+mLrNShBBCCOEVJFAKYJJdfSjNXFOclC515uwgIYQQQhQOCZQCeFAW7U0x12rOJoQQQvgGCRRPSLY8KFvigPDQEPRprunFQgghhC+QQClAiueUIwqNq5ZBuegIf2+REEIIEZRIoBTAJHsKUahdIdrfWyOEEEIELRIoBfCgnERp1K5Q2t9bI4QQQgQtEijukp7ujKAkOBhBkUARQgghfIUEirukZHSRNRGUKNQqL4EihBBC+AoJFA/TO2kIRSJKoZYiKEIIIYTPkEApQAUPECKTrBBCCOFDJFA87IHCCp7SEWGooBJjIYQQwmdIoBQggsL0TkhIiL+3SAghhAhaJFA8LjGWQVYIIYTwNRIonjZpc6gHihBCCOFrJFDcJcnyoCQwgiKBIoQQQvgUCRR3UYpHCCGEKDIkUDxO8WgOjxBCCOFrJFDcJD0xs8xYHhQhhBDCt0iguEnCyePmOjEkGlXKRPp7c4QQQoigRgLFTRJPxZvrsNKxCA1VDxQhhBDCl0iguElygiVQImPK+ntThBBCiKBHAsVDD0p0TDl/b4oQQggR9EigeNjqvkzZCv7eEiGEECLokUBxk9BUqw9K+fISKEIIIYSvkUBxk4i0BHNdoYIEihBCCOFrJFDcID3dgdLpp81ylUqV/L05QgghRNAjgeIGh04kIhqJZlkCRQghhPA9EihusPfQUYSGOMxyeGmVGQshhBC+RgLFDQ4eOWyu0xECRGgOjxBCCOFrJFDc4PCRI+Y6ObQ0EKIuskIIIYSvkUBxg2PHjpnrlPAYf2+KEEIIUSKQQHGD+HhLoDgiJFCEEEKIokACxQ1OxVuTjEMiy/h7U4QQQogSgQRKPjgcDpzOmGSsCh4hhBCiaJBAyYdjCSnOLrKloiVQhBBCiKJAAiUf9hw7jTKwusiGKcUjhBBCFAkSKPmw+1gCYjK6yEICRQghhCgSJFDyYc/x04gOyRAopSRQhBBCiKJAAiUfdrukeCRQhBBCiKJBAsUNgRJjR1CU4hFCCCGKBAkUN1I8ZWwPiiIoQgghRJEggZIPe44lINppko319+YIIYQQJQIJlDyIT0xBfGIqYkJsD4pa3QshhBDFUqCkpaXh6aefRoMGDVC6dGk0atQIL774ounIasPlZ555BjVq1DDP6du3LzZv3oxA7IFCyoYmWXcoxSOEEEIUT4Hyyiuv4IMPPsC7776L9evXm9uvvvoq3nnnHedzePvtt9/Ghx9+iIULFyImJgb9+/dHYmJGKiXABEqsLVBkkhVCCCGKhHBvr/Cff/7B4MGDMXDgQHO7fv36+Oabb7Bo0SJn9OTNN9/EU089ZZ5HvvzyS1SrVg2TJk3C1VdfjUAyyJIYZ5mxPChCCCFEsYygdOvWDdOnT8emTZvM7ZUrV2Lu3LkYMGCAub19+3bs37/fpHVsypUrhy5dumD+/Pk5rjMpKQnx8fFZLkXVRRZwICpdHhQhhBCiWEdQHn/8cSMgmjdvjrCwMONJeemll3DdddeZxylOCCMmrvC2/Vh2Ro8ejeeffx7+iKBEIRmhSLfuUIpHCCGEKJ4RlAkTJmD8+PH4+uuvsWzZMnzxxRd47bXXzHVBeeKJJxAXF+e87Nq1C0XlQXHO4SERiqAIIYQQxTKC8sgjj5goiu0ladOmDXbs2GGiIMOGDUP16tXN/QcOHDBVPDa83b59+xzXGRkZaS5+7SJLcRKqqmwhhBCiKPD6ETchIQGh2Q7kTPWkp1tpEpYfU6TQp2LDlBCrebp27YpA4XRyGo6cSs6cw6P0jhBCCFF8IyiDBg0ynpO6deuiVatWWL58OV5//XUMHz7cPB4SEoL7778fo0aNQpMmTYxgYd+UmjVrYsiQIQi0Cp5KpVKtO9QDRQghhCi+AoX9Tig47rrrLhw8eNAIj9tvv900ZrN59NFHcerUKdx22204fvw4evTogT///BNRUVEIFKwKHqBuTBrARUVQhBBCiCIjxOHa4rWYwJQQS5NpmC1btqxP3mP8wh148qc1eKzOOtx5aBRQrztw8+8+eS8hhBCiJBDvwfFbrs98usjWKK0UjxBCCFHUSKDkUcFDqtgeFKV4hBBCiCJDAiVfk2yydYe6yAohhBBFhgRKPimeCmG2QNEcHiGEEKKokEDJgeTUdBw4YTVoKxua0ahNKR4hhBCiyJBAyYF9cafB2qbI8FBEOexBgRIoQgghRFEhgZJHeqdWhdIIST5l3SkPihBCCFFkSKDkwO4Mg2yt8qWBpBPWnZHyoAghhBBFhQRKHiXGtSuUBpwRFKV4hBBCiKJCAiWPFE/tCtFA8knrTqV4hBBCiCJDAiUH9hxPcEnxZAgUVfEIIYQQRYYESh4pHppkkZzhQVEfFCGEEKLIkEDJRlq6A/vjrN4ntcpFZXpQFEERQgghigwJlGwciE9EaroD4aEhqBYTAqTbwwLlQRFCCCGKCgmUXNI7NcpHISwlI3pCVMUjhBBCFBkSKHkZZO0KnohoIDTMvxsmhBBClCAkUPIqMbYreJTeEUIIIYoUCZRs7HHtIuvsgaL0jhBCCFGUSKDkVWKsHihCCCGEX5BAyS3FkyWCoh4oQgghRFEigeKCw+FwpnjU5l4IIYTwHxIoLhw6mYSk1HSEhADV2aRNKR4hhBDCL0ig5JDeqRYbhVLhoS5t7iVQhBBCiKJEAsWFzPROaesOu829BIoQQghRpEig5FbBQ5TiEUIIIfxCuH/eNjC5uXt99G9VHaEhGXeoD4oQQgjhFyRQXIgMD0ODyi4VO7ZAUQRFCCGEKFKU4skLZ6t7CRQhhBCiKJFAyQuleIQQQgi/IIGSFzLJCiGEEH5BAiUvnGXGanUvhBBCFCUSKHnhbNSmVvdCCCFEUSKBkhdK8QghhBB+QQIlN1KTgfQUa1kmWSGEEKJIkUDJr4KHSKAIIYQQRYoESm4kZfhPwqOAMPWzE0IIIYoSCZTcUA8UIYQQwm9IoORXYiyDrBBCCFHkSKDkl+JRBEUIIYQociRQckMpHiGEEMJvSKDkhnqgCCGEEH5DAiXfNvfqIiuEEEIUNRIo+ba51xweIYQQoqiRQMkNpXiEEEIIvyGBkm+KRwJFCCGEKGokUPKt4pEHRQghhChqJFDy64MSKQ+KEEIIUdRIoOSG+qAIIYQQwSNQ6tevj5CQkDMuI0eONI+fe+65Zzx2xx13IOBQmbEQQgjhN7w+pnfx4sVIS0tz3l6zZg0uuOACXHHFFc77RowYgRdeeMF5Ozo6GgGHqniEEEKI4BEoVapUyXL75ZdfRqNGjdC7d+8sgqR69eoIaNQHRQghhAhOD0pycjLGjRuH4cOHm1SOzfjx41G5cmW0bt0aTzzxBBISEvJcT1JSEuLj47NcfI6mGQshhBDBE0FxZdKkSTh+/Dhuuukm533XXnst6tWrh5o1a2LVqlV47LHHsHHjRkycODHX9YwePRrPP/88/JLikQdFCCGEKHJCHA6Hw1cr79+/P0qVKoXJkyfn+pwZM2agT58+2LJli0kF5RZB4cWGEZQ6deogLi4OZcuW9f6Gp6UAL1a2lh/dDkRX9P57CCGEECWM+Ph4lCtXzq3jt88iKDt27MC0adPyjIyQLl26mOu8BEpkZKS5FHkPFKIyYyGEECJ4PChjxoxB1apVMXDgwDyft2LFCnNdo0YNBAy2/ySsFBBeyt9bI4QQQpQ4fBJBSU9PNwJl2LBhCA/PfIutW7fi66+/xkUXXYRKlSoZD8oDDzyAXr16oW3btggY1KRNCCGECD6BwtTOzp07TfWOK/Sj8LE333wTp06dMj6SoUOH4qmnnkJAoR4oQgghRPAJlH79+iEn7y0FyaxZs3zxlt5FPVCEEEIIv6JZPDmhNvdCCCGEX5FAyQmleIQQQgi/IoGSEzLJCiGEEH5FAiUvgRIpD4oQQgjhDyRQckJt7oUQQojgncVTbFGKRwhRgkhLS0NKSoq/N0MEAREREQgLC/PKuiRQckImWSFECYDtIPbv32+GugrhLcqXL4/q1asjJCSkUOuRQMkJRVCEECUAW5xwLEl0dHShDyiiZONwOJCQkICDBw96ZYSNBEpOSKAIIUpAWscWJxw9IoQ3KF26tLmmSOF3qzDpHplkc0IpHiFEkGN7Thg5EcKb2N+pwvqaJFDy7CQrgSKECG6U1hGB+p2SQMlzFo8EihBCCOEPJFByQikeIYQoMdSvXx9vvvmmvzdDZEMCJSdkkhVCiIBMHeR1ee655wq03sWLF+O2227zyjZ+8803xhg6cuRIr6yvJCOBkp20VCA10VqWQBFCiIBh3759zgsjHmXLls1y38MPP5yl5DU1NdWt9VapUsVrZuHPPvsMjz76qBEqiYkZxxI/kZycjOKMBEpu0ROiFI8QQgQMbP5lX8qVK2eiJvbtDRs2IDY2Fn/88Qc6duyIyMhIzJ07F1u3bsXgwYNRrVo1lClTBp07d8a0adPyTPFwvZ9++ikuvfRSI1yaNGmCX375Jd/t2759O/755x88/vjjaNq0KSZOnHjGcz7//HO0atXKbB/7hNx9993Ox1j2ffvtt5ttjYqKQuvWrfHrr7+axxgdat++fZZ1cZu57TY33XQThgwZgpdeegk1a9ZEs2bNzP1fffUVOnXqZPYP99W1117r7FVis3btWlx88cVG9PF5PXv2NPtu9uzZpjsse+a4cv/995vn+BIJlNwESmgEEB7p760RQoiia7KVnOqXC9/bW1AcvPzyy1i/fj3atm2LkydP4qKLLsL06dOxfPlyXHjhhRg0aBB27tyZ53qef/55XHnllVi1apV5/XXXXYejR4/m+ZoxY8Zg4MCBRjxdf/31JpriygcffGBSP0wnrV692oiexo0bm8fS09MxYMAAzJs3D+PGjcO6devM5/C0jwg/58aNGzF16lSnuGG574svvoiVK1di0qRJ+Pfff42YsdmzZw969eplRNOMGTOwdOlSDB8+3ESgeH/Dhg2NyLHh+saPH2+e40vUqC07MsgKIUogp1PS0PKZKX5573Uv9Ed0Ke8cjl544QVccMEFztsVK1ZEu3btnLd5oP7pp5+MOHCNXmSHB/BrrrnGLP/nP//B22+/jUWLFhmBkxMUGGPHjsU777xjbl999dV46KGHTFSlQYMG5r5Ro0aZ++677z7n6xjRIYzqcP0UVoy+EAoDT4mJiTHRn1KlSjnvcxUSXCc/C9+X4o1Rpffee8+Iqm+//dZES4i9DeSWW24x4uuRRx4xtydPnmzSVxRwvkQRlOyoB4oQQhRbmMpwhQdhelNatGhhZsTwgEwRkF8EhdEX14M+Ux/Z0yKuMGJx6tQpE20hlStXNkKJKR3C1+7duxd9+vTJ8fUrVqxA7dq1swiDgtCmTZss4oQwIsKoUd26dU36pnfv3uZ+ex/wvZmuscVJTmJty5YtWLBggblNIUZxwv3iSxRByY56oAghSiClI8JMJMNf7+0tsh80KU4oHl577TWTTmEr9ssvvzxfA2n2gzV9KYyS5AbTOUwB2a3eCZ/PFBHTRa7350R+j4eGhp6RCsupU2v2z0/R1L9/f3NhWoaGYAoT3rb3QX7vzZb1FDiMojAaRJ/PzJkz4WskULKjFI8QogTCA7C30iyBBD0djADQ8GpHVOjB8CZHjhzBzz//bFIkNMC6zjvq0aMH/vrrL5MaoqGVHpHzzjsvx4jN7t27sWnTphyjKFWqVDFGVYoUu1MrIx/5QfMwt49+ljp16pj7lixZcsZ7f/HFF0bw5BZFufXWW03Ki1GeRo0aoXv37vA1SvHkmuLxbehKCCGE72EFDqtpeDCnSZQVLHlFQgoCDaQcuMi0Bytv7Au9L0z52GZZVuL873//Mx6QzZs3Y9myZU7PCtMuNKQOHTrURHy2b99uIhV//vmnefzcc8/FoUOH8Oqrr5rqGvpG+Hh+MK3DlA/fZ9u2bcZ7Qx+OK/TixMfHG98MxQu3jZ+JZlsbRlyY5qKP5uabb0ZRIIGSHaV4hBAiaHj99ddRoUIFdOvWzaQpeKDt0KGDV9+DPhNGaHKaQUPBQVFw+PBhDBs2zJQGv//++ybSwrJeigGbH3/80ZhXGalo2bKl6afCKAyhh4avozCh8KGh1rXvS24w8kLPyPfff2/WyUgK012uUFyxeofRJQollml/8sknWaIpTDExEsXtufHGG1EUhDi8Wd9VRFDp0XEcFxdnFJ1XmfsmMO1ZoN01wKUfenfdQggRILAKw64wYc8NIfKD1TyM4uTXEyav75Ynx+/gSzgWFrW5F0IIIZxQTLBvy9dff+1WwzpvIYGSHXlQhBBCCCfsxMuU0h133JGlx4yvkUDJTlKGB0VVPEIIIQSKoqQ4J2SSzTXFE+vvLRFCCCFKLBIo2VGKRwghhPA7EijZUaM2IYQQwu9IoOTaB0UpHiGEEMJfSKBkRxEUIYQQwu9IoGRHHhQhhBDC70igZEeN2oQQQgi/I4HiSnoakJJgLUfKgyKEEIEEZ93kdeEwvsKse9KkSW4///bbb0dYWJiZcSN8gxq15RQ9IUrxCCFEQLFv3z7n8nfffYdnnnkmy8TdMmWKJvKdkJCAb7/91gzz46DAK664Av4kOTnZTCwONhRBycl/EhIGhGt4lhBCBBLVq1d3XjhwjlEP1/soGjj1lwPqmjdvbqb/uh7E7777btSoUcM8Xq9ePYwePdo8Vr9+fXNtTyS2b+eGPRn48ccfx+zZs7Fr164sjyclJeGxxx5DnTp1EBkZicaNG+Ozzz5zPr527VozyZjD8mJjY9GzZ09s3brVPHbuuefi/vvvz7K+IUOGmEnCNty+F1980UwV5jpuu+02cz/fs2nTpoiOjkbDhg3x9NNPIyUlJcu6Jk+ebCYmcx9UrlzZfGbywgsvoHXr1md81vbt25v1+ANFUHKr4MlhbLYQQgQtHGxvp7iLmojoQv/mjh8/3kRU3n33XZx11llYvnw5RowYgZiYGAwbNgxvv/22GXQ3YcIE1K1b14gKW1gsXrwYVatWxZgxY3DhhRea1E1eUGxcf/31RiQNGDAAY8eOzXIQp3CYP3++ec927dqZyb6HDx82j+3Zswe9evUyQmTGjBlGYMybNw+pqakefd7XXnvNfN5nn33WeR/FDrelZs2aZrgfPz/vY6SH/Pbbb0aQPPnkk/jyyy+NaPv999/NY8OHD8fzzz9v9gUFDOE+XLVqFSZOnAh/IIHiinqgCCFKKhQn/6npn/f+v72FTqvzQP2///0Pl112mbndoEEDrFu3Dh999JERKDt37kSTJk3Qo0cPEyVhBMWmSpUq5rp8+fImEpMXmzdvxoIFC5wHbQqVBx98EE899ZRZ76ZNm4wImjp1Kvr27Wuew2iGzXvvvWeEDaM9ERER5j5GPTzl/PPPx0MPPZTlPm6Da5Tl4YcfdqaiyEsvvYSrr77aCBEbCihSu3Zt9O/f34g0W6BwuXfv3lm2vyhRiscVlRgLIUSx49SpUyZFcssttxgfin0ZNWqUM3XCFMmKFSvQrFkz3Hvvvfjrr78K9F70nPBAzvQIueiiixAXF2eiIYTvwQgMD+w5wceZ0rHFSUHp1KnTGffRl9O9e3cjsvj5KVgozFzfu0+fPrmukxGXb775BomJiSa68vXXX5vIir9QBMUVNWkTQpRUmGZhJMNf710ITp60frs/+eQTdOnSJctjdrqmQ4cOJtXyxx9/YNq0abjyyitNhOOHH35w+33S0tLwxRdfYP/+/QgPD89yP4ULD/6lS5fOcx35PR4aGgoH020uZPeREKauXGFK6brrrjPREQooO0rDqJK77z1o0CDjmfnpp5+M6Zbve/nll8NfSKC4oh4oQoiSCj0gxTR6XK1aNeO72LZtmzlI5wb9HldddZW58MBLv8nRo0dRsWJFE9Gg0MgL+jVOnDhhvBmuPpU1a9bg5ptvxvHjx9GmTRukp6dj1qxZzhSPK23btjUihwf/nKIoTDe5ViulpaWZ9Z933nl5bts///xj0lb0l9js2LHjjPeePn262dacoOhiOoypHQoUpoPyEzW+RALFlaQMD4p6oAghRLGCkQOmbhg5oPBgJc2SJUtw7Ngx4xF5/fXXTQUPDbSMUrASh6kQ+k5szwYP3kyRMIpQoUKFHM2xAwcOdPo2bFjR88ADDxij7siRI81BnqkR2yRLoXDw4EETtWEl0TvvvGMO/k888YTZXnpazj77bJN+oreE2/vbb7+hUaNGZrspfPKD/hqmcxg1oYeEr2ckJLtPh1EerpfvT2MuRRerf2xuvfVWUwlFaN71K45iSFxcHONf5tqr7FricEx/0eFY8a131yuEEAHG6dOnHevWrTPXxZExY8Y4ypUrl+W+8ePHO9q3b+8oVaqUo0KFCo5evXo5Jk6caB77+OOPzWMxMTGOsmXLOvr06eNYtmyZ87W//PKLo3Hjxo7w8HBHvXr1zni//fv3m8cmTJiQ4/bceeedjrPOOsssc58+8MADjho1apht4Xo///xz53NXrlzp6NevnyM6OtoRGxvr6Nmzp2Pr1q3mseTkZLOuihUrOqpWreoYPXq0Y/DgwY5hw4Y5X8/te+ONN87YhkceecRRqVIlR5kyZRxXXXWVeU72ffTjjz8691HlypUdl1122Rnr4fa0atXK4YvvlifH7xD+g2JGfHy8UZ00JjFkJ4QQwjNohKQng9Uu7IkhBKEkYDTmrrvuMpEcb3+3PDl+K8UjhBBCCBw6dMikiGgCzs2nUpRIoAghhBACbFbH8umPP/44Rw9OUSOBIoQQQggEmuNDjdqEEEIIEXB4XaCwVCunMdgsvbLNM1yuVKmS6XQ3dOhQHDhwwNubIYQQQohijNcFCgcNscmMfeE8AmKPo2atOKcpsgadjWz27t3rnJ0ghBCiaGFTMSEC8TvldQ+KPXTJ5uWXXzZNYTiXgGVFbHTD/v5sRkPYsY5NYdio5pxzzslxnWy4w4trmZIQQoiCw06hbFjGk0T+bvM2o91CFMbDwhk+rAbid4vfqYA1yXJDx40bZ2qp+cVfunSpae/r2v63efPmZvQ15wjkJlBGjx6dZfqiEEKIwsEDCPtUMNJNkSKEt4iOjjbHdX7HAlagTJo0ybTo5RRJwtpqKiq7tbDrHAU+lhtsB+zaMIYRlDp16vhwy4UQIvjh7zEPJGx5nt8cGiHcgTOKONPHG9E4nwoUpnMGDBhghjgVBs5F4EUIIYR34YGEQ+tyGlwnhD/xmUDhcCSOtJ44caLzPg5mYtqHURXXKAqrePiYEEIIIYRP+6DQ/MqudJz8aNOxY0ej0jkx0mbjxo1mAmPXrl31FxFCCCGE7yIoLDGiQOHIaeaibDgg6JZbbjF+kooVK5pBQffcc48RJ7kZZIUQQghR8vCJQGFqh1GR4cOHn/HYG2+8YZy9bNDG0uH+/fvj/fffL1A7XpUbCyGEEMUH+7jtTlv9EEegNd93g927d6uKRwghhCim7Nq1C7Vr1w4+gcIUEuv2Y2Njvd5YyC5h5s5jCkr4Fu3vokX7u2jR/i5atL8Df39Tcpw4ccJU9+bXJ6VYTjPmh8pPeRUW7mx9wYsO7e+iRfu7aNH+Llq0vwN7f9OP6g6aZiyEEEKIgEMCRQghhBABhwRKNtix9tlnn1Xn2iJC+7to0f4uWrS/ixbt7+Da38XSJCuEEEKI4EYRFCGEEEIEHBIoQgghhAg4JFCEEEIIEXBIoAghhBAi4JBAEUIIIUTAIYHiwnvvvYf69esjKioKXbp0waJFi/y9SUHB7NmzMWjQINPamKMJJk2alOVxFpI988wzqFGjBkqXLo2+ffti8+bNftve4s7o0aPRuXNnMwqiatWqGDJkCDZu3JjlOYmJiRg5ciQqVaqEMmXKmOGdBw4c8Ns2F2c++OADtG3b1tlNk9PZ//jjD+fj2te+5eWXXza/K/fff7/zPu1z7/Hcc8+Z/et6ad68eZHsawmUDL777js8+OCDpqZ72bJlaNeunZm0fPDgQX9vWrHn1KlTZn9SAObEq6++irfffhsffvghFi5ciJiYGLPv+cUXnjNr1izzg7FgwQJMnToVKSkp6Nevn/k72DzwwAOYPHkyvv/+e/N8zra67LLL/LrdxRWO3eBBcunSpViyZAnOP/98DB48GGvXrjWPa1/7jsWLF+Ojjz4yAtEV7XPv0qpVK+zbt895mTt3btHsa/ZBEQ7H2Wef7Rg5cqTzdlpamqNmzZqO0aNH+3W7gg1+5X766Sfn7fT0dEf16tUd//3vf533HT9+3BEZGen45ptv/LSVwcXBgwfNfp81a5Zz/0ZERDi+//5753PWr19vnjN//nw/bmnwUKFCBcenn36qfe1DTpw44WjSpIlj6tSpjt69ezvuu+8+c7/2uXd59tlnHe3atcvxMV/va0VQACQnJ5uzH6YWXAcS8vb8+fP9um3Bzvbt27F///4s+56DpJhi0773DnFxcea6YsWK5prfdUZVXPc5Q7Z169bVPi8kaWlp+Pbbb020iqke7WvfwSjhwIEDs+xbon3ufZhyZ4q+YcOGuO6667Bz584i2dfFcpqxtzl8+LD5YalWrVqW+3l7w4YNftuukgDFCclp39uPiYKTnp5ucvPdu3dH69atzX3cr6VKlUL58uWzPFf7vOCsXr3aCBKmJZmH/+mnn9CyZUusWLFC+9oHUAQyFc8UT3b0/fYuPFkcO3YsmjVrZtI7zz//PHr27Ik1a9b4fF9LoAgR5GeZ/CFxzRkL78Mfb4oRRqt++OEHDBs2zOTjhffZtWsX7rvvPuOvYkGD8C0DBgxwLtPrQ8FSr149TJgwwRQ1+BKleABUrlwZYWFhZziPebt69ep+266SgL1/te+9z913341ff/0Vf//9tzFy2nC/Mq15/PjxLM/XPi84PIts3LgxOnbsaKqoaAp/6623tK99ANMKLF7o0KEDwsPDzYVikEZ7LvPsXfvcdzBa0rRpU2zZssXn328JlIwfF/6wTJ8+PUtonLcZthW+o0GDBuaL7Lrv4+PjTTWP9n3BoBeZ4oRphhkzZph97Aq/6xEREVn2OcuQmVfWPvcO/P1ISkrSvvYBffr0MSk1RqzsS6dOnYw3wl7WPvcdJ0+exNatW01bCJ9/vwttsw0Svv32W1M5MnbsWMe6desct912m6N8+fKO/fv3+3vTgsJtv3z5cnPhV+711183yzt27DCPv/zyy2Zf//zzz45Vq1Y5Bg8e7GjQoIHj9OnT/t70Ysmdd97pKFeunGPmzJmOffv2OS8JCQnO59xxxx2OunXrOmbMmOFYsmSJo2vXruYiPOfxxx83FVLbt28331/eDgkJcfz111/mce1r3+NaxUO0z73HQw89ZH5L+P2eN2+eo2/fvo7KlSub6kBf72sJFBfeeecds6NLlSplyo4XLFjg700KCv7++28jTLJfhg0b5iw1fvrppx3VqlUzIrFPnz6OjRs3+nuziy057WtexowZ43wOxd9dd91lymGjo6Mdl156qRExwnOGDx/uqFevnvndqFKlivn+2uKEaF8XvUDRPvceV111laNGjRrm+12rVi1ze8uWLUWyr0P4T+HjMEIIIYQQ3kMeFCGEEEIEHBIoQgghhAg4JFCEEEIIEXBIoAghhBAi4JBAEUIIIUTAIYEihBBCiIBDAkUIIYQQAYcEihBCCCECDgkUIYQQQgQcEihCCCGECDgkUIQQQgiBQOP/Ac+lbxh+fvkVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAHHCAYAAAAWM5p0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMg5JREFUeJzt3Qd4VNXa9vFnD4QQAgk9IXQ9SC9SRERFJEcQxCAoR8RDFSz0bl7FLhEEQUCKihQFxAYqFkRAEClSpChdQlFMQo8EEkIy37XW+WbMhIAJzsoks/+/99rvZPbemVkzHp07z7PWHsvpdDoFAADAEIepBwYAAFAIGwAAwCjCBgAAMIqwAQAAjCJsAAAAowgbAADAKMIGAAAwirABAACMImwAAACjCBuAQfv375e77rpLQkNDxbIsWbJkiVcf/9ChQ/px58yZ49XHzc/uuOMOvQHIOwgb8Hu//vqrPProo3LddddJ4cKFJSQkRJo3by6vv/66XLhwwehzd+/eXXbu3Ckvv/yyvPvuu9K4cWPxFz169NBBR72fWb2PKmip42obP358jh//2LFj8txzz8m2bdu8NGIAvlLQZ88M5IIvvvhCHnjgAQkMDJRu3bpJnTp15OLFi7J27VoZMWKE/PLLL/Lmm28aeW71Abx+/Xp56qmnpH///kaeo3Llyvp5AgICxBcKFiwo58+fl88//1w6d+7scWz+/Pk63CUnJ1/TY6uw8fzzz0uVKlWkQYMG2f69b7755pqeD4A5hA34rdjYWHnwwQf1B/LKlSulXLly7mP9+vWTAwcO6DBiyvHjx/Vt8eLFjT2HqhqoD3RfUSFOVYkWLlx4WdhYsGCBtGvXTj7++ONcGYsKPUWKFJFChQrlyvMByD7aKPBb48aNk3PnzsmsWbM8gobLv/71Lxk0aJD7/qVLl+TFF1+U66+/Xn+Iqr+o/+///k9SUlI8fk/tv+eee3R15KabbtIf9qpFM2/ePPc5qvyvQo6iKigqFKjfc7UfXD9npH5HnZfR8uXL5dZbb9WBpWjRolK9enU9pr+bs6HC1W233SbBwcH6d6OiomT37t1ZPp8KXWpM6jw1t6Rnz576gzu7HnroIfnqq6/kzJkz7n2bNm3SbRR1LLNTp07J8OHDpW7duvo1qTbM3XffLdu3b3ef891330mTJk30z2o8rnaM63WqORmqSrVlyxa5/fbbdchwvS+Z52yoVpb6Z5T59bdu3VpKlCihKygAzCJswG+p0r4KAbfccku2zn/kkUfkmWeekYYNG8rEiROlRYsWEhMTo6sjmakP6Pvvv1/+/e9/y4QJE/SHlvrAVm0ZpWPHjvoxlC5duuj5GpMmTcrR+NVjqVCjws4LL7ygn+fee++VH3744aq/9+233+oP0oSEBB0ohg4dKuvWrdMVCBVOMlMViT///FO/VvWz+kBX7YvsUq9VBYFPPvnEo6pRo0YN/V5mdvDgQT1RVr221157TYcxNa9Fvd+uD/6aNWvq16z07dtXv39qU8HC5eTJkzqkqBaLem9btmyZ5fjU3JwyZcro0JGWlqb3zZw5U7dbpkyZIhEREdl+rQCukRPwQ2fPnnWq/3lHRUVl6/xt27bp8x955BGP/cOHD9f7V65c6d5XuXJlvW/NmjXufQkJCc7AwEDnsGHD3PtiY2P1ea+++qrHY3bv3l0/RmbPPvusPt9l4sSJ+v7x48evOG7Xc8yePdu9r0GDBs6yZcs6T5486d63fft2p8PhcHbr1u2y5+vVq5fHY953333OUqVKXfE5M76O4OBg/fP999/vbNWqlf45LS3NGR4e7nz++eezfA+Sk5P1OZlfh3r/XnjhBfe+TZs2XfbaXFq0aKGPzZgxI8tjasto2bJl+vyXXnrJefDgQWfRokWdHTp0+NvXCMA7qGzALyUmJurbYsWKZev8L7/8Ut+qKkBGw4YN07eZ53bUqlVLtylc1F/OqsWh/mr3Ftdcj08//VTS09Oz9Tt//PGHXr2hqiwlS5Z0769Xr56uwrheZ0aPPfaYx331ulTVwPUeZodql6jWR1xcnG7hqNusWiiKalE5HP/7T4+qNKjncrWItm7dmu3nVI+jWizZoZYfqxVJqlqiKjGqraKqGwByB2EDfknNA1BUeyA7Dh8+rD8A1TyOjMLDw/WHvjqeUaVKlS57DNVKOX36tHjLf/7zH936UO2dsLAw3c754IMPrho8XONUH9yZqdbEiRMnJCkp6aqvRb0OJSevpW3btjrYLVq0SK9CUfMtMr+XLmr8qsVUrVo1HRhKly6tw9qOHTvk7Nmz2X7O8uXL52gyqFp+qwKYCmOTJ0+WsmXLZvt3AfwzhA34bdhQvfiff/45R7+XeYLmlRQoUCDL/U6n85qfwzWfwCUoKEjWrFmj52D897//1R/GKoCoCkXmc/+Jf/JaXFRoUBWDuXPnyuLFi69Y1VDGjBmjK0hq/sV7770ny5Yt0xNha9eune0Kjuv9yYmffvpJz2NR1BwRALmHsAG/pSYgqgt6qWtd/B21ckR90KkVFBnFx8frVRaulSXeoCoHGVduuGSuniiq2tKqVSs9kXLXrl364mCqTbFq1aorvg5l7969lx3bs2ePriKoFSomqIChPtBVNSmrSbUuH330kZ7MqVYJqfNUiyMyMvKy9yS7wS87VDVHtVxU+0tNOFUrldSKGQC5g7ABvzVy5Ej9waraECo0ZKaCiFqp4GoDKJlXjKgPeUVdL8Jb1NJa1S5QlYqMcy1URSDzEtHMXBe3yrwc10Ut8VXnqApDxg9vVeFRqy9cr9MEFSDU0uGpU6fq9tPVKimZqyYffvih/P777x77XKEoq2CWU6NGjZIjR47o90X9M1VLj9XqlCu9jwC8i4t6wW+pD3W1BFO1HtR8hYxXEFVLQdUHnJpIqdSvX19/+KiriaoPN7UM88cff9QfTh06dLjissprof6aVx9+9913nwwcOFBf02L69Olyww03eEyQVJMZVRtFBR1VsVAtgGnTpkmFChX0tTeu5NVXX9VLQps1aya9e/fWVxhVSzzVNTTUUlhTVBXm6aefzlbFSb02VWlQy5JVS0PN81DLlDP/81PzZWbMmKHng6jw0bRpU6latWqOxqUqQep9e/bZZ91LcWfPnq2vxTF69Ghd5QBgmJdWtQB51r59+5x9+vRxVqlSxVmoUCFnsWLFnM2bN3dOmTJFL8N0SU1N1cs1q1at6gwICHBWrFjRGR0d7XGOopattmvX7m+XXF5p6avyzTffOOvUqaPHU716ded777132dLXFStW6KW7ERER+jx126VLF/16Mj9H5uWh3377rX6NQUFBzpCQEGf79u2du3bt8jjH9XyZl9aqx1L71WNnd+nrlVxp6ataIlyuXDk9PjXO9evXZ7lk9dNPP3XWqlXLWbBgQY/Xqc6rXbt2ls+Z8XESExP1P6+GDRvqf74ZDRkyRC8HVs8NwCxL/T/TgQYAANgXczYAAIBRhA0AAGAUYQMAABhF2AAAAEYRNgAAgFGEDQAAYBRhAwAAGOWXVxANurG/r4cA5ElHv/e8HDsAkdJFC+abz6ULP02V/IjKBgAAMMovKxsAAOQplr3/tidsAABgmmWJnRE2AAAwzbJ3ZcPerx4AABhHZQMAANMs2igAAMAky96NBHu/egAAYByVDQAATLNoowAAAJMsezcS7P3qAQCAcVQ2AAAwzaKNAgAATLLs3Uiw96sHAMCPrVmzRtq3by8RERFiWZYsWbLE47jT6ZRnnnlGypUrJ0FBQRIZGSn79+/3OOfUqVPStWtXCQkJkeLFi0vv3r3l3LlzORoHYQMAgNxoo1he2HIoKSlJ6tevL2+88UaWx8eNGyeTJ0+WGTNmyMaNGyU4OFhat24tycnJ7nNU0Pjll19k+fLlsnTpUh1g+vbtm6Nx0EYBAMBP2yh333233rKiqhqTJk2Sp59+WqKiovS+efPmSVhYmK6APPjgg7J79275+uuvZdOmTdK4cWN9zpQpU6Rt27Yyfvx4XTHJDiobAAD4aWXjamJjYyUuLk63TlxCQ0OladOmsn79en1f3arWiStoKOp8h8OhKyHZRWUDAIB8IiUlRW8ZBQYG6i2nVNBQVCUjI3XfdUzdli1b1uN4wYIFpWTJku5zsoPKBgAAudFGsf75FhMTo6sPGTe1L6+jsgEAQD6ZsxEdPUqGDh3qse9aqhpKeHi4vo2Pj9erUVzU/QYNGrjPSUhI8Pi9S5cu6RUqrt/PDiobAADkE4GBgXoJasbtWsNG1apVdWBYsWKFe19iYqKei9GsWTN9X92eOXNGtmzZ4j5n5cqVkp6erud2ZBeVDQAATHP45gqi6noYBw4c8JgUum3bNj3nolKlSjJ48GB56aWXpFq1ajp8jB49Wq8w6dChgz6/Zs2a0qZNG+nTp49eHpuamir9+/fXK1WyuxJFIWwAAOCnS183b94sLVu2dN93tWC6d+8uc+bMkZEjR+prcajrZqgKxq233qqXuhYuXNj9O/Pnz9cBo1WrVnoVSqdOnfS1OXLCcqqFtn4m6Mb+vh4CkCcd/X6Sr4cA5Dmli5r/uzvozpe98jgXVj4l+RGVDQAATLP4IjYAAGCSZe/1GPZ+9QAAwDgqGwAAmGbRRgEAACZZ9m4kEDYAADDNsndlw95RCwAAGEdlAwAA0yx7/21P2AAAwDSLNgoAAIAxVDYAADDNsvff9oQNAABMs2ijAAAAGENlAwAA0yx7/21P2AAAwDTL3mHD3q8eAAAYR2UDAADTLHtPECVsAABgmmXvRgJhAwAA0yx7VzbsHbUAAIBxVDYAADDNsvff9oQNAABMs2ijAAAAGENlAwAAwyybVzYIGwAAGGbZPGzQRgEAAEZR2QAAwDRLbI2wAQCAYRZtFAAAAHOobAAAYJhl88oGYQMAAMMswgYAADDJsnnYYM4GAAAwisoGAACmWWJrhA0AAAyzaKMAAACYQ2UDAADDLJtXNggbAAAYZtk8bNBGAQAARlHZAADAMMvmlQ3CBgAApllia7RRAACAUVQ2AAAwzKKNAgAATLIIGwAAwCTL5mGDORsAAMAoKhsAAJhmia0RNgAAMMyijQIAAGAOlQ0AAAyzbF7ZIGwAAGCYZfOwQRsFAAAYRWUDAADDLJtXNggbAACYZomt0UYBAABGUdkAAMAwizYKAAAwySJsAAAAkyybhw3mbAAAAKOobAAAYJoltkbYAADAMIs2CgAAgDlUNpBjzRteL0O6RUrDWpWkXJlQ6TzkTfn8ux0e54x+vJ30vO8WKV4sSNZvPygDxyySX48cdx/f88XzUjmilOfvTP5Uxs9enmuvAzBt29bNsmDeO7Jn9y45eeK4xIyfLLe3bKWPXUpNlTenT5b1a7+XY7//JsFFi0qTps3ksQFDpEyZsr4eOrzMorIB5ExwUKDs3Pe7DI5ZlOXxYT0i5YkuLWTgmPfl9m7jJenCRfn8jX4SWMgz2z4/balUiYx2b9MWrs6lVwDkjgsXLsi/bqguw0Y9fdmx5ORk2btnt/R45DF5Z/6HMmb863LkUKyMGtLfJ2OF+bBheWHLrwgbyLFvftilg8JnqzyrGS79HmopY99aJku/2yk/7z8mj4yepysg97as73HeuaRkiT/5p3s7n3wxl14BkDuaNb9N+j4xSFrcGXnZsaLFisnr096WVne1kcpVqkqduvVl6KinZO/uXyTuj2M+GS/8S1pamowePVqqVq0qQUFBcv3118uLL74oTqfTfY76+ZlnnpFy5crpcyIjI2X//v3+1UY5ceKEvPPOO7J+/XqJi4vT+8LDw+WWW26RHj16SJkyZXw5PFyDKuVL6WCxcuMe977Ec8my6edD0rReFflw2Rb3/mE975In+9wtR+NOyQdfbZbJ81dJWlq6j0YO+N65c+f0X6/FioX4eijwMssHVYmxY8fK9OnTZe7cuVK7dm3ZvHmz9OzZU0JDQ2XgwIH6nHHjxsnkyZP1OSqUqHDSunVr2bVrlxQuXDj/h41NmzbpF1SkSBGdpG644Qa9Pz4+Xr/wV155RZYtWyaNGzf21RBxDcJL/+8/kgmn/vTYn3DyTwkr9dd/QFXL5KfdR+V0YpLcXP86eWHAvRJeJlRGTfgk18cM5AUpKSkyffJrEtm6rZ6/AT9j5f5Trlu3TqKioqRdu3b6fpUqVWThwoXy448/uqsakyZNkqefflqfp8ybN0/CwsJkyZIl8uCDD+b/sDFgwAB54IEHZMaMGZclPvUGPPbYY/ocVfX4u39B1ebx++lpYjkKGBk3vGPyeyvdP6tWy8XUSzL1qS4yevJn+mfATtRk0dFPDtX/7RsR/Yyvh4M8LCWLz7zAwEC9Zaa6BG+++abs27dP/0G/fft2Wbt2rbz22mv6eGxsrO4qqD/4XVTVo2nTpvqz15thw2dzNtSLHjJkSJalJbVPHdu2bdvfPk5MTIx+czJul+L/KtUjd8WdSNS3ZUsW89hftlQxiT/5v2NZ2bTzkAQEFJDKESWNjxHIe0FjmMT/cUwmTXubqoafsrw0QTSrzzy1LytPPvmkDgw1atSQgIAAufHGG2Xw4MHStWtXfdw1fUFVMjJS913H8n3YUHMzXKWcrKhjmd+ArERHR8vZs2c9toJhjbw8WmTXod9Pyh/Hz0rLptXd+4oFF5YmdarIxh2Hrvh79atX0PM1jmdqvwB2CBpHjx6WSdNnSWjx4r4eEvJ42IjO4jNP7cvKBx98IPPnz5cFCxbI1q1b9byM8ePH69vc5rM2yvDhw6Vv376yZcsWadWqlTtYqDkbK1askLfeeku/KX8nq/IRLRSzgoMKyfUVy3hMCq13Q3k5nXhejsadljcWrJJRj7SRA0eO6/Dx7BPtdAD5bNV2fX7TelWlSZ3KsnrzfvkzKVlurldVxg7vJAu/3CRn/rzgw1cGeNf580ny29Ej7vvHjv0m+/bulpCQUClduow8NWqI7NuzW8ZNekPS09L0tTiUkNBQCQgo5MORw9ssL83ZuFLLJCsjRoxwVzeUunXryuHDh3UlpHv37vqPftfnrlqN4qLuN2jQQPwibPTr109Kly4tEydOlGnTpuklOkqBAgWkUaNGMmfOHOncubOvhoeraFirsnzz9iD3/XHDO+nbdz/bIH2ffU8mzPlWigQFytSnu+iLeq3b9qvc22+apFz831yMlIup8kDrRvLUY20lMKCgHDp2UqbMXyWT3/1rHgfgD/bs+kUGPNrTfX/Ka+P07d33REnvR/vJ2tWr9P0eXf7375D7vJmzpWHjm3J5tPA358+fF4fDs4GhPmPT0/+36k+tPlGBQ/2B7woXiYmJsnHjRnn88ce9OhbLmXHBrY+kpqbqZbCKCiCqt/RPBN3IRXGArBz9fpKvhwDkOaWLmv+7u9qIr73yOPtfbZPtc9UlJL799luZOXOmXvr6008/6Y5Cr1699LJYRd2q1Z8Zl77u2LHDf5a+ZqTCRcYSDgAA/sTywdLXKVOm6PDwxBNPSEJCgkRERMijjz6qL+LlMnLkSElKStIh5MyZM3LrrbfK119/7dWgkWcqG95GZQPIGpUNwDeVjRtGeqeysW9c9isbeUmeqGwAAODPrHz8vSbeQNgAAMAwy95Zgy9iAwAAZlHZAADAMIfD3qUNwgYAAIZZ9s4atFEAAIBZVDYAADDMsnlpg7ABAIBhlr2zBmEDAADTLJunDeZsAAAAo6hsAABgmGXzygZhAwAAwyx7Zw3aKAAAwCwqGwAAGGbZvLRB2AAAwDDL3lmDNgoAADCLygYAAIZZNi9tEDYAADDMsnfWoI0CAADMorIBAIBhls1LG4QNAAAMs+ydNQgbAACYZtk8bTBnAwAAGEVlAwAAwyx7FzYIGwAAmGbZPG3QRgEAAEZR2QAAwDDL3oUNwgYAAKZZNk8btFEAAIBRVDYAADDMsndhg7ABAIBpls3TBm0UAABgFJUNAAAMs2xe2SBsAABgmGXvrEHYAADANMvmaYM5GwAAwCgqGwAAGGbZu7BB2AAAwDTL5mmDNgoAADCKygYAAIZZ9i5sEDYAADDNYfO0QRsFAAAYRWUDAADDLHsXNggbAACYZtk8bRA2AAAwzGHvrMGcDQAAYBaVDQAADLNoowAAAJMse2cN2igAAMAsKhsAABhmib1LG4QNAAAMc9g7a9BGAQAAZlHZAADAMMvmM0QJGwAAGGbZO2vQRgEAAGZR2QAAwDCHzUsbhA0AAAyz7J01CBsAAJhm2TxtMGcDAAAYRWUDAADDLHsXNggbAACY5rB52qCNAgAAjKKyAQCAYZbYG2EDAADDLNooAADAH/3+++/y8MMPS6lSpSQoKEjq1q0rmzdvdh93Op3yzDPPSLly5fTxyMhI2b9/v9fHQdgAACAXvmLe4YUtJ06fPi3NmzeXgIAA+eqrr2TXrl0yYcIEKVGihPuccePGyeTJk2XGjBmyceNGCQ4OltatW0tycnLut1E+++yzbD/gvffe+0/GAwCA37F80EYZO3asVKxYUWbPnu3eV7VqVY+qxqRJk+Tpp5+WqKgovW/evHkSFhYmS5YskQcffDB3w0aHDh2y/WampaX90zEBAIAspKSk6C2jwMBAvWVVKFBVigceeEBWr14t5cuXlyeeeEL69Omjj8fGxkpcXJxunbiEhoZK06ZNZf369V4NG9lqo6Snp2drI2gAAHA5y/LOFhMTowNBxk3ty8rBgwdl+vTpUq1aNVm2bJk8/vjjMnDgQJk7d64+roKGoioZGan7rmPewmoUAADySRslOjpahg4d6rEvq6qGoooAjRs3ljFjxuj7N954o/z88896fkb37t0lN11T2EhKStIlmSNHjsjFixc9jqnUBAAA/uLw0pSNK7VMsqJWmNSqVctjX82aNeXjjz/WP4eHh+vb+Ph4fa6Lut+gQQPxadj46aefpG3btnL+/HkdOkqWLCknTpyQIkWKSNmyZQkbAADkAc2bN5e9e/d67Nu3b59UrlzZPVlUBY4VK1a4w0ViYqJelaJaLj5d+jpkyBBp3769XlKj1uRu2LBBDh8+LI0aNZLx48d7dXAAAPhLG8XywpbTz2v1Ga3aKAcOHJAFCxbIm2++Kf369XOPafDgwfLSSy/pyaQ7d+6Ubt26SURERLYXhhirbGzbtk1mzpwpDodDChQooGfFXnfddXqtruoBdezY0asDBAAgv7N88JxNmjSRxYsX63keL7zwgq5kqKWuXbt2dZ8zcuRI3aXo27evnDlzRm699Vb5+uuvpXDhwr4NG+riICpoKKptouZtqB6QmhF79OhRrw4OAABcu3vuuUdvV6KqGyqIqM2kHIcNNZt106ZNeilNixYt9GVO1ZyNd999V+rUqWNmlAAA5GMOvhslZ1TvxzVr9eWXX9aXPVUTSY4fP657QQAAwMx1NvKrHFc21JpdF9VGUb0dAACAK+GiXgAAGGbl57KEL8KGms16tTdNXR4VAAD8xbJ31sh52FBrcjNKTU3VF/pS7ZQRI0Z4c2wAAMCOYWPQoEFZ7n/jjTdk8+bN3hgTAAB+xWHz0kaOV6Ncyd133+2+3joAAPiLxWoU7/joo4/096QAAABPVn5OCr66qFfGN83pdOrvvVfX2Zg2bZq3xwcAAOwWNqKiojzChrp0eZkyZeSOO+6QGjVqSF5wetNUXw8ByJPaTF3n6yEAec53g2/JP3MW7BI2nnvuOTMjAQDAT1k2b6PkOGypb3pNSEi4bP/Jkyf1MQAAgH9U2VBzNLKivmq+UKFCOX04AAD8nsPehY3sh43Jkye7S0Fvv/22FC1a1H0sLS1N1qxZk2fmbAAAkJc4CBvZM3HiRHdlY8aMGR4tE1XRqFKlit4PAABwTWEjNjZW37Zs2VI++eQT/dXyAADg71k2nyCa4zkbq1atMjMSAAD8lMPeWSPnq1E6deokY8eOvWz/uHHj5IEHHvDWuAAAgF3DhpoI2rZt2yy/G0UdAwAAniy+GyVnzp07l+US14CAAElMTPTWuAAA8BuO/JwUfFHZqFu3rixatOiy/e+//77UqlXLW+MCAMCvPmwdXthsU9kYPXq0dOzYUX799Ve588479b4VK1bIggUL9De/AgAA/KOw0b59e1myZImMGTNGh4ugoCCpX7++rFy5kq+YBwAgC5a9uyg5DxtKu3bt9KaoeRoLFy6U4cOHy5YtW/TVRAEAwF8cNk8b19wCUitPunfvLhERETJhwgTdUtmwYYN3RwcAAOxV2YiLi5M5c+bIrFmzdEWjc+fO+gvYVFuFyaEAAGTNsndhI/uVDTVXo3r16rJjxw6ZNGmSHDt2TKZMmWJ2dAAA+MkVRB1e2Py+svHVV1/JwIED5fHHH5dq1aqZHRUAALBfZWPt2rXy559/SqNGjaRp06YydepUOXHihNnRAQDgJxNEHV7Y/D5s3HzzzfLWW2/JH3/8IY8++qi+iJeaHJqeni7Lly/XQQQAAFzOsvnlynO8GiU4OFh69eqlKx07d+6UYcOGySuvvCJly5aVe++918woAQBAvvWPrn6qJoyqb3v97bff9LU2AADA5RxMEP3nChQoIB06dNAbAADwZEk+Tgp5JWwAAIArc9g7a+TrL5EDAAD5AJUNAAAMc9i8skHYAADAMCs/r1v1AtooAADAKCobAAAY5rB3YYOwAQCAaZbNwwZtFAAAYBSVDQAADHPYvLRB2AAAwDCHvbMGbRQAAGAWlQ0AAAyzbF7ZIGwAAGCYgy9iAwAAJln2zhrM2QAAAGZR2QAAwDCHzSsbhA0AAAxz2LyPQhsFAAAYRWUDAADDLHsXNggbAACY5rB52qCNAgAAjKKyAQCAYZa9CxuEDQAATHOIvdn99QMAAMOobAAAYJhl8z4KYQMAAMMssTfCBgAAhjlsXtlgzgYAADCKygYAAIZZYm9UNgAAMMyyvLP9E6+88oqeqDp48GD3vuTkZOnXr5+UKlVKihYtKp06dZL4+HjxNsIGAAB+btOmTTJz5kypV6+ex/4hQ4bI559/Lh9++KGsXr1ajh07Jh07dvT68xM2AAAwzLIsr2zX4ty5c9K1a1d56623pESJEu79Z8+elVmzZslrr70md955pzRq1Ehmz54t69atkw0bNnjx1RM2AAAwzuGl7VqoNkm7du0kMjLSY/+WLVskNTXVY3+NGjWkUqVKsn79evEmJogCAJBPpKSk6C2jwMBAvWXl/fffl61bt+o2SmZxcXFSqFAhKV68uMf+sLAwfcybqGwAAJBP2igxMTESGhrqsal9WTl69KgMGjRI5s+fL4ULFxZforIBAEA+WfoaHR0tQ4cO9dh3paqGapMkJCRIw4YN3fvS0tJkzZo1MnXqVFm2bJlcvHhRzpw541HdUKtRwsPDxZsIGwAA5BOBV2mZZNaqVSvZuXOnx76ePXvqeRmjRo2SihUrSkBAgKxYsUIveVX27t0rR44ckWbNmnl13IQNAAD88IvYihUrJnXq1PHYFxwcrK+p4drfu3dvXSkpWbKkhISEyIABA3TQuPnmm706FsIGAACGOSRvmjhxojgcDl3ZUBNPW7duLdOmTfP681hOp9Mpfib5kq9HAORNbaau8/UQgDznu8G3GH+OxTu8s7rjvnrenUth97AFAAD8BG0UAAAMs8TeCBsAABhm2Txt0EYBAABGUdkAAMAwh80bKYQNAAAMs+ydNWijAAAAs6hsAABgmEUbBQAAmGTZO2vQRgEAAGZR2QAAwDAHbRQAAGCSZe+sQdgAAMA0y+ZhgzkbAADAKCobAAAYZjFnAwAAmOSwd9agjQIAAMyisgEAgGEWbRQAAGCSZe+sQRsFAACYRWUDAADDLNooAADAJIe9swZtFAAAYBaVDRgRHx8vk157VX74/ntJTr4gFStVlhdeGiO169T19dCAXFM6uJA8emtlualKcSkc4JDfzyTL2G8OyN6EJH28RJEAfbxxpeJSNLCA7Pg9UV7/LlafB/9i0UYBvCvx7Fnp8XAXaXxTU3ljxltSomQJOXL4sISEhPp6aECuUeFh6n/qyE9HE2XUkt1y5kKqVCheWP5MueQ+56X2NeRSWro89fkeOX/xkjzQMEImdKwtPeb9JMmX0n06fniXZe+sQdiA970z6y0JCw+XF1+Oce+rUKGiT8cE5LaHGpeXhD8vytjlB9z74hJT3D+r4FG7XDEdLA6duqD3TVxxUD7p20RaVS8tX/yS4JNxwwxL7I05G/C61atWSu3adWT4kIFyx23NpHOnDvLxhx/4elhArrrlupKyN/6cPNf2Blnct4m89VA9aVenrPt4QIH//ef3YtpfFQyniKSmpUvd8iE+GTNgy7Bx9OhR6dWr11XPSUlJkcTERI9N7YPv/PbbUflg0UKpVLmKTH9zlnT+TxcZG/OSfLZksa+HBuSaiNDCElUvXH47kywjFu+ST3fEy8A7qkrrmmX08SOnL+hKR5/mlXXLpaDDki6Ny0vZYoFSMjjA18OHlzksyytbfpWnw8apU6dk7ty5Vz0nJiZGQkNDPbZXx/5VvkfuS093Ss1atWXg4KFSs2Ytub/zf6Tj/Z3lww/e9/XQgFyjPhf2JZyTt9cdkQPHk2Tpz/GydGeC3FsvXB9PS3fKM0v3SMUSQbL08aayrP/NcmOFENkQe1qcqsQBv2J5acuvfDpn47PPPrvq8YMHD/7tY0RHR8vQoUM99jkLBP7jseHalSlTRq67/nqPfdddd518u3yZz8YE5LaTSaly+P/PxXA5fPq83F6tpPv+voQkeWT+dgkuVEAKFrDk7IVLMu3Burr9AvgTn4aNDh06iGVZ4rxKjFfHryYwMFBvGSX/NdkbPtDgxoZyKDbWY9/hQ4ckIqK8z8YE5LafjyXqqkVGFYsHSXyGSaIuSRfT9G354oWletmi8s66I7k2TuQSS2zNp22UcuXKySeffCLp6elZblu3bvXl8HCNHu7WXXbu2C5vvzlDL3n9cunn8tFHH8h/ujzk66EBuebDn/6QWuFFpWuT8lI+tLBeYXJP3TBZsj3OfU6LaqWkQYUQKRcSKM2vKyETOtaStb+eks1Hzvp07DBznQ3LC/+XX/m0stGoUSPZsmWLREVFZXn876oeyJvq1K0nr70+VSZPek1mTn9DyleoICNH/Z+0u+deXw8NyDWqFTJ66V7p07ySdG9aUf5ITJapq2Pl270n3OeUCg6QfrdX0Rf3Um2Xb3YnyLyNv/l03IAJltOHn+bff/+9JCUlSZs2bbI8ro5t3rxZWrRokaPHpY0CZK3N1HW+HgKQ53w3+Bbjz/HjQe9Uq266Ln9eHNGnlY3bbrvtqseDg4NzHDQAAMhrLLG3PL30FQAA5H9crhwAANMssTXCBgAAhlk2TxuEDQAADLPsnTWYswEAAMyisgEAgGGW2BthAwAA0yyxNdooAADAKCobAAAYZtm8tEHYAADAMMveWYM2CgAAMIvKBgAAhllib4QNAABMs8TWaKMAAACjqGwAAGCYZfPSBmEDAADDLHtnDcIGAACmWWJvzNkAAABGUdkAAMA0S2yNsAEAgGGWzdMGbRQAAGAUlQ0AAAyz7F3YIGwAAGCaJfZGGwUAABhFZQMAANMssTXCBgAAhlk2Txu0UQAAgFFUNgAAMMyyd2GDsAEAgGmW2BttFAAAciNtWF7YciAmJkaaNGkixYoVk7Jly0qHDh1k7969HuckJydLv379pFSpUlK0aFHp1KmTxMfHe/e1EzYAAPBPq1ev1kFiw4YNsnz5cklNTZW77rpLkpKS3OcMGTJEPv/8c/nwww/1+ceOHZOOHTt6fSyW0+l0ip9JvuTrEQB5U5up63w9BCDP+W7wLcafY3/8Ba88TrWwoGv+3ePHj+sKhwoVt99+u5w9e1bKlCkjCxYskPvvv1+fs2fPHqlZs6asX79ebr75ZvEWKhsAAOTCBFHLC1tKSookJiZ6bGpfdqhwoZQsWVLfbtmyRVc7IiMj3efUqFFDKlWqpMOGNxE2AADIJ2JiYiQ0NNRjU/v+Tnp6ugwePFiaN28uderU0fvi4uKkUKFCUrx4cY9zw8LC9DFvYjUKAAD5ZDVKdHS0DB061GNfYGDg3/6emrvx888/y9q1a8UXCBsAAOSTtBEYGJitcJFR//79ZenSpbJmzRqpUKGCe394eLhcvHhRzpw541HdUKtR1DFvoo0CAIAfcjqdOmgsXrxYVq5cKVWrVvU43qhRIwkICJAVK1a496mlsUeOHJFmzZp5dSxUNgAA8MPvRunXr59eafLpp5/qa2245mGoeR5BQUH6tnfv3rotoyaNhoSEyIABA3TQ8OZKFIWwAQCAH16ufPr06fr2jjvu8Ng/e/Zs6dGjh/554sSJ4nA49MW81KqW1q1by7Rp07w+Fq6zAdgI19kAfHOdjdgTyV55nKqlC0t+RGUDAADDLLE3wgYAAKZZYmuEDQAA/HCCaF7C0lcAAGAUlQ0AAPxwNUpeQtgAAMAwS+yNNgoAADCKygYAAIZZNi9tEDYAADDOEjujjQIAAIyisgEAgGGWvQsbhA0AAEyzxN5oowAAAKOobAAAYJhl89IGYQMAAMMsmzdSCBsAAJhmia0xZwMAABhFZQMAAMMssTfCBgAAhlk2Txu0UQAAgFFUNgAAMMyyeSOFsAEAgGmW2BptFAAAYBSVDQAADLPE3ggbAAAYZtk8bdBGAQAARlHZAADAMMvmjRTCBgAAhln2zhq0UQAAgFmEDQAAYBRtFAAADLNs3kYhbAAAYJhl8wmitFEAAIBRVDYAADDMsndhg7ABAIBpltgbbRQAAGAUlQ0AAEyzxNYIGwAAGGbZPG3QRgEAAEZR2QAAwDDL3oUNwgYAAKZZYm+EDQAATLPE1pizAQAAjKKyAQCAYZbNSxuEDQAADLPsnTVoowAAALMsp9PpNPwcsKmUlBSJiYmR6OhoCQwM9PVwgDyDfzdgN4QNGJOYmCihoaFy9uxZCQkJ8fVwgDyDfzdgN7RRAACAUYQNAABgFGEDAAAYRdiAMWri27PPPssEOCAT/t2A3TBBFAAAGEVlAwAAGEXYAAAARhE2AACAUYQNAABgFGEDxrzxxhtSpUoVKVy4sDRt2lR+/PFHXw8J8Kk1a9ZI+/btJSIiQizLkiVLlvh6SECuIGzAiEWLFsnQoUP18r6tW7dK/fr1pXXr1pKQkODroQE+k5SUpP9dUEEcsBOWvsIIVclo0qSJTJ06Vd9PT0+XihUryoABA+TJJ5/09fAAn1OVjcWLF0uHDh18PRTAOCob8LqLFy/Kli1bJDIy0r3P4XDo++vXr/fp2AAAuY+wAa87ceKEpKWlSVhYmMd+dT8uLs5n4wIA+AZhAwAAGEXYgNeVLl1aChQoIPHx8R771f3w8HCfjQsA4BuEDXhdoUKFpFGjRrJixQr3PjVBVN1v1qyZT8cGAMh9BX3wnLABtey1e/fu0rhxY7nppptk0qRJetlfz549fT00wGfOnTsnBw4ccN+PjY2Vbdu2ScmSJaVSpUo+HRtgEktfYYxa9vrqq6/qSaENGjSQyZMn6yWxgF1999130rJly8v2q2A+Z84cn4wJyA2EDQAAYBRzNgAAgFGEDQAAYBRhAwAAGEXYAAAARhE2AACAUYQNAABgFGEDAAAYRdgA/FCPHj2kQ4cO7vt33HGHDB482CcXsbIsS86cOZPrzw0g7yBsALkcAtSHr9rUd8j861//khdeeEEuXbpk9Hk/+eQTefHFF7N1LgEBgLfx3ShALmvTpo3Mnj1bUlJS5Msvv5R+/fpJQECAREdHe5x38eJFHUi8QX33BgD4CpUNIJcFBgZKeHi4VK5cWR5//HGJjIyUzz77zN36ePnllyUiIkKqV6+uzz969Kh07txZihcvrkNDVFSUHDp0yP14aWlp+ovv1PFSpUrJyJEjJfO3EGRuo6igM2rUKKlYsaIej6qwzJo1Sz+u67s7SpQooSscalyub+6NiYmRqlWrSlBQkNSvX18++ugjj+dR4emGG27Qx9XjZBwnAPsibAA+pj6YVRVDWbFihezdu1eWL18uS5culdTUVGndurUUK1ZMvv/+e/nhhx+kaNGiujri+p0JEyboL/F65513ZO3atXLq1ClZvHjxVZ+zW7dusnDhQv3leLt375aZM2fqx1Xh4+OPP9bnqHH88ccf8vrrr+v7KmjMmzdPZsyYIb/88osMGTJEHn74YVm9erU7FHXs2FHat2+vv8n0kUcekSeffNLwuwcgX1BfxAYgd3Tv3t0ZFRWlf05PT3cuX77cGRgY6Bw+fLg+FhYW5kxJSXGf/+677zqrV6+uz3VRx4OCgpzLli3T98uVK+ccN26c+3hqaqqzQoUK7udRWrRo4Rw0aJD+ee/evarsoZ87K6tWrdLHT58+7d6XnJzsLFKkiHPdunUe5/bu3dvZpUsX/XN0dLSzVq1aHsdHjRp12WMBsB/mbAC5TFUsVBVBVS1Ua+Khhx6S5557Ts/dqFu3rsc8je3bt8uBAwd0ZSOj5ORk+fXXX+Xs2bO6+tC0aVP3sYIFC0rjxo0va6W4qKpDgQIFpEWLFtkesxrD+fPn5d///rfHflVdufHGG/XPqkKScRxKs2bNsv0cAPwXYQPIZWouw/Tp03WoUHMzVDhwCQ4O9jj33Llz0qhRI5k/f/5lj1OmTJlrbtvklBqH8sUXX0j58uU9jqk5HwBwNYQNIJepQKEmZGZHw4YNZdGiRVK2bFkJCQnJ8pxy5crJxo0b5fbbb9f31TLaLVu26N/NiqqeqIqKmmuhJqdm5qqsqImnLrVq1dKh4siRI1esiNSsWVNPdM1ow4YN2XqdAPwbE0SBPKxr165SunRpvQJFTRCNjY3V18EYOHCg/Pbbb/qcQYMGySuvvCJLliyRPXv2yBNPPHHVa2RUqVJFunfvLr169dK/43rMDz74QB9Xq2TUKhTV7jl+/Liuaqg2zvDhw/Wk0Llz5+oWztatW2XKlCn6vvLYY4/J/v37ZcSIEXpy6YIFC/TEVQAgbAB5WJEiRWTNmjVSqVIlvdJDVQ969+6t52y4Kh3Dhg2T//73vzpAqDkSKhjcd999V31c1ca5//77dTCpUaOG9OnTR5KSkvQx1SZ5/vnn9UqSsLAw6d+/v96vLgo2evRovSpFjUOtiFFtFbUUVlFjVCtZVIBRy2LVqpUxY8YYf48A5H2WmiXq60EAAAD/RWUDAAAYRdgAAABGETYAAIBRhA0AAGAUYQMAABhF2AAAAEYRNgAAgFGEDQAAYBRhAwAAGEXYAAAARhE2AACAUYQNAAAgJv0/0lNdbA7y3I8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       117\n",
      "           1       0.85      0.92      0.88        75\n",
      "\n",
      "    accuracy                           0.91       192\n",
      "   macro avg       0.90      0.91      0.90       192\n",
      "weighted avg       0.91      0.91      0.91       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data augmentation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2))\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hybrid Model with Advanced Feature Fusion\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\", add_pooling_layer=False)\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        weighted_features = self.batch_norm(fused_features)\n",
    "        weighted_features = self.dropout(weighted_features)\n",
    "        return self.fc(weighted_features)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Testing Phase\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        running_test_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item()\n",
    "                correct_test += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "                all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_accuracy = correct_test / total_test * 100\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Loss: {avg_test_loss:.4f} - Test Acc: {test_accuracy:.2f}%\")\n",
    "        scheduler.step(avg_test_loss)\n",
    "    \n",
    "    torch.save(model.state_dict(), \"hybrid_modell.pth\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(epochs), test_losses, label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Initialize and train model\n",
    "model = HybridModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdd1c5-557a-4cd0-b7d4-5632d8e90108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7b16d-9685-47cc-80b4-6dec427483cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a86c28-6d1e-4ce0-b8eb-69c66fa063e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017535e-8639-4dd8-8dbe-0f7bb5e41808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216db222-151f-4589-8eea-7eb582892052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0616e0d-2670-4a16-b0ba-7470f9572f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea073b-cf11-4c40-bfc8-c5b2feac2212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa0204-d994-4732-adc8-70a33b276ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063e06c-5f33-4f08-9cbc-8fd11fc22e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6dd3e-9c41-4e25-a324-ccf259992b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07f2f2-a0e3-4679-927b-83e311507036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab326392-cb4c-4b27-b273-3b5f48ca3371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422bf84-6583-4af2-9e60-1a99032d42cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d263ca6-0d9c-4164-82cb-cdc8d8e9811a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d44873-6207-4baf-99ec-34e893e9eaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4d07c-997e-4246-982b-28653ea0c309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28883484-dd8b-447b-af46-0ca572a3d2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ba8e1-8416-431d-ae3e-c7de3c6062e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c74b99-2187-4411-8d73-f7ad45dfcfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936aa3b-8dda-467d-9503-cf36bea2c3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed76dbb-62bf-493e-8d1f-9910395d22a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9aa1f-64e1-403f-a565-431dc9ea023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9926f8-0fd0-4590-bf6b-507397efa1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a1a8c-d188-4428-9037-5c8753e888d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae4dd82-d5af-43a9-97a3-c5a1cc7e296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    110\u001b[39m         scheduler.step()\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m#  Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_hybrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_hybrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs)\u001b[39m\n\u001b[32m     85\u001b[39m outputs = model(inputs)\n\u001b[32m     86\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m optimizer.step()\n\u001b[32m     89\u001b[39m running_train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Improved Hybrid Model\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False  # Freeze early CNN layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        self.projection = nn.Linear(1280, 768)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        for param in self.vit.encoder.layer[:6].parameters():\n",
    "            param.requires_grad = False  # Freeze early ViT layers\n",
    "        self.weight_cnn = nn.Parameter(torch.ones(1))\n",
    "        self.weight_vit = nn.Parameter(torch.ones(1))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.projection(self.cnn(x).flatten(1))\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        weights = self.softmax(torch.cat([self.weight_cnn, self.weight_vit], dim=0))\n",
    "        fused_features = weights[0] * cnn_features + weights[1] * vit_features\n",
    "        fused_features = self.batch_norm(fused_features)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "#  Load dataset\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+drishti/Testing/\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#  Initialize model\n",
    "hybrid_model = HybridModel().to(device)\n",
    "\n",
    "#  Define loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=3e-5, weight_decay=5e-4)\n",
    "scheduler_hybrid = get_cosine_schedule_with_warmup(optimizer_hybrid, num_warmup_steps=5, num_training_steps=50)\n",
    "\n",
    "#  Train function\n",
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs=50):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in dataloader_train:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(dataloader_train)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_val:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(dataloader_val)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "\n",
    "#  Train the model\n",
    "train_model(hybrid_model, dataloader_train, dataloader_test, criterion, optimizer_hybrid, scheduler_hybrid, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377cc58-d820-4a2e-928a-08141c91c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Paths to Dataset\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d567af-3188-4ad7-9855-9da22f726988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fd20b-b888-4de9-831f-6c8102cfed20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b42f00-b88d-41fc-8ab2-0c566d4c5bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f287585-236b-4d01-915c-ed0dfd2e7687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba6142-5ff8-4eeb-851a-8dd851e27ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bd54a-d7aa-4f8d-aaf7-8d74b77c4d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7749d-a48b-4633-88b7-e033ad73d8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac3274c-dc97-4529-8edc-6af3a4883b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afc7ca-8513-47b3-b238-1ce8e470081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/8f/ws6g2jvs4td4pv9rk5y8s2f00000gn/T/ipykernel_12936/3204067662.py:80: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/var/folders/8f/ws6g2jvs4td4pv9rk5y8s2f00000gn/T/ipykernel_12936/3204067662.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision context\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Acc: 47.88%, Val Acc: 53.51%\n",
      "Epoch [2/50] - Train Acc: 69.10%, Val Acc: 79.34%\n",
      "Epoch [3/50] - Train Acc: 80.72%, Val Acc: 83.03%\n",
      "Epoch [4/50] - Train Acc: 84.41%, Val Acc: 81.92%\n",
      "Epoch [5/50] - Train Acc: 86.62%, Val Acc: 84.50%\n",
      "Epoch [6/50] - Train Acc: 87.36%, Val Acc: 83.39%\n",
      "Epoch [7/50] - Train Acc: 89.11%, Val Acc: 84.87%\n",
      "Epoch [8/50] - Train Acc: 89.85%, Val Acc: 81.92%\n",
      "Epoch [9/50] - Train Acc: 90.68%, Val Acc: 82.29%\n",
      "Epoch [10/50] - Train Acc: 88.75%, Val Acc: 84.13%\n",
      "Epoch [11/50] - Train Acc: 90.13%, Val Acc: 84.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Reduce rotation range\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Lighter jitter\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Hybrid Model with ViT, CNN (EfficientNet), and Attention Mechanism\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False  # Freeze early CNN layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        self.projection = nn.Linear(1280, 768)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        for param in self.vit.encoder.layer[:6].parameters():\n",
    "            param.requires_grad = False  # Freeze early ViT layers\n",
    "        \n",
    "        self.weight_cnn = nn.Parameter(torch.ones(1))\n",
    "        self.weight_vit = nn.Parameter(torch.ones(1))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.projection(self.cnn(x).flatten(1))\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        weights = self.softmax(torch.cat([self.weight_cnn, self.weight_vit], dim=0))\n",
    "        fused_features = weights[0] * cnn_features + weights[1] * vit_features\n",
    "        fused_features = self.batch_norm(fused_features)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "#  Load dataset with smaller batch size to optimize memory\n",
    "batch_size = 16  # Reduce batch size to manage memory\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "#  Initialize model\n",
    "hybrid_model = HybridModel().to(device)\n",
    "\n",
    "#  Define loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=3e-5, weight_decay=5e-4)\n",
    "scheduler_hybrid = get_cosine_schedule_with_warmup(optimizer_hybrid, num_warmup_steps=5, num_training_steps=50)\n",
    "\n",
    "#  Mixed Precision Training Setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "#  Training Loop for Hybrid Model with Mixed Precision\n",
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs=50):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in dataloader_train:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():  # Mixed precision context\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(dataloader_train)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_val:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(dataloader_val)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "\n",
    "#  Train the Hybrid Model\n",
    "train_model(hybrid_model, dataloader_train, dataloader_test, criterion, optimizer_hybrid, scheduler_hybrid, epochs=50)\n",
    "\n",
    "#  Generator and Discriminator for GANs\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 1280 * 112 * 112)  # Reduced image size\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc1(z)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.tanh(x)\n",
    "        return x.view(-1, 1280, 112, 112)  # Reduced image size\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 56 * 56, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "#  Training Loop for GAN\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs=50, z_dim=100, lr=0.0002):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for real_images, _ in dataloader:\n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            outputs_real = discriminator(real_images)\n",
    "            loss_d_real = criterion(outputs_real, real_labels)\n",
    "            \n",
    "            z = torch.randn(batch_size, z_dim).to(device)\n",
    "            fake_images = generator(z)\n",
    "            outputs_fake = discriminator(fake_images.detach())\n",
    "            loss_d_fake = criterion(outputs_fake, fake_labels)\n",
    "            \n",
    "            loss_d = loss_d_real + loss_d_fake\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_g.zero_grad()\n",
    "            outputs_fake = discriminator(fake_images)\n",
    "            loss_g = criterion(outputs_fake, real_labels)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}\")\n",
    "\n",
    "#  Initialize GANs and Train\n",
    "generator = Generator(z_dim=100).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "train_gan(generator, discriminator, dataloader_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c3bb7-76c8-474f-bf5b-e535dcba893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/8f/ws6g2jvs4td4pv9rk5y8s2f00000gn/T/ipykernel_14054/139085568.py:80: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/var/folders/8f/ws6g2jvs4td4pv9rk5y8s2f00000gn/T/ipykernel_14054/139085568.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed precision context\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Acc: 45.48%, Val Acc: 46.13%\n",
      "Epoch [2/50] - Train Acc: 61.72%, Val Acc: 79.34%\n",
      "Epoch [3/50] - Train Acc: 76.29%, Val Acc: 80.81%\n",
      "Epoch [4/50] - Train Acc: 82.56%, Val Acc: 84.50%\n",
      "Epoch [5/50] - Train Acc: 85.24%, Val Acc: 83.76%\n",
      "Epoch [6/50] - Train Acc: 87.55%, Val Acc: 83.03%\n",
      "Epoch [7/50] - Train Acc: 88.47%, Val Acc: 81.55%\n",
      "Epoch [8/50] - Train Acc: 90.77%, Val Acc: 84.50%\n",
      "Epoch [9/50] - Train Acc: 91.70%, Val Acc: 83.03%\n",
      "Epoch [10/50] - Train Acc: 91.70%, Val Acc: 81.55%\n",
      "Epoch [11/50] - Train Acc: 92.34%, Val Acc: 83.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Reduced rotation range\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Lighter jitter\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Hybrid Model with ViT, CNN (EfficientNet), and Attention Mechanism\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False  # Freeze early CNN layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        self.projection = nn.Linear(1280, 768)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        for param in self.vit.encoder.layer[:6].parameters():\n",
    "            param.requires_grad = False  # Freeze early ViT layers\n",
    "        \n",
    "        self.weight_cnn = nn.Parameter(torch.ones(1))\n",
    "        self.weight_vit = nn.Parameter(torch.ones(1))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.projection(self.cnn(x).flatten(1))\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        weights = self.softmax(torch.cat([self.weight_cnn, self.weight_vit], dim=0))\n",
    "        fused_features = weights[0] * cnn_features + weights[1] * vit_features\n",
    "        fused_features = self.batch_norm(fused_features)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "#  Load dataset with smaller batch size to optimize memory\n",
    "batch_size = 32  # Reduce batch size to manage memory\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "#  Initialize model\n",
    "hybrid_model = HybridModel().to(device)\n",
    "\n",
    "#  Define loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=3e-5, weight_decay=5e-4)\n",
    "scheduler_hybrid = get_cosine_schedule_with_warmup(optimizer_hybrid, num_warmup_steps=5, num_training_steps=50)\n",
    "\n",
    "#  Mixed Precision Training Setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "#  Training Loop for Hybrid Model with Mixed Precision\n",
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs=50):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in dataloader_train:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():  # Mixed precision context\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = running_train_loss / len(dataloader_train)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_val:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(dataloader_val)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "        scheduler.step()\n",
    "\n",
    "#  Train the Hybrid Model\n",
    "train_model(hybrid_model, dataloader_train, dataloader_test, criterion, optimizer_hybrid, scheduler_hybrid, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ddc21-2760-40e9-b2d0-507fcd597c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Acc: 68.91%, Val Acc: 75.28%\n",
      "Epoch [2/50] - Train Acc: 76.29%, Val Acc: 78.60%\n",
      "Epoch [3/50] - Train Acc: 79.34%, Val Acc: 80.81%\n",
      "Epoch [4/50] - Train Acc: 79.34%, Val Acc: 80.07%\n",
      "Epoch [5/50] - Train Acc: 80.90%, Val Acc: 80.44%\n",
      "Epoch [6/50] - Train Acc: 81.09%, Val Acc: 80.07%\n",
      "Epoch [7/50] - Train Acc: 82.29%, Val Acc: 81.18%\n",
      "Epoch [8/50] - Train Acc: 83.30%, Val Acc: 83.39%\n",
      "Epoch [9/50] - Train Acc: 82.84%, Val Acc: 83.76%\n",
      "Epoch [10/50] - Train Acc: 83.30%, Val Acc: 84.87%\n",
      "Epoch [11/50] - Train Acc: 84.78%, Val Acc: 80.44%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),  # Increased rotation range\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # Adjusted color jitter\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Multi-Head Attention Model\n",
    "class HybridModelWithAttention(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2, num_heads=8, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False  # Freeze early CNN layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        # Projection layer to match dimensions for attention\n",
    "        self.projection = nn.Linear(1280, feature_dim)  \n",
    "        \n",
    "        # Multi-Head Attention Layer\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=num_heads, dropout=dropout)\n",
    "        \n",
    "        # Additional layers\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from CNN\n",
    "        cnn_features = self.cnn(x).flatten(1)  # Flatten output of CNN\n",
    "        \n",
    "        # Projection to match the feature dimension of attention\n",
    "        projected_features = self.projection(cnn_features).unsqueeze(0)  # Add batch dimension for MHA (1, batch_size, feature_dim)\n",
    "        \n",
    "        # Multi-Head Attention (Attention Layer)\n",
    "        attn_output, attn_weights = self.attn(projected_features, projected_features, projected_features)  # Self-attention\n",
    "        attn_output = attn_output.squeeze(0)  # Remove batch dimension\n",
    "        \n",
    "        # Batch normalization, dropout, and final classification\n",
    "        attn_output = self.batch_norm(attn_output)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        \n",
    "        return self.fc(attn_output)\n",
    "\n",
    "#  Load dataset\n",
    "batch_size = 32  # Reduce batch size to manage memory\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#  Initialize model\n",
    "hybrid_model_with_attention = HybridModelWithAttention().to(device)\n",
    "\n",
    "#  Define loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Add weight decay for regularization\n",
    "optimizer_hybrid = optim.Adam(hybrid_model_with_attention.parameters(), lr=3e-5, weight_decay=1e-4)  # L2 regularization\n",
    "\n",
    "# Cosine scheduler for learning rate decay\n",
    "scheduler_hybrid = ReduceLROnPlateau(optimizer_hybrid, mode='max', patience=3, verbose=True)\n",
    "\n",
    "#  Train function with learning rate scheduler and early stopping\n",
    "def train_model_with_regularization_and_lr_scheduler(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs=50, patience=5):\n",
    "    model = model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in dataloader_train:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(dataloader_train)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_val:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(dataloader_val)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation accuracy\")\n",
    "                break  # Stop training if no improvement for `patience` epochs\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(val_accuracy)  # Use validation accuracy for scheduler\n",
    "\n",
    "#  Train with regularization and learning rate scheduler\n",
    "train_model_with_regularization_and_lr_scheduler(hybrid_model_with_attention, dataloader_train, dataloader_test, criterion, optimizer_hybrid, scheduler_hybrid, epochs=50, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b2bb81-aa54-4f01-9ef3-abba38497405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Acc: 77.49%, Val Acc: 79.34%\n",
      "Epoch [2/50] - Train Acc: 83.76%, Val Acc: 81.18%\n",
      "Epoch [3/50] - Train Acc: 85.15%, Val Acc: 83.03%\n",
      "Epoch [4/50] - Train Acc: 86.81%, Val Acc: 83.03%\n",
      "Epoch [5/50] - Train Acc: 88.47%, Val Acc: 85.24%\n",
      "Epoch [6/50] - Train Acc: 87.18%, Val Acc: 81.18%\n",
      "Epoch [7/50] - Train Acc: 90.68%, Val Acc: 81.55%\n",
      "Epoch [8/50] - Train Acc: 89.39%, Val Acc: 81.92%\n",
      "Epoch [9/50] - Train Acc: 88.65%, Val Acc: 82.66%\n",
      "Epoch [10/50] - Train Acc: 91.14%, Val Acc: 82.29%\n",
      "Early stopping due to no improvement in validation accuracy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#  Define device (Use MPS if available, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),  # Increased rotation range\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # Adjusted color jitter\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "#  Improved Hybrid Model with Multihead Attention\n",
    "class HybridModelWithMHA(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False  # Freeze early CNN layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])  # Remove the final classifier\n",
    "        \n",
    "        # Projection to match feature size (if necessary)\n",
    "        self.projection = nn.Linear(1280, feature_dim)\n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.weight_cnn = nn.Parameter(torch.ones(1))\n",
    "        self.weight_vit = nn.Parameter(torch.ones(1))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # Multihead Attention Layer\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, dropout=0.1)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Update the fully connected layer size\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        cnn_features = self.cnn(x).flatten(1)  # Flatten before passing to projection layer\n",
    "        cnn_features = self.projection(cnn_features)  # Project to feature_dim\n",
    "        \n",
    "        # ViT features\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]  # Take the CLS token\n",
    "        \n",
    "        # Fusion of CNN and ViT features\n",
    "        weights = self.softmax(torch.cat([self.weight_cnn, self.weight_vit], dim=0))\n",
    "        fused_features = weights[0] * cnn_features + weights[1] * vit_features\n",
    "        \n",
    "        # Multihead Attention\n",
    "        # Adding batch_size as first dimension for multihead attention\n",
    "        attn_output, _ = self.multihead_attention(fused_features.unsqueeze(0), fused_features.unsqueeze(0), fused_features.unsqueeze(0))\n",
    "        attn_output = attn_output.squeeze(0)  # Remove batch dimension\n",
    "        \n",
    "        # Batch normalization and dropout\n",
    "        fused_features = self.batch_norm(attn_output)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        \n",
    "        return self.fc(fused_features)\n",
    "\n",
    "#  Load dataset\n",
    "batch_size = 32  # Reduce batch size to manage memory\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#  Initialize model\n",
    "model_with_mha_and_gan = HybridModelWithMHA().to(device)\n",
    "\n",
    "#  Define loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Add weight decay for regularization\n",
    "optimizer_hybrid = optim.Adam(model_with_mha_and_gan.parameters(), lr=3e-5, weight_decay=1e-4)  # L2 regularization\n",
    "\n",
    "# Cosine scheduler for learning rate decay\n",
    "scheduler_hybrid = ReduceLROnPlateau(optimizer_hybrid, mode='max', patience=3, verbose=True)\n",
    "\n",
    "#  Train function with learning rate scheduler and early stopping\n",
    "def train_model_with_regularization_and_lr_scheduler(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, epochs=50, patience=5):\n",
    "    model = model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        for inputs, labels in dataloader_train:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(dataloader_train)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader_val:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(dataloader_val)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping due to no improvement in validation accuracy\")\n",
    "                break  # Stop training if no improvement for `patience` epochs\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(val_accuracy)  # Use validation accuracy for scheduler\n",
    "\n",
    "#  Train with regularization and learning rate scheduler\n",
    "train_model_with_regularization_and_lr_scheduler(model_with_mha_and_gan, dataloader_train, dataloader_test, criterion, optimizer_hybrid, scheduler_hybrid, epochs=50, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86417919-0022-4456-9976-230ed45045b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b7b3ae-45d1-48a9-ba4d-e6b46d791a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.5138 - Train Acc: 77.21%\n",
      "Confusion Matrix:\n",
      "[[103  10]\n",
      " [ 55 103]]\n",
      "AUC: 0.7817\n",
      "Test Accuracy: 76.01%\n",
      "Epoch [2/50] - Loss: 0.3802 - Train Acc: 84.50%\n",
      "Confusion Matrix:\n",
      "[[ 85  28]\n",
      " [ 17 141]]\n",
      "AUC: 0.8223\n",
      "Test Accuracy: 83.39%\n",
      "Epoch [3/50] - Loss: 0.3373 - Train Acc: 85.15%\n",
      "Confusion Matrix:\n",
      "[[ 71  42]\n",
      " [ 13 145]]\n",
      "AUC: 0.7730\n",
      "Test Accuracy: 79.70%\n",
      "Epoch [4/50] - Loss: 0.3343 - Train Acc: 84.96%\n",
      "Confusion Matrix:\n",
      "[[ 93  20]\n",
      " [ 27 131]]\n",
      "AUC: 0.8261\n",
      "Test Accuracy: 82.66%\n",
      "Epoch [5/50] - Loss: 0.2866 - Train Acc: 86.99%\n",
      "Confusion Matrix:\n",
      "[[ 73  40]\n",
      " [  8 150]]\n",
      "AUC: 0.7977\n",
      "Test Accuracy: 82.29%\n",
      "Epoch [6/50] - Loss: 0.2870 - Train Acc: 88.84%\n",
      "Confusion Matrix:\n",
      "[[ 80  33]\n",
      " [ 15 143]]\n",
      "AUC: 0.8065\n",
      "Test Accuracy: 82.29%\n",
      "Epoch [7/50] - Loss: 0.2694 - Train Acc: 87.73%\n",
      "Confusion Matrix:\n",
      "[[101  12]\n",
      " [ 31 127]]\n",
      "AUC: 0.8488\n",
      "Test Accuracy: 84.13%\n",
      "Epoch [8/50] - Loss: 0.2300 - Train Acc: 89.39%\n",
      "Confusion Matrix:\n",
      "[[ 79  34]\n",
      " [ 12 146]]\n",
      "AUC: 0.8116\n",
      "Test Accuracy: 83.03%\n",
      "Epoch [9/50] - Loss: 0.2128 - Train Acc: 91.42%\n",
      "Confusion Matrix:\n",
      "[[ 99  14]\n",
      " [ 36 122]]\n",
      "AUC: 0.8241\n",
      "Test Accuracy: 81.55%\n",
      "Epoch [10/50] - Loss: 0.2426 - Train Acc: 90.22%\n",
      "Confusion Matrix:\n",
      "[[ 87  26]\n",
      " [ 18 140]]\n",
      "AUC: 0.8280\n",
      "Test Accuracy: 83.76%\n",
      "Epoch [11/50] - Loss: 0.2172 - Train Acc: 90.96%\n",
      "Confusion Matrix:\n",
      "[[ 76  37]\n",
      " [ 14 144]]\n",
      "AUC: 0.7920\n",
      "Test Accuracy: 81.18%\n",
      "Epoch [12/50] - Loss: 0.2017 - Train Acc: 91.97%\n",
      "Confusion Matrix:\n",
      "[[ 93  20]\n",
      " [ 30 128]]\n",
      "AUC: 0.8166\n",
      "Test Accuracy: 81.55%\n",
      "Early stopping due to no improvement\n",
      "Best Model Loaded with AUC: 0.8488\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Set up device (MPS, CUDA, or CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Data Augmentation with MixUp, CutMix, RandAugment\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "# Dataset loading\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model Components\n",
    "class HybridModelWithMHA(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone (EfficientNet + Pretrained)\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features[:5].parameters():\n",
    "            param.requires_grad = False\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        # Vision Transformer (ViT)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        \n",
    "        # Fusion Layer\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        # Multihead Attention for feature fusion\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, dropout=0.1)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        \n",
    "        # ViT features (CLS token)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Feature Fusion (Concatenation and Projection)\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attention(fused_features.unsqueeze(0), fused_features.unsqueeze(0), fused_features.unsqueeze(0))\n",
    "        attn_output = attn_output.squeeze(0)\n",
    "        \n",
    "        # Batch normalization, dropout, and classifier\n",
    "        fused_features = self.batch_norm(attn_output)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "def get_optimizer_and_scheduler(model, lr=1e-4):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix and AUC\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return cm, auc, test_accuracy\n",
    "\n",
    "# Training Loop with Checkpointing & Early Stopping\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50, patience=5):\n",
    "    writer = SummaryWriter()\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluation Phase\n",
    "        cm, auc, test_accuracy = evaluate_model(model, test_loader, device)\n",
    "        val_acc = auc  # Use AUC as evaluation metric\n",
    "        \n",
    "        # Early Stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping due to no improvement\")\n",
    "                break\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Best Model Loaded with AUC: {best_val_acc:.4f}\")\n",
    "    writer.close()\n",
    "\n",
    "# Model Initialization\n",
    "model = HybridModelWithMHA().to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2e1f4b-eb5e-4fe9-87b5-fcec47caef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.5244 - Train Acc: 75.28%\n",
      "Confusion Matrix:\n",
      "[[ 65  48]\n",
      " [ 11 147]]\n",
      "AUC: 0.7528\n",
      "Test Accuracy: 78.23%\n",
      "Precision: 0.7538 - Recall: 0.9304 - F1-score: 0.8329\n",
      "Epoch [2/50] - Loss: 0.4082 - Train Acc: 82.10%\n",
      "Confusion Matrix:\n",
      "[[ 81  32]\n",
      " [ 14 144]]\n",
      "AUC: 0.8141\n",
      "Test Accuracy: 83.03%\n",
      "Precision: 0.8182 - Recall: 0.9114 - F1-score: 0.8623\n",
      "Epoch [3/50] - Loss: 0.3243 - Train Acc: 86.16%\n",
      "Confusion Matrix:\n",
      "[[ 93  20]\n",
      " [ 28 130]]\n",
      "AUC: 0.8229\n",
      "Test Accuracy: 82.29%\n",
      "Precision: 0.8667 - Recall: 0.8228 - F1-score: 0.8442\n",
      "Epoch [4/50] - Loss: 0.2958 - Train Acc: 87.27%\n",
      "Confusion Matrix:\n",
      "[[ 79  34]\n",
      " [  7 151]]\n",
      "AUC: 0.8274\n",
      "Test Accuracy: 84.87%\n",
      "Precision: 0.8162 - Recall: 0.9557 - F1-score: 0.8805\n",
      "Epoch [5/50] - Loss: 0.2802 - Train Acc: 87.45%\n",
      "Confusion Matrix:\n",
      "[[ 85  28]\n",
      " [ 27 131]]\n",
      "AUC: 0.7907\n",
      "Test Accuracy: 79.70%\n",
      "Precision: 0.8239 - Recall: 0.8291 - F1-score: 0.8265\n",
      "Epoch [6/50] - Loss: 0.2718 - Train Acc: 88.10%\n",
      "Confusion Matrix:\n",
      "[[105   8]\n",
      " [ 39 119]]\n",
      "AUC: 0.8412\n",
      "Test Accuracy: 82.66%\n",
      "Precision: 0.9370 - Recall: 0.7532 - F1-score: 0.8351\n",
      "Epoch [7/50] - Loss: 0.2476 - Train Acc: 89.21%\n",
      "Confusion Matrix:\n",
      "[[100  13]\n",
      " [ 35 123]]\n",
      "AUC: 0.8317\n",
      "Test Accuracy: 82.29%\n",
      "Precision: 0.9044 - Recall: 0.7785 - F1-score: 0.8367\n",
      "Epoch [8/50] - Loss: 0.2304 - Train Acc: 89.85%\n",
      "Confusion Matrix:\n",
      "[[ 74  39]\n",
      " [  9 149]]\n",
      "AUC: 0.7990\n",
      "Test Accuracy: 82.29%\n",
      "Precision: 0.7926 - Recall: 0.9430 - F1-score: 0.8613\n",
      "Epoch [9/50] - Loss: 0.2537 - Train Acc: 88.65%\n",
      "Confusion Matrix:\n",
      "[[ 85  28]\n",
      " [ 18 140]]\n",
      "AUC: 0.8191\n",
      "Test Accuracy: 83.03%\n",
      "Precision: 0.8333 - Recall: 0.8861 - F1-score: 0.8589\n",
      "Epoch [10/50] - Loss: 0.2541 - Train Acc: 89.48%\n",
      "Confusion Matrix:\n",
      "[[ 91  22]\n",
      " [ 28 130]]\n",
      "AUC: 0.8140\n",
      "Test Accuracy: 81.55%\n",
      "Precision: 0.8553 - Recall: 0.8228 - F1-score: 0.8387\n",
      "Epoch [11/50] - Loss: 0.1869 - Train Acc: 92.62%\n",
      "Confusion Matrix:\n",
      "[[ 98  15]\n",
      " [ 37 121]]\n",
      "AUC: 0.8165\n",
      "Test Accuracy: 80.81%\n",
      "Precision: 0.8897 - Recall: 0.7658 - F1-score: 0.8231\n",
      "Early stopping due to no improvement\n",
      "Best Model Loaded with AUC: 0.8412\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Set up device (MPS, CUDA, or CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is the last transformation before any tensor-specific operations\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/acrima+origa/Testing\"\n",
    "\n",
    "# Dataset loading\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model Components with more layers unfrozen in EfficientNet\n",
    "class HybridModelWithMHA(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone (EfficientNet + Pretrained)\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True  # Unfreeze all layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        # Vision Transformer (ViT)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        \n",
    "        # Fusion Layer\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        # Multihead Attention for feature fusion\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, dropout=0.1)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        \n",
    "        # ViT features (CLS token)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Feature Fusion (Concatenation and Projection)\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attention(fused_features.unsqueeze(0), fused_features.unsqueeze(0), fused_features.unsqueeze(0))\n",
    "        attn_output = attn_output.squeeze(0)\n",
    "        \n",
    "        # Batch normalization, dropout, and classifier\n",
    "        fused_features = self.batch_norm(attn_output)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler with Warmup\n",
    "def get_optimizer_and_scheduler(model, lr=1e-4):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix, AUC, Precision-Recall and F1-score\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f} - Recall: {recall:.4f} - F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return cm, auc, test_accuracy, precision, recall, f1\n",
    "\n",
    "# Training Loop with Checkpointing & Early Stopping\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50, patience=5):\n",
    "    writer = SummaryWriter()\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluation Phase\n",
    "        cm, auc, test_accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "        val_acc = auc  # Use AUC as evaluation metric\n",
    "        \n",
    "        # Early Stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping due to no improvement\")\n",
    "                break\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1/test', f1, epoch)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Best Model Loaded with AUC: {best_val_acc:.4f}\")\n",
    "    writer.close()\n",
    "\n",
    "# Model Initialization\n",
    "model = HybridModelWithMHA().to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bf934-af9c-4cce-b5ff-3f5ee483aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "# Set up device (MPS, CUDA, or CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Data augmentation pipeline with stronger regularization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),  # Ensure ToTensor is the last transformation before any tensor-specific operations\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/DRISHTI-GS/DRISHTI-GS/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/DRISHTI-GS/DRISHTI-GS/Testing\"\n",
    "\n",
    "# Dataset loading with class weights to handle class imbalance\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = [0] * len(train_dataset.classes)\n",
    "for _, label in train_dataset:\n",
    "    class_counts[label] += 1\n",
    "class_weights = [sum(class_counts) / count for count in class_counts]\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "\n",
    "# WeightedRandomSampler to handle class imbalance\n",
    "weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model Components with more layers unfrozen in EfficientNet\n",
    "class HybridModelWithMHA(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone (EfficientNet + Pretrained)\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True  # Unfreeze all layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        # Vision Transformer (ViT)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        \n",
    "        # Fusion Layer\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        # Multihead Attention for feature fusion\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, dropout=0.2)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.6)  # Increased dropout for more regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        \n",
    "        # ViT features (CLS token)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Feature Fusion (Concatenation and Projection)\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attention(fused_features.unsqueeze(0), fused_features.unsqueeze(0), fused_features.unsqueeze(0))\n",
    "        attn_output = attn_output.squeeze(0)\n",
    "        \n",
    "        # Batch normalization, dropout, and classifier\n",
    "        fused_features = self.batch_norm(attn_output)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler with Warmup\n",
    "def get_optimizer_and_scheduler(model, lr=1e-5):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)  # L2 regularization (weight decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss Function with Class Weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix, AUC, Precision-Recall and F1-score\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f} - Recall: {recall:.4f} - F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return cm, auc, test_accuracy, precision, recall, f1\n",
    "\n",
    "# Training Loop without Early Stopping\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    writer = SummaryWriter()\n",
    "    best_val_acc = 0.0\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluation Phase\n",
    "        cm, auc, test_accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "        val_acc = auc  # Use AUC as evaluation metric\n",
    "        \n",
    "        # Save best model based on AUC\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1/test', f1, epoch)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Best Model Loaded with AUC: {best_val_acc:.4f}\")\n",
    "    writer.close()\n",
    "\n",
    "# Model Initialization\n",
    "model = HybridModelWithMHA().to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7243bcbd-249b-4653-a126-0dd2ad53b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.8948 - Train Acc: 25.18%\n",
      "Confusion Matrix:\n",
      "[[11 68]\n",
      " [10 52]]\n",
      "AUC: 0.4890\n",
      "Test Accuracy: 44.68%\n",
      "Precision: 0.4333 - Recall: 0.8387 - F1-score: 0.5714\n",
      "Epoch [2/50] - Loss: 0.8837 - Train Acc: 23.58%\n",
      "Confusion Matrix:\n",
      "[[24 55]\n",
      " [ 9 53]]\n",
      "AUC: 0.5793\n",
      "Test Accuracy: 54.61%\n",
      "Precision: 0.4907 - Recall: 0.8548 - F1-score: 0.6235\n",
      "Epoch [3/50] - Loss: 0.7992 - Train Acc: 29.26%\n",
      "Confusion Matrix:\n",
      "[[51 28]\n",
      " [ 9 53]]\n",
      "AUC: 0.7502\n",
      "Test Accuracy: 73.76%\n",
      "Precision: 0.6543 - Recall: 0.8548 - F1-score: 0.7413\n",
      "Epoch [4/50] - Loss: 0.7406 - Train Acc: 35.28%\n",
      "Confusion Matrix:\n",
      "[[50 29]\n",
      " [ 7 55]]\n",
      "AUC: 0.7600\n",
      "Test Accuracy: 74.47%\n",
      "Precision: 0.6548 - Recall: 0.8871 - F1-score: 0.7534\n",
      "Epoch [5/50] - Loss: 0.6648 - Train Acc: 38.65%\n",
      "Confusion Matrix:\n",
      "[[56 23]\n",
      " [ 3 59]]\n",
      "AUC: 0.8302\n",
      "Test Accuracy: 81.56%\n",
      "Precision: 0.7195 - Recall: 0.9516 - F1-score: 0.8194\n",
      "Epoch [6/50] - Loss: 0.7115 - Train Acc: 35.82%\n",
      "Confusion Matrix:\n",
      "[[75  4]\n",
      " [10 52]]\n",
      "AUC: 0.8940\n",
      "Test Accuracy: 90.07%\n",
      "Precision: 0.9286 - Recall: 0.8387 - F1-score: 0.8814\n",
      "Epoch [7/50] - Loss: 0.6737 - Train Acc: 40.78%\n",
      "Confusion Matrix:\n",
      "[[58 21]\n",
      " [ 3 59]]\n",
      "AUC: 0.8429\n",
      "Test Accuracy: 82.98%\n",
      "Precision: 0.7375 - Recall: 0.9516 - F1-score: 0.8310\n",
      "Epoch [8/50] - Loss: 0.6377 - Train Acc: 40.43%\n",
      "Confusion Matrix:\n",
      "[[61 18]\n",
      " [ 4 58]]\n",
      "AUC: 0.8538\n",
      "Test Accuracy: 84.40%\n",
      "Precision: 0.7632 - Recall: 0.9355 - F1-score: 0.8406\n",
      "Epoch [9/50] - Loss: 0.7069 - Train Acc: 39.18%\n",
      "Confusion Matrix:\n",
      "[[66 13]\n",
      " [ 1 61]]\n",
      "AUC: 0.9097\n",
      "Test Accuracy: 90.07%\n",
      "Precision: 0.8243 - Recall: 0.9839 - F1-score: 0.8971\n",
      "Epoch [10/50] - Loss: 0.6196 - Train Acc: 42.73%\n",
      "Confusion Matrix:\n",
      "[[57 22]\n",
      " [ 5 57]]\n",
      "AUC: 0.8204\n",
      "Test Accuracy: 80.85%\n",
      "Precision: 0.7215 - Recall: 0.9194 - F1-score: 0.8085\n",
      "Epoch [11/50] - Loss: 0.7031 - Train Acc: 44.68%\n",
      "Confusion Matrix:\n",
      "[[64 15]\n",
      " [ 1 61]]\n",
      "AUC: 0.8970\n",
      "Test Accuracy: 88.65%\n",
      "Precision: 0.8026 - Recall: 0.9839 - F1-score: 0.8841\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 213\u001b[39m\n\u001b[32m    210\u001b[39m optimizer, scheduler = get_optimizer_and_scheduler(model)\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs)\u001b[39m\n\u001b[32m    169\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m    170\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m running_loss += loss.item()\n\u001b[32m    174\u001b[39m correct_train += (outputs.argmax(\u001b[32m1\u001b[39m) == labels).sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:140\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m opt = opt_ref()\n\u001b[32m    139\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/adamw.py:243\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    230\u001b[39m     beta1, beta2 = cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    232\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    233\u001b[39m         group,\n\u001b[32m    234\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m         state_steps,\n\u001b[32m    241\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/adamw.py:875\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    873\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/optim/adamw.py:477\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    475\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# Set up device (MPS, CUDA, or CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Data augmentation pipeline with stronger regularization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Training/\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/ACRIMA/ACRIMA/PARTITIONED/Testing/\"\n",
    "\n",
    "# Dataset loading with class weights to handle class imbalance\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = [0] * len(train_dataset.classes)\n",
    "for _, label in train_dataset:\n",
    "    class_counts[label] += 1\n",
    "class_weights = [sum(class_counts) / count for count in class_counts]\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "\n",
    "# WeightedRandomSampler to handle class imbalance\n",
    "weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model Components with more layers unfrozen in EfficientNet\n",
    "class HybridModelWithMHA(nn.Module):\n",
    "    def __init__(self, feature_dim=768, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone (EfficientNet + Pretrained)\n",
    "        self.cnn = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.cnn.features.parameters():\n",
    "            param.requires_grad = True  # Unfreeze all layers\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        \n",
    "        # Vision Transformer (ViT)\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        \n",
    "        # Fusion Layer\n",
    "        self.projection = nn.Linear(1280 + feature_dim, feature_dim)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "        # Multihead Attention for feature fusion\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=feature_dim, num_heads=8, dropout=0.2)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.dropout = nn.Dropout(0.5)  # Moderate dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN features\n",
    "        cnn_features = self.cnn(x).flatten(1)\n",
    "        \n",
    "        # ViT features (CLS token)\n",
    "        vit_features = self.vit(x).last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Feature Fusion (Concatenation and Projection)\n",
    "        features = torch.cat([cnn_features, vit_features], dim=-1)\n",
    "        fused_features = self.projection(features)\n",
    "        \n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attention(fused_features.unsqueeze(0), fused_features.unsqueeze(0), fused_features.unsqueeze(0))\n",
    "        attn_output = attn_output.squeeze(0)\n",
    "        \n",
    "        # Batch normalization, dropout, and classifier\n",
    "        fused_features = self.batch_norm(attn_output)\n",
    "        fused_features = self.dropout(fused_features)\n",
    "        return self.fc(fused_features)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler with Warmup\n",
    "def get_optimizer_and_scheduler(model, lr=1e-5, warmup_steps=5):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning Rate Warmup Function\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return 1.0\n",
    "    \n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Mixup Augmentation Function\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "# Loss Function with Class Weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix, AUC, Precision-Recall and F1-score\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f} - Recall: {recall:.4f} - F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return cm, auc, test_accuracy, precision, recall, f1\n",
    "\n",
    "# Training Loop without Early Stopping\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    writer = SummaryWriter()\n",
    "    best_val_acc = 0.0\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Mixup data\n",
    "            inputs, labels = mixup_data(inputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluation Phase\n",
    "        cm, auc, test_accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "        val_acc = auc  # Use AUC as evaluation metric\n",
    "        \n",
    "        # Save best model based on AUC\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1/test', f1, epoch)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Best Model Loaded with AUC: {best_val_acc:.4f}\")\n",
    "    writer.close()\n",
    "\n",
    "# Model Initialization\n",
    "model = HybridModelWithMHA().to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d91839-0baa-4bd8-a014-cfdc20c85b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramanathanswaminathan/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Loss: 0.9310 - Train Acc: 48.00%\n",
      "Confusion Matrix:\n",
      "[[ 3 35]\n",
      " [ 2 11]]\n",
      "AUC: 0.4626\n",
      "Test Accuracy: 27.45%\n",
      "Precision: 0.2391 - Recall: 0.8462 - F1-score: 0.3729\n",
      "Epoch [2/50] - Loss: 0.8815 - Train Acc: 40.00%\n",
      "Confusion Matrix:\n",
      "[[ 2 36]\n",
      " [ 2 11]]\n",
      "AUC: 0.4494\n",
      "Test Accuracy: 25.49%\n",
      "Precision: 0.2340 - Recall: 0.8462 - F1-score: 0.3667\n",
      "Epoch [3/50] - Loss: 0.7077 - Train Acc: 56.00%\n",
      "Confusion Matrix:\n",
      "[[ 3 35]\n",
      " [ 1 12]]\n",
      "AUC: 0.5010\n",
      "Test Accuracy: 29.41%\n",
      "Precision: 0.2553 - Recall: 0.9231 - F1-score: 0.4000\n",
      "Epoch [4/50] - Loss: 0.4649 - Train Acc: 90.00%\n",
      "Confusion Matrix:\n",
      "[[ 7 31]\n",
      " [ 1 12]]\n",
      "AUC: 0.5536\n",
      "Test Accuracy: 37.25%\n",
      "Precision: 0.2791 - Recall: 0.9231 - F1-score: 0.4286\n",
      "Epoch [5/50] - Loss: 0.1899 - Train Acc: 94.00%\n",
      "Confusion Matrix:\n",
      "[[15 23]\n",
      " [ 1 12]]\n",
      "AUC: 0.6589\n",
      "Test Accuracy: 52.94%\n",
      "Precision: 0.3429 - Recall: 0.9231 - F1-score: 0.5000\n",
      "Epoch [6/50] - Loss: 0.1317 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[23 15]\n",
      " [ 4  9]]\n",
      "AUC: 0.6488\n",
      "Test Accuracy: 62.75%\n",
      "Precision: 0.3750 - Recall: 0.6923 - F1-score: 0.4865\n",
      "Epoch [7/50] - Loss: 0.3041 - Train Acc: 92.00%\n",
      "Confusion Matrix:\n",
      "[[27 11]\n",
      " [ 5  8]]\n",
      "AUC: 0.6630\n",
      "Test Accuracy: 68.63%\n",
      "Precision: 0.4211 - Recall: 0.6154 - F1-score: 0.5000\n",
      "Epoch [8/50] - Loss: 0.2063 - Train Acc: 92.00%\n",
      "Confusion Matrix:\n",
      "[[25 13]\n",
      " [ 6  7]]\n",
      "AUC: 0.5982\n",
      "Test Accuracy: 62.75%\n",
      "Precision: 0.3500 - Recall: 0.5385 - F1-score: 0.4242\n",
      "Epoch [9/50] - Loss: 0.0378 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[24 14]\n",
      " [ 6  7]]\n",
      "AUC: 0.5850\n",
      "Test Accuracy: 60.78%\n",
      "Precision: 0.3333 - Recall: 0.5385 - F1-score: 0.4118\n",
      "Epoch [10/50] - Loss: 0.0960 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[29  9]\n",
      " [ 6  7]]\n",
      "AUC: 0.6508\n",
      "Test Accuracy: 70.59%\n",
      "Precision: 0.4375 - Recall: 0.5385 - F1-score: 0.4828\n",
      "Epoch [11/50] - Loss: 0.0698 - Train Acc: 96.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [12/50] - Loss: 0.0181 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [13/50] - Loss: 0.0221 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [14/50] - Loss: 0.0158 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[33  5]\n",
      " [ 7  6]]\n",
      "AUC: 0.6650\n",
      "Test Accuracy: 76.47%\n",
      "Precision: 0.5455 - Recall: 0.4615 - F1-score: 0.5000\n",
      "Epoch [15/50] - Loss: 0.0114 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[33  5]\n",
      " [ 7  6]]\n",
      "AUC: 0.6650\n",
      "Test Accuracy: 76.47%\n",
      "Precision: 0.5455 - Recall: 0.4615 - F1-score: 0.5000\n",
      "Epoch [16/50] - Loss: 0.0189 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [17/50] - Loss: 0.0716 - Train Acc: 94.00%\n",
      "Confusion Matrix:\n",
      "[[33  5]\n",
      " [ 7  6]]\n",
      "AUC: 0.6650\n",
      "Test Accuracy: 76.47%\n",
      "Precision: 0.5455 - Recall: 0.4615 - F1-score: 0.5000\n",
      "Epoch [18/50] - Loss: 0.0137 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[33  5]\n",
      " [ 7  6]]\n",
      "AUC: 0.6650\n",
      "Test Accuracy: 76.47%\n",
      "Precision: 0.5455 - Recall: 0.4615 - F1-score: 0.5000\n",
      "Epoch [19/50] - Loss: 0.0094 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [20/50] - Loss: 0.0141 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [21/50] - Loss: 0.0378 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [22/50] - Loss: 0.0131 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [23/50] - Loss: 0.0107 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [24/50] - Loss: 0.0081 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [25/50] - Loss: 0.0059 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [26/50] - Loss: 0.0037 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [27/50] - Loss: 0.0038 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [28/50] - Loss: 0.0203 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[34  4]\n",
      " [ 7  6]]\n",
      "AUC: 0.6781\n",
      "Test Accuracy: 78.43%\n",
      "Precision: 0.6000 - Recall: 0.4615 - F1-score: 0.5217\n",
      "Epoch [29/50] - Loss: 0.0092 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [30/50] - Loss: 0.0050 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[34  4]\n",
      " [ 7  6]]\n",
      "AUC: 0.6781\n",
      "Test Accuracy: 78.43%\n",
      "Precision: 0.6000 - Recall: 0.4615 - F1-score: 0.5217\n",
      "Epoch [31/50] - Loss: 0.0019 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [32/50] - Loss: 0.0050 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [33/50] - Loss: 0.0025 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [34/50] - Loss: 0.0059 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[32  6]\n",
      " [ 7  6]]\n",
      "AUC: 0.6518\n",
      "Test Accuracy: 74.51%\n",
      "Precision: 0.5000 - Recall: 0.4615 - F1-score: 0.4800\n",
      "Epoch [35/50] - Loss: 0.0185 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[31  7]\n",
      " [ 7  6]]\n",
      "AUC: 0.6387\n",
      "Test Accuracy: 72.55%\n",
      "Precision: 0.4615 - Recall: 0.4615 - F1-score: 0.4615\n",
      "Epoch [36/50] - Loss: 0.0016 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[34  4]\n",
      " [ 7  6]]\n",
      "AUC: 0.6781\n",
      "Test Accuracy: 78.43%\n",
      "Precision: 0.6000 - Recall: 0.4615 - F1-score: 0.5217\n",
      "Epoch [37/50] - Loss: 0.0009 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[34  4]\n",
      " [ 7  6]]\n",
      "AUC: 0.6781\n",
      "Test Accuracy: 78.43%\n",
      "Precision: 0.6000 - Recall: 0.4615 - F1-score: 0.5217\n",
      "Epoch [38/50] - Loss: 0.0020 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[35  3]\n",
      " [ 7  6]]\n",
      "AUC: 0.6913\n",
      "Test Accuracy: 80.39%\n",
      "Precision: 0.6667 - Recall: 0.4615 - F1-score: 0.5455\n",
      "Epoch [39/50] - Loss: 0.0033 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[35  3]\n",
      " [ 7  6]]\n",
      "AUC: 0.6913\n",
      "Test Accuracy: 80.39%\n",
      "Precision: 0.6667 - Recall: 0.4615 - F1-score: 0.5455\n",
      "Epoch [40/50] - Loss: 0.0039 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[38  0]\n",
      " [ 8  5]]\n",
      "AUC: 0.6923\n",
      "Test Accuracy: 84.31%\n",
      "Precision: 1.0000 - Recall: 0.3846 - F1-score: 0.5556\n",
      "Epoch [41/50] - Loss: 0.0011 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 7  6]]\n",
      "AUC: 0.7045\n",
      "Test Accuracy: 82.35%\n",
      "Precision: 0.7500 - Recall: 0.4615 - F1-score: 0.5714\n",
      "Epoch [42/50] - Loss: 0.0011 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[35  3]\n",
      " [ 7  6]]\n",
      "AUC: 0.6913\n",
      "Test Accuracy: 80.39%\n",
      "Precision: 0.6667 - Recall: 0.4615 - F1-score: 0.5455\n",
      "Epoch [43/50] - Loss: 0.0030 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 7  6]]\n",
      "AUC: 0.7176\n",
      "Test Accuracy: 84.31%\n",
      "Precision: 0.8571 - Recall: 0.4615 - F1-score: 0.6000\n",
      "Epoch [44/50] - Loss: 0.0008 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 7  6]]\n",
      "AUC: 0.7176\n",
      "Test Accuracy: 84.31%\n",
      "Precision: 0.8571 - Recall: 0.4615 - F1-score: 0.6000\n",
      "Epoch [45/50] - Loss: 0.0008 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[34  4]\n",
      " [ 7  6]]\n",
      "AUC: 0.6781\n",
      "Test Accuracy: 78.43%\n",
      "Precision: 0.6000 - Recall: 0.4615 - F1-score: 0.5217\n",
      "Epoch [46/50] - Loss: 0.0049 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 7  6]]\n",
      "AUC: 0.7045\n",
      "Test Accuracy: 82.35%\n",
      "Precision: 0.7500 - Recall: 0.4615 - F1-score: 0.5714\n",
      "Epoch [47/50] - Loss: 0.0009 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 7  6]]\n",
      "AUC: 0.7176\n",
      "Test Accuracy: 84.31%\n",
      "Precision: 0.8571 - Recall: 0.4615 - F1-score: 0.6000\n",
      "Epoch [48/50] - Loss: 0.0015 - Train Acc: 100.00%\n",
      "Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 7  6]]\n",
      "AUC: 0.7045\n",
      "Test Accuracy: 82.35%\n",
      "Precision: 0.7500 - Recall: 0.4615 - F1-score: 0.5714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 166\u001b[39m\n\u001b[32m    163\u001b[39m optimizer, scheduler = get_optimizer_and_scheduler(model)\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 117\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs)\u001b[39m\n\u001b[32m    114\u001b[39m correct_train, total_train = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Training Phase\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:245\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[33;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m path, target = \u001b[38;5;28mself\u001b[39m.samples[index]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.transform(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:284\u001b[39m, in \u001b[36mdefault_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/torchvision/datasets/folder.py:264\u001b[39m, in \u001b[36mpil_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    263\u001b[39m     img = Image.open(f)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/PIL/Image.py:984\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    982\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.12/site-packages/PIL/ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from transformers import ViTModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# Set up device (MPS, CUDA, or CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Data augmentation pipeline with regularization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset paths\n",
    "train_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/DRISHTI-GS/DRISHTI-GS/Training\"\n",
    "test_dir = \"/Users/ramanathanswaminathan/Downloads/glaucoma_exhaustive/DRISHTI-GS/DRISHTI-GS/Testing\"\n",
    "\n",
    "# Dataset loading with class weights to handle class imbalance\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = [0] * len(train_dataset.classes)\n",
    "for _, label in train_dataset:\n",
    "    class_counts[label] += 1\n",
    "class_weights = [sum(class_counts) / count for count in class_counts]\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "\n",
    "# WeightedRandomSampler to handle class imbalance\n",
    "weights = [class_weights[label] for _, label in train_dataset]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Simplified Model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use ResNet18 instead of EfficientNet and ViT for simpler model\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, num_classes)  # Replace final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "# Optimizer and Learning Rate Scheduler with Warmup\n",
    "def get_optimizer_and_scheduler(model, lr=1e-4, warmup_steps=5):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning Rate Warmup Function\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return 1.0\n",
    "    \n",
    "    scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Loss Function with Class Weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix, AUC, Precision-Recall and F1-score\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f} - Recall: {recall:.4f} - F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return cm, auc, test_accuracy, precision, recall, f1\n",
    "\n",
    "# Training Loop without Early Stopping\n",
    "def train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device, epochs=50):\n",
    "    writer = SummaryWriter()\n",
    "    best_val_acc = 0.0\n",
    "    checkpoint_path = \"best_model.pth\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluation Phase\n",
    "        cm, auc, test_accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "        val_acc = test_accuracy  # Use accuracy as evaluation metric for now\n",
    "        \n",
    "        # Save best model based on test accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "        # Learning Rate Scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "        writer.add_scalar('Precision/test', precision, epoch)\n",
    "        writer.add_scalar('Recall/test', recall, epoch)\n",
    "        writer.add_scalar('F1/test', f1, epoch)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Best Model Loaded with Accuracy: {best_val_acc:.2f}\")\n",
    "    writer.close()\n",
    "\n",
    "# Model Initialization\n",
    "model = SimpleModel().to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer, scheduler = get_optimizer_and_scheduler(model)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, test_loader, optimizer, scheduler, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa8fb2-1610-4233-833e-fe448348ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
